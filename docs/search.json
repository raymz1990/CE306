[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CE306 - Instrumentação Matemática para Estatística",
    "section": "",
    "text": "Apresentação\nCE306 - Instrumentação Matemática para Estatística Departamento de Estatística - UFPR Professor: Wagner Bonat Primeiro Semestre 2024 (27/Fevereiro/2024 - 2/Julho/2024).",
    "crumbs": [
      "Apresentação"
    ]
  },
  {
    "objectID": "index.html#objetivos",
    "href": "index.html#objetivos",
    "title": "CE313 - Estatística Não-Paramétrica",
    "section": "Objetivos",
    "text": "Objetivos\nOs métodos de inferência estatística não paramétricos ou de distribuição livre, são procedimentos matemáticos para testes de hipóteses e modelos de regressão que, diferentemente da estatística paramétrica, não fazem suposições sobre a distribuição de probabilidade das variáveis a serem consideradas. Objetivo geral: Espera-se que, ao final da disciplina, o aluno deva saber identificar o uso de testes não-paramétricos e lidar de forma apropriada com problemas práticos.\nObjetivos específicos: Identificar situações nas quais procedimentos não-paramétricos podem ser aplicados, selecionar testes não-paramétrico adequados para um problema em estudo, construir as hipóteses correspondentes e aplicar os procedimentos escolhidos utilizando funções R para esta finalidade.",
    "crumbs": [
      "Apresentação"
    ]
  },
  {
    "objectID": "index.html#ementa",
    "href": "index.html#ementa",
    "title": "CE306 - Instrumentação Matemática para Estatística",
    "section": "Ementa",
    "text": "Ementa\nFunções, limites e continuidade. Derivadas e integrais. Séries numéricas. Vetores, matrizes, sistemas lineares e decomposições matriciais. Métodos numéricos. Solução de sistemas de equações não-lineares. Derivação e integração numéricas. Otimização numéricos. Programação linear, quadrática e não-linear. Aspectos computacionais. Softwares para computação científica.",
    "crumbs": [
      "Apresentação"
    ]
  },
  {
    "objectID": "index.html#referências-bibliográficas-básicas",
    "href": "index.html#referências-bibliográficas-básicas",
    "title": "CE306 - Instrumentação Matemática para Estatística",
    "section": "Referências bibliográficas básicas",
    "text": "Referências bibliográficas básicas\n1, Deisenroth, M. P. ; Faisal, A. A. ; Ong, C. S. Mathematics for Machine Learning, Cambridge University Press, 2020;\n\nGoodfellow et. al. Deep Learning, MIT Press, 2016;\nR. A. Becker, J. M. Chambers and A. R. Wilks, “The New S Language,” Wadsworth &Brooks/Cole, Monterey, 1988.",
    "crumbs": [
      "Apresentação"
    ]
  },
  {
    "objectID": "index.html#referências-bibliográficas-complementares",
    "href": "index.html#referências-bibliográficas-complementares",
    "title": "CE306 - Instrumentação Matemática para Estatística",
    "section": "Referências bibliográficas complementares",
    "text": "Referências bibliográficas complementares\n\nHastie, T.; Tibshirani, R. and Friedman, J. (2013). The elements of statistical learning: Data mining, inference, and prediction. Springer New York.\nHollander, M. and Wolfe, D.A. (1999). Nonparametric statistical methods. 2nd. ed. New York: John Wiley & Sons.\nKloke, J. and McKean, J.W. (2015). Nonparametric statistical methods using R. Boca Raton: CRC Press.\nSilverman, B.W. (1994). Nonparametric Regression and Generalized Linear Models: A Roughness Penalty Approach, London: Editora Chapman & Hall.\nWasserman, L. (2006). All of nonparametric statistics: New York: Springer.",
    "crumbs": [
      "Apresentação"
    ]
  },
  {
    "objectID": "index.html#conteúdo-programático",
    "href": "index.html#conteúdo-programático",
    "title": "CE313 - Estatística Não-Paramétrica",
    "section": "Conteúdo Programático",
    "text": "Conteúdo Programático\nMÓDULO I: Estimação não paramétrica\n\nAula 01 - Estatística não paramétrica 1\nAula 02 - Estatísticas de ordem\nAula 03 - Estatística não paramétrica 2\nAula 04 - Função de Distribuição Empírica\nAula 05 -\nAula 06 -\n\n\nMÓDULO II: Problemas de amostra única\n\nAula 07 -\nAula 08 -\nAula 09 -\nAula 10 -\nAula 11 -\nAula 12 -\nAula 13 -\nAula 14 -\n\n\nMÓDULO III: Procedimentos em k amostras\n\nAula 15 -\nAula 16 -\nAula 17 -\nAula 18 -\nAula 19 -\nAula 20 -\nAula 21 -\nAula 22 -\n\n\nMÓDULO IV: Regressão não paramétrica\n\nAula 23 -\nAula 24 -\nAula 25 -\nAula 26 -\nAula 27 -\nAula 28 -\nAula 29 -\nAula 30 -\n\n\nMÓDULO V: Redes neurais\n\nAula 31 -\nAula 32 -\nAula 33 -\nAula 34 -\nAula 35 -\nAula 36 -",
    "crumbs": [
      "Apresentação"
    ]
  },
  {
    "objectID": "ModuloI/index.html",
    "href": "ModuloI/index.html",
    "title": "Prefácio",
    "section": "",
    "text": "Contexto e motivação\nA transformação digital pela qual a sociedade está passando, aliada ao maior acesso a dispositivos tecnológicos como smartphones e tablets conectados à internet vêm revolucionando a forma como vivemos. Neste contexto, as empresas de tecnologia não demoraram para criar diversos produtos em que o lucro é gerado baseado nos dados de seus clientes. Exemplos deste mercado de dados incluem e-mails gratuitos, mídias sociais, plataformas de divulgação de vídeos, portais de informação e busca, entre outros.\nSeguindo esta tendência, empresas de praticamente todos os seguimentos estão procurando em seus dados formas de otimizar a sua operação e gerar mais lucro. Neste cenário de transformação digital surge a profissão do cientista de dados. Este profissional é o responsável por usar métodos científicos para entender e criar valor baseado em dados. Devido a sua flexibilidade e o momento em que vivemos, o profissional de ciência de dados está em alta demanda pelo mercado de trabalho, sendo um dos profissionais mais bem remunerados. Consequentemente, profissionais de outras áreas estão interessados em migrar para a área de ciência de dados e para isto estão procurando por formação adicional.\nA profissão denominada de cientista de dados é extremamente nova e definições precisas sobre as habilidades de tal profissional estão em pleno desenvolvimento. Isto dificulta a formação de profissionais nesta área. Além de ser um desafio para instituições de ensino desenharem cursos que respondam as reais necessidades do mercado de trabalho. Uma busca rápida por ofertas de empregos para cientistas de dados traz uma lista enciclopédica de habilidades que vão desde ferramentas tecnológicas baseadas em softwares proprietários, passando por diversas linguagens de programação, até chegar em algoritmos específicos de aprendizagem de máquina e modelos estatísticos.\nQuando focamos apenas nas diversas técnicas que compõem a caixa de ferramentas do cientista de dados, nos deparamos com uma infinidade de modelos e algoritmos. De forma semelhante, livros que tem no título a expressão ciência de dados ou, mais geralmente, na língua Inglesa Data Science trazem um grande conjunto de técnicas que incluem pelo menos uma ampla gama de modelos estatísticos e de aprendizagem de máquina. Alguns livros chegam a trazer modelos para processamento de linguagem natural, análise de redes, dados espaciais entre outros. Esta grande quantidade de técnicas para análise de dados que faz parte do dia-a-dia do cientista de dados torna-se intimidante para profissionais de outras áreas que buscam um reposicionamento como cientistas de dados. Além disso, é um grande desafio desenhar cursos para tais profissionais, uma vez que não está claro quais são as técnicas que devem receber maior atenção e discutir todas as técnicas em uso pelos cientistas de dados é um trabalho impossível.\nPor outro lado, a grande maioria das técnicas e algoritmos utilizados em aplicações de ciência de dados são herdadas de outras áreas, principalmente da estatística e da ciência da computação, que por sua vez estão alicerçadas em disciplinas básicas da matemática do ensino superior, tais como, cálculo diferencial integral, álgebra matricial e métodos numéricos. Tais disciplinas são conhecidas por muitos profissionais das áreas de engenharia, economia, administração, tecnologia e análise de desenvolvimento de sistemas entre outros. Porém, a forma como tais disciplinas são ministradas nos diversos programas de graduação, bem como a junção destas disciplinas na criação de uma única técnica, torna difícil para tais profissionais identificarem suas aplicações nas ferramentas de análise de dados.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "ModuloI/index.html#estimação-de-densidades",
    "href": "ModuloI/index.html#estimação-de-densidades",
    "title": "Módulo I",
    "section": "",
    "text": "Definição. Seja \\(f\\) a derivada de \\(F\\); por isso pode-se expressar como \\[\nf(x)=\\lim_{h\\to 0}\\frac{F(x+h)-F(x-h)}{2h}\\cdot\n\\] Então, dizemos que \\(\\widehat{f}\\), definido por \\[\n\\widehat{f}(x)=\\frac{\\widehat{F}(x+h)-\\widehat{F}(x-h)}{2h},\n\\] é o histograma, sendo que \\(\\widehat{F}\\) é a função de distribuição empírica.\n\n\n\n\n\n\n\n\nTeorema\n\n\n\nSeja \\(f\\) a função de densidade da função de distribuição \\(F\\). Então, com probabilidade 1,\n\\[\n    \\widehat{f}(x)\\sim Binomial(n,p),\n\\] com \\(p=F(x+h)-F(x-h)\\). Assim, o comportamento assintótico do histograma pode ser derivado da distribuição binomial como \\[\n    \\mbox{E}\\big(\\widehat{f}(x)\\big)=\\frac{F(x+h)-F(x-h)}{2h}\n\\] e \\[\n    \\mbox{Var}\\big(\\widehat{f}(x)\\big)=\\frac{p(1-p)}{4nh^2}\\cdot\n\\]\n\n\n\n\n\n\n\n\n\nDefinição. O estimador kernel da função de densidade é dado por \\[\n\\widehat{f}(x)=\\frac{1}{nh_n}\\sum_{i=1}^n K\\Big( \\frac{x-X_i}{h_n}\\Big),\n\\] onde \\(K(\\cdot)\\) é uma função conhecida como kernel.\n\n\n\n\n\n\n\n\n\n\n\nTeorema\n\n\n\nSuponhamos que \\(f\\) seja contínua e limitada. Então o viés do estimador kernel de densidade converge a zero quando \\(h_n\\to 0\\), para todo \\(x\\).\n\n\n\n\n\n\n\n\n\nTeorema\n\n\n\nSuponhamos que \\(f\\) seja contínua três vezes diferenciável, com terceira derivada limitada na vizinhança de \\(x\\) e \\(K\\) satisfazendo \\[\n    \\int K^2(u)\\mbox{d}u&lt;\\infty \\qquad \\mbox{e} \\qquad \\int |u|^3K(u)\\mbox{d}u&lt;\\infty\\cdot\n\\]\n\n\nSe \\(h_n\\to 0\\) quando \\(n\\to\\infty\\), temos que \\[\n        \\mbox{viés}\\big(\\widehat{f}(x)\\big) = \\frac{h_n^2}{2}f''(x)\\int u^2K(u)\\mbox{d}u + o(h_n^2)\\cdot\n    \\]\n\n\nSe, além disso \\(nh_n\\to\\infty\\) quando \\(n\\to\\infty\\), então temos \\[\n        \\mbox{Var}\\big(\\widehat{f}(x)\\big) = \\frac{f(x)}{nh_n}\\int K^2(u)\\mbox{d}u + o\\big((nh_n)^{-1}\\big)\\cdot\n    \\]",
    "crumbs": [
      "Módulo I"
    ]
  },
  {
    "objectID": "ModuloI/index.html#exercícios",
    "href": "ModuloI/index.html#exercícios",
    "title": "Módulo I",
    "section": "Exercícios",
    "text": "Exercícios\n\nSeja \\(T(X_1,\\cdots,X_n)\\) uma estatística simétrica nas observaçóes. Mostre que \\(T\\) pode ser escrita como função das estatísticas de ordem. Por outro lado, se \\(T(X_1,\\cdots,X_n)\\) pode ser escrita como função das estatísticas de ordem, \\(T\\) é simétrica nas observações.\nSejam \\(X_1,X_2,\\cdots,X_m\\) e \\(Y_1,Y_2,\\cdots,Y_n\\) amostras independentes de duas distribuições absolutamente contínuas. Encontre o estimador não viciado de mínima variância de:\n\n\n\\(\\mbox{E}(XY)\\)\n\\(\\mbox{Var}(X+Y)\\)\n\n\nSeja \\((X_1,Y_1), (X_2,Y_2), \\cdots, (X_n,Y_n)\\) uma amostra aleatória com distribuição absolutamente contínua bivariada. Encontre o estimador não viciado de mínima variância de:\n\n\n\\(\\mbox{E}(XY)\\)\n\\(\\mbox{Var}(X+Y)\\)\n\n\nConsidere \\((\\mathcal{R},\\mathcal{B},P_\\theta)\\) um espaço de probabilidade e \\(\\mathcal{P}=\\{P_\\theta \\, : \\theta\\in\\Theta\\}\\). Seja \\(A\\) um elemento da \\(\\sigma\\)-álgebra de Borel e considere \\(d(\\theta)=P_\\theta(A)\\).\n\n\nA função \\(d\\) é estimável? Se sim, qual é o grau?\nEncontre o estimador não viciado de mínima variância de \\(d\\), baseado em uma amostra de tamanho \\(n\\) e assumindo que \\(\\mathcal{P}\\) seja a classe de todas as distribuições contínuas.",
    "crumbs": [
      "Módulo I"
    ]
  },
  {
    "objectID": "ModuloI/Aula01/index.html",
    "href": "ModuloI/Aula01/index.html",
    "title": "1  Estatística Não Paramétrica",
    "section": "",
    "text": "1.1 Introdução\nEm todos os problemas de inferência estatística considerados, assumimos que a distribuição da variável aleatória amostrada seja conhecida a menos, talvez, para alguns parâmetros. Na prática, entretanto, a forma funcional da distribuição é raramente ou nunca conhecida. Por conseguinte, é desejável conceber alguns procedimentos que estejam livres desta hipótese relativa à distribuição.\nPara entender a ideia de estatística não-paramétrica, primeiro requeremos uma compreensão de conceitos da estatística básica paramétrica. Conceitos elementares introduzem o conceito de teste de significância estatística com base na distribuição amostral de uma estatística particular. Em resumo, se tivermos um conhecimento básico da distribuição subjacente de uma variável, poderemos fazer previsões sobre como, em amostras repetidas de tamanho igual, essa estatística específica se comportará, isto é, como será distribuída.\nEstudamos aqui alguns procedimentos que são comumente referidos como métodos sem distribuição ou não paramétricos. O termo livre de distribuição refere-se ao fato de que nenhuma suposição é feita sobre a distribuição subjacente, exceto que a função de distribuição sendo amostrada seja absolutamente contínua ou puramente discreta. O termo não paramétrico refere-se ao fato de não haver parâmetros envolvidos no sentido tradicional do termo parâmetro utilizado até o momento.\nGrosseiramente falando, um procedimento não-paramétrico é um procedimento estatístico que possui certas propriedades desejáveis que mantêm suposições relativamente leves em relação às populações subjacentes das quais os dados são obtidos.\nNos dois exemplos seguintes mostramos distribuições conhecidas que são livres de parâmetros.\nCode\n# Definindo os valores para o eixo x1 e x2\nx1 &lt;- seq(-6, 6, length.out = 1000)\nx2 &lt;- seq(0, 10, length.out = 1000)\n\n# Graus de liberdade para a distribuição t-Student e qui-quadrado\ndf_t &lt;- 3\ndf_chi &lt;- 3\n\n# Calculando os valores de densidade das distribuições\ndensidade_t &lt;- dt(x1, df = df_t)\ndensidade_chi &lt;- dchisq(x2, df = df_chi)\n\n# Configurando o layout da plotagem\npar(mfrow = c(1, 2))\n\n# Plotando a distribuição t-Student\nplot(x1, densidade_t, type = \"l\", lwd = 2, col = \"blue\", \n     main = \"Distribuição t-Student (3)\",\n     xlab = \"x\", ylab = \"Densidade\")\n\n# Plotando a distribuição qui-quadrado\nplot(x2, densidade_chi, type = \"l\", lwd = 2, col = \"green\", \n     main = \"Distribuição Qui-Quadrado (3)\",\n     xlab = \"x\", ylab = \"Densidade\")\nO desenvolvimento repetido e contínuo de procedimentos estatísticos não paramétricos nas últimas décadas deve-se às seguintes vantagens de técnicas não paramétricas:\nMas têm desvantagens:",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Estatística Não Paramétrica</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula01/index.html#introdução",
    "href": "ModuloI/Aula01/index.html#introdução",
    "title": "1  Estatística Não Paramétrica",
    "section": "",
    "text": "Métodos não-paramétricos exigem poucas suposições sobre as populações subjacentes das quais os dados são obtidos. Em particular, os procedimentos não paramétricos abandonam a suposição tradicional de que as populações subjacentes sejam normais.\nOs procedimentos não paramétricos permitem que o usuário obtenha p-valores exatos para testes, probabilidades de cobertura exatas para intervalos de confiança, taxas exatas de erros experimentais para procedimentos de comparação múltipla e probabilidades exatas de cobertura para faixas de confiança sem confiar nas suposições de que as populações subjacentes sejam normais.\nAs técnicas não paramétricas são frequentemente, embora nem sempre, mais fáceis de aplicar do que as suas contrapartes teóricas normais.\nOs procedimentos não paramétricos são geralmente muito fáceis de entender.\nEmbora, à primeira vista, a maioria dos procedimentos não- paramétricos pareça sacrificar muito as informações básicas nas amostras, investigações de eficiência teórica mostraram que esse não é o caso. Normalmente, os procedimentos não-paramétricos são apenas ligeiramente menos eficientes do que os seus concorrentes de teoria normal quando as populações subjacentes são normais e podem ser moderadamente ou muito mais eficientes que os concorrentes quando as populações subjacentes não são normais.\n\n\n\nMétodos não paramétricos são relativamente insensíveis a observações distantes.\nOs procedimentos não paramétricos são aplicáveis em muitas situações em que os procedimentos teóricos normais não podem ser utilizados. Muitos procedimentos não-paramétricos exigem apenas as classificações das observações em vez da magnitude real das observações, enquanto os procedimentos paramétricos exigem as magnitudes.\nNem todos os procedimentos desenvolvidos na estatística paramétrica podem ser aplicados à estatística não-paramétrica.",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Estatística Não Paramétrica</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula02/index.html",
    "href": "ModuloI/Aula02/index.html",
    "title": "2  Estatísticas de Ordem",
    "section": "",
    "text": "2.1 Amostras aleatórias\nConsidere-se um experimento estatístico que culmina em desfechos \\(x\\), que são os valores assumidos por uma variável aleatória \\(X\\). Seja \\(F\\) a função de distribuição de \\(X\\). Na prática, \\(F\\) não será completamente conhecida, isto é, um ou mais parâmetros associados com \\(F\\) serão desconhecidos. O trabalho de um estatístico é estimar esses parâmetros desconhecidos ou testar a validade de certas afirmações sobre eles. Ele pode, por exemplo, obter \\(n\\) observações independentes de \\(X\\). Isso significa que ele observa \\(n\\) valores \\(x1, x2, \\cdots , x_n\\) assumidos da variável aleatória \\(X\\). Cada \\(x_i\\) pode ser considerado como o valor assumido pela variável aleatória \\(X_i, i = 1, 2, \\cdots , n\\) onde \\(X_1, X_2, \\cdots, X_n\\) são variáveis aleatórias independentes com distribuição comum \\(F\\) . Os valores observados \\((x_1, x_2, \\cdots, x_n)\\) são então valores assumidos por \\((X_1, X_2, \\cdots, X_n)\\). O conjunto \\((X_1, X_2, \\cdots , X_n)\\) é, então, uma amostra de tamanho \\(n\\) da distribuição da população \\(F\\) . O conjunto de \\(n\\) valores \\(x_1, x_2, \\cdots , x_n\\) é chamado de uma realização ou estimativa da amostra. Note-se que os possíveis valores do vector aleatório \\((X_1, X_2, \\cdots , X_n)\\) podem ser olhados como pontos em \\(\\mathbb{R}^n\\), os quais podem ser chamados de elementos do espaço amostral. Na prática podemos não observar \\(x_1, x_2, \\cdots, x_n\\) mas alguma função \\(g(x_1, x_2, \\cdots , x_n)\\). Então \\(g(x_1, x_2, \\cdots , x_n)\\) serão considerados os valores assumidos pela variável aleatória \\(g(X)\\).\nVamos agora formalizar esses conceitos.\nSe \\(X_1, X_2, \\cdots , X_n\\) é uma amostra aleatória de \\(F (\\cdot; \\theta)\\), a função de distribuição conjunta é dada por:\n\\[F(x_1, \\cdots, x_n; \\theta) = \\prod_{i=1}^{n} F(x_i; \\theta)\\]\nSegundo esta definição cada uma das variáveis na amostra isoladamente é uma estatística assim como funções destas que, eventualmente, podem não fornecer informações úteis. Duas das estatísticas mais comumente utilizadas são mostradas no exemplo a seguir.\nDeve-se lembrar que as estatísticas amostrais apresentadas neste exemplo \\(\\overline{X}_n, S_{n}^{2}\\) e outras que irão definir-se posteriormente são variáveis aleatórias, com todas as consequências que isso implica, enquanto os parâmetros populacionais \\(\\mu, \\sigma^2\\) e assim por diante são constantes fixas, que podem ser desconhecidas.\nExemplo. Seja \\(X \\sim Bernoulli(p)\\), onde \\(p\\) é desconhecido. A função de distribuição de \\(X\\), mostrada na Figura 2.1, é dada por\n\\[F(x) = p\\delta (x − 1) + (1 − p)\\delta(x),    x \\in \\mathbb{R},\\] onde a função \\(\\delta(\\cdot)\\) foi definida em (1.2) como \\(\\delta(x) = \\begin{cases} 1, \\ x \\ \\geq \\ 0, \\\\ 0, \\ x \\ &lt; 0 \\end{cases}\\), chamada de função delta.\nSuponha que cinco observações independentes de \\(X\\) sejam 0, 1, 1, 1, 0. Então 0, 1, 1, 1, 0 é uma realização da amostra \\(X_1, X_2, \\cdots , X_5\\). A estimativa da média amostral é\n\\[\\overline{x}_5 = \\displaystyle \\frac{0 + 1 + 1 + 1 + 0}{5} = 0, 6\\] o qual é o valor assumido pela variável aleatória \\(\\overline{X}_n\\). A estimativa da variância amostral é \\[S_{5}^{2} = \\sum_{i=1}{5} \\displaystyle \\frac{(x_i - \\overline{x}_5)}{5 - 1}= \\displaystyle \\frac{2 \\ \\times (0,6)^2 \\ + \\ 3 \\ \\times (0,4)^2}{4}= 0,3\\]\nsendo este o valor assumido pela variável aleatória \\(S_{5}^{2}\\).\nExemplo. Seja \\(X \\sim N (\\mu, \\sigma^2)\\), \\(\\mu\\) conhecida, \\(\\sigma^2\\) desconhecido e \\(X_1, \\cdots , X_n\\) uma amostra aleatória dessa distribuição. De acordo com nossa definição, a função \\(\\sum_{i=1}^{n} X_{i} / \\sigma^2\\) não é uma estatística. Suponha que cinco observações de \\(X\\) -0,864; 0,561; 2.355; 0,582 e -0,774. Então, a estimativa da média amostral é 0.372 e a estimativa da variância amostral é 1.648.",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula02/index.html#amostras-aleatórias",
    "href": "ModuloI/Aula02/index.html#amostras-aleatórias",
    "title": "2  Estatísticas de Ordem",
    "section": "",
    "text": "Definição. Seja \\(X\\) uma variável aleatória com função de distribuição \\(F\\) e \\(X_1, \\cdots, X_n\\) variáveis aleatórias independentes com distribuição comum \\(F\\). Chamaremos a coleção \\(X_1, \\cdots, X_n\\) de uma amostra aletória de tamanho \\(n\\) de \\(F\\) ou simplesmente como \\(n\\) observações independentes de \\(X\\).\n\n\n\n\nDefinição. Sejam \\(X_1, X_2, \\cdots, X_n\\) \\(n\\) observações independentes da variável aleatória \\(X\\) e seja \\(g: \\mathbb{R}^n \\to \\mathbb{R}\\) uma função real derivável. Então a variável aleatória \\(g(X_1, X_2, \\cdots, X_n)\\) é chamada de estatística, desde que não dependa de parâmetros desconhecidos.\n\n\n\nDefinição. Seja \\(X_1, X_2, \\cdots, X_n\\) uma amostra aleatória da função de distribuição \\(F\\). A estatística \\[\\overline{X}_n = \\sum_{i=1}^{n} \\displaystyle \\frac{Xi}{n},\\] é chamada de média amostral e a estatística \\[S_{n}^{2} = \\sum_{i=1}^{n} \\displaystyle \\frac{(X_i - \\overline{X}_n)^2}{n-1}\\] é chama de variância amostral.\n\n\n\n\n\n\n\n\n\n\nFigura 2.1: Representação da função de distribuição Bernoulli para três valores do parâmetro \\(p\\) = 0.3, 0.5 e 0.8. Observe que nesta curva a reta no intervalo (0, 1) depende de 1 - \\(p\\), isso porque a função \\(\\delta\\) é sempre zero para \\(x\\) - 1 nesse intervalo.",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula02/index.html#estatísticas-de-ordem",
    "href": "ModuloI/Aula02/index.html#estatísticas-de-ordem",
    "title": "2  Estatísticas de Ordem",
    "section": "2.2 Estatísticas de ordem",
    "text": "2.2 Estatísticas de ordem\nSeja \\((X_1, X_2, \\cdots , X_n)\\) um vetor aleatório n-dimensional e \\((x_1, x_2, \\cdots , x_n)\\) uma \\(n\\)-tupla assumida por \\((X_1, X_2, \\cdots , X_n)\\). Vamos organizar \\(x_1, x_2, \\cdots , x_n\\) em ordem crescente de magnitude, para que \\[x_{(1)}\\le x_{(2)} \\le \\cdots ≤ x_{(n)},\\] onde \\(x_{(1)}\\) = min\\((x_1, x_2, \\cdots , x_n)\\), \\(x_{(2)}\\) é o segundo menor valor em \\(x_1, \\cdots , x_n\\) e assim por diante, \\(x_{(n)}\\) = max\\((x_1, \\cdots , x_n)\\). Se quaisquer dois \\(x_i\\), \\(x_j\\) forem iguais, a ordem não importa.\n\nDefinição. A função \\(X_{(k)}\\) de \\((X_1, \\cdots ,X_n)\\) que assume o valor \\(x_{(k)}\\) em cada possível sequência \\((x_1, x_2, \\cdots , x_n)\\) de valores assumidos por \\((X_1,X_2, \\cdots , X_n)\\) é conhecida como a \\(k\\)-ésima estatística de ordem ou a estatística de ordem \\(k\\). O conjunto \\((X_{(1)},X_{(2)}, \\cdots , X_{(n)})\\) é chamado de estatísticas de ordem para \\((X_1, X_2, \\cdots , X_n)\\).\n\nExemplo. Consideremos \\(X_1\\), \\(X_2\\), \\(X_3\\) três variáveis aleatórias discretas de maneira que, \\(X_1\\) e \\(X_3\\) sejam tais que assumam somente valores 0, 1 e que \\(X_2\\) assuma valores 1, 2, 3. O vetor aleatório \\((X_1\\), \\(X_2\\), \\(X_3)\\) assume os valores: (0, 1, 0), (0, 2, 0), (0, 3, 0), (0, 1, 1), (0, 2, 1), (0, 3, 1), (1, 1, 0), (1, 2, 0), (1, 3, 0), (1, 1, 1), (1, 2, 1) e (1, 3, 1). Então \\(X_{(1)}\\) assume somente valores 0 ou 1; \\(X_{(2)}\\) assume somente valores 0 ou 1 e \\(X_{(3)}\\) assume somente valores 1, 2 ou 3.\n\n\n\n\n\n\nTeorema 2.1\n\n\n\nSeja \\((X_{(1)}, X_{(2)}, \\cdots , X_{(n)})\\) um vetor aleatório de dimensão \\(n\\) e seja \\(X_{(k)}, 1 \\le k \\le n\\), a \\(k\\)-ésima estatística de ordem. Então \\(X_{(k)}\\) é também uma variável aleatória.\n\n\nExercício. Na apresentação dos resultados a seguir assumiremos que \\(X_1, X_2, \\cdots , X_n\\) são variáveis aleatórias independentes e igualmente distribuídas contínuas com função de densidade \\(f\\) . Seja \\(\\{ X_{(1)}, X_{(2)}, \\cdots , X_{(n)} \\}\\) o conjunto das estatística de ordem para \\(X_1, X_2, \\cdots , X_n\\). Dado que todas as \\(X_i\\) são contínuas segue que, com probabilidade 1 \\[X_{(1)} \\le X_{(2)} \\le \\cdots \\le X_{(n)}·\\]\n\n2.2.1 Propriedades das estatísticas de ordem\nComeçaremos o estudo das propriedades encontrando a função de densidade conjunta de \\((X_{(1)}, X_{(2)}, \\cdots , X_{(n)})\\).\n\n\n\n\n\n\nTeorema 2.2\n\n\n\nSejam \\(X_1, \\cdots, X_n\\) variáveis aleatórias contínuas independentes, igualmente distríbuidas com densidade \\(f\\). A função de desindade conjunta de \\((X_{(1)}, \\cdots, X_{(n)})\\) é dada por \\[\nf(x_{(1)}, \\ldots, x_{(n)}) =\n\\begin{cases}\nn! \\prod\\limits_{i=1}^{n} f(x_{(i)}), & \\text{se } x_{(1)} &lt; x_{(2)} &lt; \\cdots &lt; x_{(n)} \\\\\n0, & \\text{caso contrário}\n\\end{cases}.\n\\]\n\n\nDemonstração: A transformação de \\((X_1, \\cdots , X_n)\\) a \\((X_{(1)}, \\cdots , X_{(n)})\\) não é biunívoca. De fato, existem um total de \\(n!\\) possíveis arranjos de \\(x_1, \\cdots , x_n\\) em ordem crescente de magnitude. Assim, existem \\(n!\\) inversas para a transformação.\nPor exemplo, uma das \\(n!\\) permutações pode ser \\[\nx_4 &lt; x_1 &lt; x_{n−1} &lt; x_3 &lt; \\cdots &lt; x_n &lt; x_2·\n\\]\nA inversa correspondente é \\[\nx_4 = x_{(1)}, x_1 = x_{(2)}, \\ x_{n−1} = x_{(3)}, \\ x_3 = x_{(4)} \\cdots x_n = x_{(n−1)}, \\ x_2 = x_{(n)}·\n\\] O determinante Jacobiano desta transformação é a matriz \\(n \\times n\\) identidade com as colunas reorganizadas, isto devido a que cada \\(x_{(i)}\\) é igual a uma, e somente uma, das \\(x_1, x_2, \\cdots , x_n\\). Portanto \\(J = \\pm 1\\) e\n\\[\nf (x_{(2)}, \\ x_{(n)}, \\ x_{(4)}, \\ x_{(1)}, \\ \\cdots , \\ x_{(3)}, \\ x_{(n−1)}) \\ \\mid J \\mid =\n\\prod\\limits_{i=1}^{n} \\ f(x_{(i)}),\n\\]\nquando \\(x_{(1)} &lt; x_{(2)} &lt; \\cdots &lt; x_{(n)}\\). A mesma expressão é válida para cada um dos \\(n!\\) arranjos. Segue então que\n\\[\n\\begin{align*}\nf(x_{(1)}, \\ldots, x_{(n)}) &= \\sum \\prod\\limits_{i=1}^{n} f(x_{(i)}) \\\\\n&\\ \\ \\ \\ \\ \\ \\text{Todas as } n! \\text{ permutações} \\\\\n& = \\begin{cases}\nn! \\prod\\limits_{i=1}^{n} f(x_{(i)}), & \\text{se } x_{(1)} &lt; x_{(2)} &lt; \\cdots &lt; x_{(n)} \\\\\n0, & \\text{caso contrário}\n\\end{cases}.\n\\end{align*}\n\\]\nExemplo. Sejam \\(X_1, \\cdots , X_n\\) variáveis aleatórias independentes com função de densidade comum \\[\nf(x) =\n\\begin{cases}\n1, & \\text{se } 0 &lt; x &lt; 1 \\\\\n0, & \\text{caso contrário}\n\\end{cases}.\n\\] Então a função de densidade conjunta de \\(X_{(1)}, X_{(2)}, \\cdots , X_{(n)}\\) é \\[\nf(x_{(1)}, \\ \\cdots, \\ x_{(n)}) =\n\\begin{cases}\nn!, & \\text{se } 0 &lt; x_{(1)} &lt; x_{(2)} &lt; \\cdots &lt; x_{(n)} \\\\\n0, & \\text{caso contrário}\n\\end{cases}.\n\\]\nEstamos confiados que como resultado do Teorema 2.2 temos funções de densidade. Vejamos neste exemplo se isso é realmente acontece. Consideremos, para simplificar, o caso \\(n\\) = 3 e verifiquemos se a integral da função de densidade é 1. Então\n\\[\n\\begin{align*}\n\\int \\int\\limits_\\mathbb{R} \\int f(x_{(1)},x_{(2)},x_{(3)}) \\ dx_{(1)}dx_{(2)}dx_{(3)})\n& = 6 \\int_{0}^1 \\left[\\int_{x_{(1)}}^1 \\left(\\int_{x_{(2)}}^1 dx_{(3)} \\right) dx_{(2)} \\right] dx_{(1)} \\\\\n& = 6 \\int_{0}^1 \\left[\\int_{x_{(1)}}^1 \\left(1 - x_{(2)} \\right) dx_{(2)} \\right] dx_{(1)} \\\\\n& = 6 \\int_{0}^1 \\left[\\frac{1}{2} - x_{(1}) + \\frac{x^2_{(1)}}{2} \\right] dx_{(1)} = 1. \\\\\n\\end{align*}\n\\]\nUm detalhe interessante é que esta e outras propriedades demonstradas aqui somente são válidas quando as variáveis aleatórias são contínuas. Isso não significa que estatísticas de ordem não possam ser definidas no caso discreto. O que estamos dizendo é que estas propriedades somente podem ser demonstradas no caso contínuo.\nExemplo. Consideremos a situação em que temos somente três variáveis aleatórias independentes \\(X_1\\), \\(X_2\\) e \\(X_3\\) com distribuição geométrica de parâmetro \\(p\\), isto é,\n\\[\nP (X = x; p) = (1 − p)p^x, \\ \\ \\ \\ \\    x = 0, 1, 2, \\cdots\n\\] Encontremos \\(P (X_{(1)} &lt; X_{(2)} &lt; X_{(3)})\\). Nesta situação a probabilidade requerida pode ser escrita como: \\[\n\\begin{align*}\nP (X_{(1)} &lt; X_{(2)} &lt; X_{(3)})  =  1 − P (X_1 = X_2 \\neq X_3) − P (X_1 = X_3 \\neq X_2) \\\\\n−P (X_2 = X_3 \\neq X_1) − P (X_1 = X_2 = X_3)\n\\end{align*}\n\\] a qual pode ser escrita como \\[\n\\begin{align*}\nP (X_{(1)} &lt; X_{(2)} &lt; X_{(3)})\n& = 1 − 3P (X_1 = X_2 \\neq X_3) − P (X_1 = X_2 = X_3) \\\\\n& = 1 − 3 [P (X_1 = X_2) − P (X_1 = X_2 = X_3)] − P (X_1 = X_2 = X_3) \\\\\n& = 1 − 3P (X_1 = X_2) + 2P (X_1 = X_2 = X_3)· \\\\\n\\end{align*}\n\\]\nNão é difícil perceber que \\[\nP(X_1 = X_2) = \\frac{(1-p)^2}{1-p^2},\n\\]\ne que \\[\nP(X_1 = X_2 = X_3) = \\frac{(1-p)^3}{1-p^3},\n\\]\ndo qual obtemos que \\[\nP(X_{(1)} = X_{(2)} = X_{(3)}) = \\frac{6p^3}{(1-p)(1+p+p^2)}.\n\\] As propriedades das estatísticas de ordem que serão demonstradas valerão somente caso as variáveis sejam contínuas. Isto deve-se a que, caso as variáveis sejam discretas, a probabilidade\n\\[\nP (X_{(1)} = X_{(2)} = \\cdots = X_{(n)}) \\neq 0,\n\\]\ncomo vai ser mostrado no seguinte exemplo. Acontece que o fato da probabilidade das estatística de ordem poderem coincidir, com probabilidade diferente de zero, altera a estrutura da demonstração e não nos permite obtermos estes resultados para o caso discreto.\nExemplo. Sejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias independentes assumindo somente 0 e 1 com probabilidade 1/2. Observemos que \\[\n\\begin{align*}\nP(X_{(1)} = X_{(2)} = \\cdots = X_{(n)})\n& = \\prod\\limits_{k=1}^{n} P(X_{(k)} = 0) + \\prod\\limits_{k=1}^{n} P(X_{(k)} = 1)  \\\\\n& = \\prod\\limits_{k=1}^{n} P(X_{(k)} = 0) + \\prod\\limits_{k=1}^{n} P(X_{k} = 1) = \\frac{1}{2^{n-1}} . \\\\\n\\end{align*}\n\\]\nEstudemos agora o comportamento marginal, ou seja, nos interessa agora encontrar a função de distribuição marginal de cada estatística de ordem.\n\n\n\n\n\n\nTeorema 2.3\n\n\n\nSejam \\(X_1, \\cdots, X_n\\) variáveis aleatórias contínuas independentes e igualmente distribuídas e \\((X_{(1)}, \\cdots, X_{(n)})\\) as estatísticas de ordem. A função de densidade marginal de \\(X_{(r)}\\) é dada por \\[\nf_r(x_{(r)}) = \\frac{n!}{(r-1)!(n-r)!}[F(x_{(r)})]^{r-1}[1-F(x_{(r)})]^{n-r}f(x_{(r)}),\n\\] onde \\(F\\) é a função de distribuição comum de \\(X_1, \\cdots, X_n\\).\n\n\nDemonstração : Partimos da expressão da função de densidade conjunta das estatísticas de ordem obtida no Teorema 2.2. Então,\n$$ \\[\\begin{align*}\nf_r(x_{(r)})\n& = n!f(x_{(r)})  \n\\int_{-\\infty}^{x_{(r)}} \\int_{-\\infty}^{x_{(r-1)}} \\cdots\n\\int_{-\\infty}^{x_{(2)}} \\int_{x_{(r)}}^{+\\infty} \\int_{x_{(r+1)}}^{+\\infty} \\cdots\n\\int_{x_{(n-1)}}^{+\\infty}\n\\prod\\limits_{i \\neq r}^{n} f(t_i) \\\n\\text{d}t_n \\cdots\\text{d}t_{r+1} \\ \\text{d}t_{1} \\cdots \\text{d}t_{r-1}  \\\\\n\n& = n!f(x_{(r)})\n\\frac{[1-F(x_{(r)})]^{n-r}}{(n-r)!}\n\\int_{-\\infty}^{x_{(r)}} \\cdots\n\\int_{x_{(-\\infty)}}^{x_{(2)}}\n\\prod\\limits_{i =1}^{r-1} f(t_i) \\ \\text{d}t_i \\\\\n\n& = n!f(x_{(r)})\n\\frac{[1-F(x_{(r)})]^{n-r}}{(n-r)!}\n\\frac{[F(x_{(r)})]^{r-1}}\n{(r-1)!}.\n\n\\end{align*}\\]\\end{align*} $$\nComo utilidade deste teorema podemos mencionar o fato de agora podermos encontrar os momentos das estatística de ordem. Faremos isso como consequência do seguinte exemplo.\nExemplo. Sejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias independentes \\(U\\) (0, 1). Então $$ f_r(x_{(r)}) =\n\\[\\begin{cases}\n\\frac{n!}{(r-1)!(n-r)!} x_{(r)}^{r-1}(1-x_{(r)})^{n-r},\n& \\text{se } 0 &lt; x_{(r)} &lt; 1 \\\\\n\n& \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  (1 \\leq r \\leq n) \\\\\n0, & \\text{caso contrário}\n\\end{cases}\\]\n. $$\nObservemos que, na situação do exemplo acima,\n\\[\nX_{(r)} \\sim \\beta(r, n − r + 1),\n\\]\nlogo, valem os resultados da distribuição Beta e, por exemplo,\n\\[\nE(X_{(r)}) = r/(n + 1)·\n\\]\nPara uma densidade qualquer e somente quatro variáveis aleatórias a forma da densidade marginal, de uma qualquer estatística de ordem, é mostrada no seguinte exemplo.\nExemplo. Sejam \\(X_1, X_2, X_3 ,X_4\\) variáveis aleatórias independentes com densidade comum \\(f\\). A função de densidade conjunta das estatísticas de ordem \\(X_{(1)}, X_{(2)}, X_{(3)}, X_{(4)}\\) é\n$$ f(x_{(1)}, x_{(2)}, x_{(3)}, x_{(4)}) =\n\\[\\begin{cases}\n4!f (x_{(1)})f (x_{(2)})f (x_{(3)})f (x_{(4)}),\n& \\text{se }    x_{(1)} &lt; x_{(2)} &lt; x_{(3)} &lt; x_{(4)} \\\\\n\n0,  \n& \\text{caso contrário}\n\\end{cases}\\]\n. $$\nVamos calcular a função de densidade marginal de \\(X_{(2)}\\). Temos que, se \\(x_{(1)} &lt; x_{(2)} &lt; x_{(3)} &lt; x_{(4)}\\)\n$$ \\[\\begin{align*}\nf2(x_{(2)})\n& =  4! \\int \\int \\int \\int f(t_1) f(x_{(2)}) f(t_3) f(t_4)\n\\ \\text{d}t_1 \\ \\text{d}t_3 \\ \\text{d}t_4 \\\\\n\n& =  4! f(x_{(2)})\n\\int_{-\\infty}^{x_{(2)}}\n\\int_{2}^{+\\infty}\n\\left[\\int_{t_3}^{+\\infty} f(t_4) \\ \\text{d}t_4\\right]\nf(t_3) f(t_1) \\ \\text{d}t_3 \\ \\text{d}t_1  \\\\\n\n& =  4! f(x_{(2)})\n\\int_{-\\infty}^{x_{(2)}}\n\\Biggl\\{\n\\int_{x_{(2)}}^{+\\infty}[1 - F(t_3)]f(t_3) \\text{d}t_3\n\\Biggl\\}\nf{(t_1)} \\text{d}t_1\\\\\n\n& =  4! f(x_{(2)})\n\\int_{-\\infty}^{x_{(2)}}\n\\frac{[1-F(x_{(2)})]^2}{2}\nf(t_1) \\ \\text{d}t_1 =\n4! f(x_{(2)})\n\\frac{[1-F(x_{(2)})]^2}{2}\nF(x_{(2)})\n\n·\n\\end{align*}\\] $$\nEvidentemente, a expressão acima coincide com o resultado apresentado no Teorema 2.3.",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula02/index.html#momentos-amostrais",
    "href": "ModuloI/Aula02/index.html#momentos-amostrais",
    "title": "2  Estatísticas de Ordem",
    "section": "2.4 Momentos amostrais",
    "text": "2.4 Momentos amostrais\nNesta seção vamos estudar algumas estatísticas amostrais comumente utilizadas e suas distribuições.\nObservemos que nFn(x) é o número de Xk (1 ≤ k ≤ n) menores ou iguais a x. Se X_{(1)}, X_{(2)}, , X_{(n)} são as estatísticas de ordem de \\(X_1, X_2, \\cdots , X_n\\) então claramente\nFn(x) =  \nk , se X n\n\n\n\n≤ x &lt; X\n(k+1)\n, (k = 1, 2, , n − 1)\n· (2.11)\n 1, se x ≥ X_{(n)}\ncom esperança e variância\nVar[Fb\nE[Fn(x)] = \\(F\\) (x) (2.13)\nF (x)[1 − \\(F\\) (x)]\nDemonstração : Dado que δ(x − Xi), i = 1, 2, , n são variáveis aleatórias independentes igualmente distribuídas cada uma com função de probabilidade P [δ(x − Xi) = 1] = P (x − Xi ≥ 0) = \\(F\\) (x) e P [δ(x − Xi) = 0] = 1 − \\(F\\) (x), sua soma nF ∗(x) é uma variável aleatória com distribuição Binomial(n, p), onde p = \\(F\\) (x). As relações (2.12), (2.13) e (2.14) seguem-se imediatamente.\nDemonstração :\nE´ uma consequência da Lei dos Grandes Números .\nCorolário 2.12\nonde Z ∼ N (0, 1).\n√n[F (x) F (x)] √F (x)[1 − \\(F\\) (x)] −→ Z quando n → ∞,\nDemonstração :\nE´ consequência do Teorema do Limite Central.\nExemplo 2.15\nVamos apresentar o conceito de função distribuição empírica no caso de termos uma amostra aleatória da distribuição N (0, 1). A lista de comandos na linguagem de programação R está disponível abaixo. O primeiro comando destina-se a fixar o gerador de amostras e, assim, em qualquer momento podemos obter a mesma amostra aleatória. Na Figura 2.2 mostramos a forma da distribuição empírica, de três formas diferentes, para uma amostra de tamanho 12. A representação da função de distribuição empírica é realizada permitindo escolher qual utilizar segundo o agrado.\nlwd = 2\n−1.5 −1.0 −0.5 0.0 0.5\nx\n−1.5 −1.0 −0.5 0.0 0.5\nx\n−1.5 −1.0 −0.5 0.0 0.5\nx\nFigura 2.2: Representação da função de distribuição amostral ou empírica, de três formas diferentes, para uma amostra normal padrão de tamanho 12.\nA linhas de comando a seguir permitiram-nos gerar os gráficos na Figura 2.2: construímos : set.seed(5739); x=rnorm(12); Fn=ecdf(x) par(mar=c(5,4,3,1), cex=0.9) plot(Fn, main=““) plot(Fn, verticals = TRUE, do.points = FALSE, main=”“) plot(Fn , lwd = 2, main=”“); mtext(”lwd = 2”, adj = 1) xx=unique(sort(c(seq(-3, 2, length = 201), knots(Fn12)))) lines(xx, Fn(xx), col = “blue”) abline(v = knots(Fn), lty = 2, col = “gray70”) Observemos que a convergência da distribuição empírica, segundo o Teorema 2.10, é para cada valor de x. E´ possível fazer uma demonstração da convergência em probabilidade simultaneamente para todos os x, ou seja, da convergência uniforme.\nDemonstração : Seja ϵ &gt; 0. Escolhemos um inteiro k &gt; 1/ϵ e números −∞ = x0 &lt; x1 ≤ x2 ≤ ≤ xk−1 &lt; xk = ∞, tais que \\(F\\) (x−) ≤ j/k ≤ \\(F\\) (xj), para j = 1, , k − 1. Observe que se xj−1 &lt; xj, então\nPela Lei dos Grandes Números\nF (x−) − \\(F\\) (xj−1) ≤ ϵ·\nq.c. Fn(xj) −→ \\(F\\) (xj) e — q.c. −\npara j = 1, , k − 1. Consequentemente,\nFbn(xj ) −→ \\(F\\) (xj ),\n∗ − q.c. ∆n = max{|Fbn(xj) − \\(F\\) (xj)|, |Fn (xj ) − \\(F\\) (xj)|, j = 1, , k − 1} −→ 0·\nSeja x arbitrário e encontremos j tal que xj−1 &lt; x ≤ xj. Então, Fbn(x) − \\(F\\) (x) ≤ Fbn(x−) − \\(F\\) (xj−1) ≤ Fbn(x−) − \\(F\\) (x−) + ϵ,\ne\nIsto implica que\nFbn(x) − \\(F\\) (x) ≥ Fbn(xj−1) − \\(F\\) (x−) ≥ Fbn(xj−1) − \\(F\\) (xj−1) − ϵ·\nq.c. sup |Fn(x) F (x)| ∆n + ϵ ϵ· x Como isso vale para todo ϵ &gt; 0, o teorema segue.\nAgora, dado que \\(F\\) ∗(x) tem pontos de salto em Xi, i = 1, 2, , n é claro que existem todos os momentos de \\(F\\) ∗(x). Vamos considerar alguns valores típicos da função de distribuição \\(F\\) , chamados de estatísticas amostrais. Escrevamos a = 1 ∑ Xk, (2.15)\npara os momentos de ordem k ao redor do 0 (zero). Aqui ak, serão chamados de momentos amostrais de ordem k. Com esta notação\nO momento amostral central é definido por\nn a1 = Xi n i=1\n= X·\nb = 1 ∑(X − a )k = 1 ∑(X\n— X) · (2.16)\nLogicamente,\nk n i 1 i=1\nn i i=1\nb = 0 e b\n= (n − 1 ) S2·\nComo mencionado anteriormente, não chamamos b2 a variaˆncia amostral. S2\nserá chamada como a variaˆncia\namostral por razões que se tornarão claras posteriormente. Temos que b2 = a2 − a2· Para a função geradora de momentos de Fn podemos afirmar que n\nMFbn\n\n= 1 etXi · n\n\ni=1\nDefinições similares são realizadas para momentos amostrais de distribuições multivariadas. Por exemplo, se (X1, Y2), (X2, Y2), , (Xn, Yn) é uma amostra de uma distribuição bivariada, podemos escrever n n X = 1 ∑ X , Y = 1 ∑ Y\npara as duas médias amostrais e para os momentos de segunda ordem centrais escrevemos\nb20\nn = (Xi n i=1\n— X) , b02\nn = (Yi n i=1\n— Y ) ,\nMais uma vez, escrevemos\nb11\nn\nn = (Xi n i=1\n— X)(Yi\n— Y )·\nn\nS2 = 1 ∑(X\n— X)2, S2 = 1 ∑(Y\n— Y ) , (2.17)\npara as duas variaˆncias amostrais e para a covariância amostral utilizamos n\nS11\n= 1 (X n − 1 i=1\n— X)(Yi\n— Y )· (2.18)\nEm particular, o coeficiente de correlação amostral é definido por b11 S11\nR = 20\nb02\n= · S1S2\nPode ser demonstrado que |R| ≤ 1 e que os valores extremos ±1 ocorrem somente quando todos os pontos amostrais (X1, Y2), (X2, Y2), , (Xn, Yn) estão alinhados. Correspondendo a uma amostra \\(X_1, X_2, \\cdots , X_n\\) de observações em \\(F\\) , p-ésimo quantil amostral é definido como o p-ésimo quantil da função de distribuição amostral, ou seja, como \\(F\\) −1. Os quatis amostrais são definidos de maneira similar. Então, se 0 &lt; p &lt; 1, o quantil amostral de ordem p,\nr = [np] se n é um número par [np] + 1 se n é um número ímpar\n· (2.19)\nComo usual, [x] denota o maior inteiro x. Observe que, se [n] for par, podemos escolher qualquer valor entre X([np]) e X([np]+1) como o p-ésimo quantil amostral. Então, se p = 1 e n par podemos escolher qualquer valor entre X(n/2) e X(n/2+1), os dois valores do meio, como a mediana amostral. Habitualmente é escolhido o ponto médio. Assim, a mediana amostral é definida como\nξb1/2 = \nX((n+1)/2) se n é ímpar X(n/2) + X((n/2)+1) se n é par\n· (2.20)\nObserve que\n2 [n + 1] = (n + 1 )\n2 2 se n é ímpar. Consideraremos agora os momentos de características amostrais. Nos seguintes desenvolvimentos denotaremos E(Xk) = mk e E[(X µ)k] = µk como os momentos populacionais e os momentos populacionais centrais de k-ésima ordem, respectivamente. Nas situações onde utilizamos mk ou µk assumiremos que estes existem. Também, σ2 representará a variância populacional.\nDemonstração : Para provar (2.23) observemos que\n(∑n\nXi = ∑\nX3 + 3 ∑ ∑\nX2Xk + ∑ ∑ ∑ XiXjXk,\ni=1\ni=1\ni=1 j=1 j̸=k\ni=1 j=1 k=1 i̸=j, i̸=k j̸=k\ndesta expressão obtemos o resultado em (2.23). Similarmente\n(∑n )4\n( n )  n n n\n\n∑ ∑ ∑\nXi =\n∑ Xi ∑ X3 + 3 ∑ ∑ X2Xj +\ni j k\ni=1\ni=1\nn\n i=1\ni i=1 j=1 i̸=j n n\ni=1 j=1 k=1 i̸=j, i̸=k j̸=k\n= ∑ X4 + 4 ∑ ∑ XiX3 + 3 ∑ ∑ X2X2\ni i=1\ni=1 j=1 i̸=j\nj i j i=1 j=1 i̸=j\nn n n n n n n = +6 ∑ ∑ ∑ X2XjXk + ∑ ∑ ∑ ∑ XiXjXkXl·\ni=1 j=1 k=1 i̸=j, i̸=k j̸=k\ni=1 j=1 k=1 l=1 i̸=j, i̸=k, i̸=l j̸=k, j̸=l k̸=l\nUm detalhe importante é que os momentos centrais podem ser calculados a partir dos momentos, por exemplo, µ2 = E[(X − µ)2] = m2 − µ2, µ3 = E[(X − µ)3] = m3 − 3µm2 + 2µ3\ne assim por diante. Sabemos agora como calcular os momentos, até quarta ordem, de X. Vejamos a seguir como calcular os momentos centrais.\nDemonstração : Temos que µ (X) = E(X − µ)3 = E {∑n\n(X − µ)3} = ∑n\nE(X\n3 µ3 — µ) = ·\n3\nNo caso do quarto momento central\nn3 i=1 i\n1\nn3\n{∑n\ni=1 i n2\n}\nda qual obtemos que\nµ (X) = E(X µ)4 = E n4\ni=1\n(Xi − µ)4 ,\n1 µ4(X) =\nE(Xi − µ)4 +\n_{(4)} 1 + ∑ ∑\nE{(Xi − µ)2(Xj − µ)2}·\nn4 i=1\n2 n4\ni=1 j=1 i̸=j\nDesenvolvendo adequadamente chegamos ao resultado em (2.26).\nExemplo 2.16\n, Xn uma amostra aleatória da distribuição Gamma(α, β). Sabemos da Seção 1.2 que E(X) = αβ, Var(X) = αβ2\nmk = βk(α + k − 1)(α + k − 2) α, k ≥ 1· αβ2 E(X) = αβ, Var(X) = n 1 1 µ (X) = µ = (6α3β3 + 3α2β3 + 2αβ3)· 3 n2 3 n\nAté o momento estudamos como calcular os momentos da média amostral. Mais complexo é obter expressões para os momentos da variância amostral S2. O teorema a seguir dedica-se ao objetivo de encontrarmos expressões, até segunda ordem, dos momentos amostrais centrais. Como consequência deste resultado obtemos os momentos da variaˆncia amostral.\nDemonstração : Temos que\nn E(b2) = E n i=1\nX2 n2\nn 2 Xi i=1\n= m2 −\n1  n E \nX2 + ∑\n∑ X2Xj\nAgora\n= m2\n1 — n2 [nm2\n\nn(n − 1)µ2] = ( n − 1 ) (m\n\n— µ )·\nn2b2 =\nn\ni=1\n2\n(Xi − µ)2 − n(X − µ)2 ·\nEscrevendo Yi = Xi − µ, vemos que E(Yi) = 0, Var(Yi) = σ2 e E(Y 4) = µ4. Temos então que\nn2 E(b2) = E\nn i=1 n\n2\nY 2 − nY 2\nn n\n n n n \n= E ∑ Y 4 + ∑ ∑ Y 2Y 2 − 2 ∑ ∑ Y 2Y 2 + ∑ Y 4\n\n1 3 ∑ ∑\n\nY 2Y 2 + ∑\nY 4 ·\nSegue então que\nn i j i=1 j=1 i̸=j\ni=1\ni \n2 1 n2 E(b2) = nµ + n(n − 1)σ2 − [n(n − 1)σ4 + nµ ] + [3n(n − 1)σ4 + nµ ]\n= (n − 2 + 1 ) µ + (n − 2 + 3 ) (n − 1)µ2 · (µ\n= σ2)\nPortanto\nn 4 n 2 2\nVar(b2) = E(b2) − [ E(b2)]2\n= (n − 2 +\n1 ) µ4\n\n(n − 1) (n − 2 + 3 µ 2 —\n\n( n − 1 )2\n= (n − 2 +\n1 ) µ4\nµ2 + (n − 1)(3 − n) ,\ncomo afirmado. As relações (2.29) e (2.30) podem ser provadas de forma semelhante.\nEste é justamente o motivo pelo qual chamamos S2 e não b2 de variância amostral.\nExemplo 2.17 (Continuação do Exemplo 2.16)\ninteir Nesta situação, σ2 = αβ2, µ2 = σ2 e µ4 = m4 − 4m3µ + 6m2µ2 − 3µ4. Obtemos que E(S2) = αβ2 e Var)(S2) = µ4 + 3 − n α2β4· n n(n − 1)\nO seguinte resultado fornece uma justificativa para a nossa definição de covariaˆncia amostral.\nDemonstração : Do Corolário 2.17 sabemos que E(S2) = σ2 e E(S2) = σ2. Para provar que E(S11) = ρσ1σ2 1 1 2 2 observemos que Xi é independente de Xj, (i ̸= j) e de Yj, (i ̸= j). Temos que\nAgora\n(n − 1) E(S11) = E\nE{(Xi − X)(Yi − Y )} =\nn i=1\n(Xi − X)(Yi − Y )] ·\n( ∑n Yj\n∑n Yj\n∑n Xj ∑n\nYj )\ne segue que\n1 = E(XY ) − n [ E(XY ) + (n − 1) E(X) E(Y )] 1 − n [ E(XY ) + (n − 1) E(X) E(Y )] 1 − n2 [n E(XY ) + n(n − 1) E(X) E(Y )] = n − 1 [ E(XY ) E(X) E(Y )] n\n(n − 1) E(S11) = n ( ) [ E(XY ) − E(X) E(Y )], n − 1\nisto é\nE(S11) = E(XY ) − E(X) E(Y ) = Cov(X, Y ) = ρσ1σ2·\nA seguir, voltamos nossa atenção para as distribuições das características da amostra. Existem várias possi- bilidades. Se for necessária a distribuição exata o método de transformação de variáveis pode ser utilizado. As vezes, a técnica da função geradora de momentos pode ser aplicada. Assim, se \\(X_1, X_2, \\cdots , X_n\\) é uma amostra aleatória de uma população com distribuição para a qual existe a função geradora de momentos, a função geradora de momentos da média amostral X é dada por n M (t) = E(etXi/n) = [MX(t/n)]n , (2.32) i=1 onde MX é a função geradora de momentos da distribuição populacional. Se MX (t) tiver alguma forma conhecida seria possível escrever a função de probabilidade ou de densidade de X. Embora este método tem a desvantagem óbvia que se aplica apenas à distribuições para as quais existem todos os momentos, veremos sua efetividade na situação importante de amostras da distribuição normal.\nExemplo 2.18\nSeja \\(X_1, X_2, \\cdots , X_n\\) uma amostra aleatória de tamanho n da distribuição Gama(α, 1). Nesta situação podemos encontrar a função de densidade de X. Temos que\nMX (t) = [MX\n(t/n)]n = 1 , t (1 − t/n)αn n\n&lt; 1,\nda qual obtemos que X ∼ Gama(nα, 1/n).\nExemplo 2.19\nSeja \\(X_1, X_2, \\cdots , X_n\\) uma amostra aleatória da distribuição Uniforme no intervalo (0, 1). Considere a média geométrica\nYn =\nn\ni=1\n1/n Xi ·\nSabemos que log(Yn) = (1/n) ∑n log(Xi) e, desta forma, log(Yn) é a média amostral de log(X1), , log(Xn). A função de densidade comum de log(X1), , log(Xn) é\nex, se x &lt; 0 f (x) = , 0, caso contrário\nque é a distribuição exponencial negativa com parâmetro β = 1. Vemos que a função geradora de momentos de log(Yn) é dada por\nMlog(Yn)\nn (t) = E(et log(Xi)/n) = , (1 t/n)n i=1\ne a função de densidade de log(Yn) é dada por\nflog(Yn)\n\n= \n\nnn Γ_{(n)}[−y]\nn−1\neny\n, se − ∞ &lt; y &lt; 0 ·\n 0, caso contrário\nSegue então que Yn tem por função de densidade\nfYn\n\n= \n\nnn y Γ_{(n)}\nn−1\n[− log(y)]\nn−1\n, se 0 &lt; y &lt; 1 ·\n\nVoltemos ao quantil amostral de ordem p,\n0, caso contrário\nξbp, o qual sabemos é ou X([np]) ou X([np]+1) dependendo se [np] é\num número par ou ímpar, como definido em (2.19). Simplificando, vamos discutir as propriedades de X([np]), onde p ∈ (0, 1) e n é grande. Isso, por sua vez, nos informará sobre as propriedades de ξp. Primeiro observemos que, se U1, U2, , Un é uma amostra aleatória da distribuição U (0, 1) então, pelo Teorema 2.3, temos que\ndo qual obtemos que\nU([np]) ∼ Beta([np], n − [np] + 1),\n[np]\nE(U([np])) =\nn + 1\nn−→→∞ p,\nCov(U , U\n) = n np1\n−→ p (1 − p )·\nUtilizando este resultado e a desigualdade de Chebychev, demonstramos que U −P→ p· (2.33)\nIsso gera a questão\nξbp −→ ξp?\nqualquer seja a distribuição da amostra aleatória X1, , Xn. Para respondermos a pergunta acima vamos utilizar o Lema de Hoeffding, ou seja, para respondermos se o quantil amostral de ordem p converge em probabilidade para o quantil teórico correspondente, utilizaremos o seguinte resultado devido a Hoeffding (1963).\nDemonstração : Dado que as variáveis aleatórias são limitadas ao intervalo (0, 1), sabemos que ehX ≤ (1 − X) + Xeh, isto deve-se a que a função exponencial ehX é convexa e, portanto, seu gráfico é limitado por cima no intervalo 0 ≤ X ≤ 1 pela linha que conecta as ordenadas X = 0 e X = 1. Então E(ehX ) ≤ (1 − E(X)) + E(X)eh· (2.35)\nSeja Sn = ∑n\nXi. Sabemos que\nP (Sn − E(Sn) ≥ nt) = E(1[Sn− E(Sn)−nt≥0]),\ntambém sabemos que\n1[Sn− E(Sn)−nt≥0] ≤ exp (h(Sn − E(Sn) − nt)),\nqualquer seja h uma constante positiva arbitrária. Então P Sn − E(Sn) ≥ nt ≤ E eh(Sn− E(Sn)−nt) (2.36) e como estamos assumindo que as variáveis são independentes, podemos escrever\n( ( ))\n∏ ( ( ))\nEscrevendo µi = E(Xi) temos, pela expressão em (2.35) que E(eh(Xi−µi)) ≤ e−hµi ((1 − µi) + µieh) = ef(h), (2.38) onde \\(F\\) (h) = −hµi + ln(1 − µi + µieh). As primeiras duas derivadas são:\n′ µi\n′′ µie−h(1 − µi)\nf (h) = −µi + e−h(1 − µ ) + µ\ne f (h) = [µi\n\ne−h(1 − µ )]2 ·\nµi\nNa segunda derivada, escolhendo u = µ + e−h(1 − µ ) 0 &lt; u &lt; 1. Portanto, \\(F\\) ′′(h) ≤ 1 . Pela série de Taylor\n\nvemos que este quociente é da forma u(1 − u), sendo\nEntão, pela expressão em (2.38)\nf (h) ≤\nf (0) + \\(F\\) ′(0)h +\n1 h2 = 8\n1 h2· 8\nSubstituindo em (2.36) temos que\nE(eh(Xi−µi)) ≤ e 1 h2 ·\nP (Sn\n— E(Sn\n) ≥ nt) ≤ e−nht+ 1 nh2 ,\ne o mínimo no expoente é atingido quando h = 4t. Então, o mínimo do limite superior da probabilidade é exp(−2nt2).\nDevemos lembrar que esta não é a única maneira de termos uma taxa de convergência para Teorema do Limite Central. Por exemplo, se Y1, Y2, , Yn forem variáveis aleatórias independentes e identicamente distribuídas, utilizando o Teorema de Berry-Esseen2, temos que\n( ∑n ∑\n) ( √ Var(Y1))\nC E|Y1\n— E(Y1)|\nP i=1\nXi −\ni=1\nE(Xi) ≥ nt ≤ Φ t n\n\n√n\n\nVar3/2(Y ) ·\n2\nDemonstração : Berry (1941); Esseen (1942).\nPode-se consultar o livro de Feller (1971) para uma demonstração moderna.\nExemplo 2.20\nCaso a amostra aleatória seja Bernoulli(µ), temos que n Xk ∼ Binomial(n, µ)· i=1 Então, segundo a desigualdade de Hoeffding\nP (X − µ ≥ t) ≤ exp(−2nt2)· Uma vantagem da desigualdade no Lema de Hoeffding é que não assume-se conhecimento da variância e, em geral, o limite da probabilidade é mais acurado do que outras desigualdades. Caso as variáveis aleatórias sejam limitadas como a ≤ Xi ≤ b, com a &lt; b, o limite superior da desigualdade (2.34) seria exp − 2nt2/(b − a)2 .\nExemplo 2.21\nSejam X1, , Xn variáveis aleatórias com distribuição U ( 1, 1). Nesta situação E(X) = 0, a = 1 e b = 1. A desigualdade de Hoeffding assume a forma P (X ≥ t) ≤ exp ( − nt2/2)·\nDemonstração : Para ϵ &gt; 0 qualquer, podemos escrever P (|ξp − ξp| &gt; ϵ) = P (ξp &gt; ξp + ϵ) + P (ξp &lt; ξp − ϵ)· Pelo Teorema 2.9, podemos escrever P (ξbp &gt; ξp + ϵ) = P (p &gt; Fbn(ξp + ϵ))\nn = P i=1\n1[Xi&gt;ξp+ϵ] &gt; n(1 − p))\nn = P i=1\nVi −\n∑i=1\nE(Vi) &gt; nδ1),\nonde Vi = 1[Xi&gt;ξp+ϵ] e δ1 = \\(F\\) (ξp + ϵ) − p. Da mesma forma, P (ξbp &lt; ξp − ϵ) = P (p &gt; Fbn(ξp − ϵ))\nn = P i=1\nWi −\n∑i=1\nE(Wi) &gt; nδ2),\nonde Wi = 1[Xi&lt;ξp−ϵ] e δ2 = p − \\(F\\) (ξp − ϵ) − p. Portanto, utilizando o Lema de Hoeffding (Lema 2.20), temos P (ξbp &gt; ξp + ϵ) ≤ exp(−2nδ2) P (ξbp &lt; ξp − ϵ) ≤ exp(−2nδ2)· Colocando δϵ = min{δ1, δ2}, a prova está completa.\nDemonstramos que\nlim P (|ξbp − ξp| &gt; ϵ) ≤ lim 2 exp(−2nδ2) = 0,\no qual significa que ξp −→ ξp. Em outras palavras, sempre que ξp seja solução única da desigualdade \\(F\\) (ξp ) ≤ p ≤ \\(F\\) (ξp), 0 &lt; p &lt; 1, o quantil amostral converge em probabilidade para o quantil populacional e isto sempre acontece nas distribuições contínuas. Um detalhe importante é que para demonstrarmos a convergência em probabilidade de ξp utilizamos o Lema de Hoeffding e ele depende da existência da esperança. O seguinte resultado fornece a distribuição assintótica da r-ésima estatística de ordem amostral de uma po- pulação com uma função de distribuição \\(F\\) , absolutamente contínua, e função de densidade \\(F\\) .\nDemonstração : Vamos demonstrar somente para o caso p = 1/2. Observemos que ξ1/2 é mediana única dado que f (ξ1/2) &gt; 0. Primeiro, consideremos que n seja ímpar, por exemplo, n = 2m − 1, logo P [√n(X(m) − \\(F\\) −1(1/2)) ≤ t] = P (X(m) ≤ t/√n + \\(F\\) −1(1/2))·\nSeja Sn o número de X que excedem t/ n + F (1/2). Então\nPercebemos que\nt X(m) ≤ √n + F\n(1/2) se, e somente se, Sn ≤ m − 1 =\nn − 1 · 2\nSn ∼ Binomial(n, 1 − \\(F\\) (F −1(1/2) + t/√n))· Fazendo pn = 1 − \\(F\\) (F −1(1/2) + t/√n), temos que\nP [√n(X\n\n\n\n— F −1(1/2)) ≤ t] = P (Sn\n≤ n − 1 )\n( Sn − npn 1 (n − 1) − npn )\n= P\nUtilizando o Teorema de Berry-Esseen, temos que\n√npn(1 − pn) ≤ √npn(1 − p ) · n\n{ ( n − 1 ) ( 1 (n − 1) − npn )}\nlim P n→∞\nSn ≤ 2\n— Φ √np\n(1 − pn)\n= 0·\nEscrevendo\n1 (n − 1) − npn npn(1 − pn)\n=\n√n( 1 − pn) 1/2 √n( − 1 + \\(F\\) (t/√n + \\(F\\) −1(1/2)))\n= 2t\n1/2 F (t/√n + \\(F\\) −1(1/2)) − \\(F\\) (F −1(1/2))\n−→ 2tf\n(F −1(1/2))·\nEntão\n( 1 (n − 1) − npn )\n( ( −1 ))\nΦ npn ou\n(1 − pn)\n≈ Φ 2tf F\n(1/2)\n√n(X\n\n− F\n\n( 1 )) −D→ N (0,\n4f 2\n1 (F −1(1/2)\n)) ·\nQuando n é par, digamos n = 2m, ambos P (√n X(m) F −1(1/2) t) quanto P (√n X(m+1) F −1(1/2) t) convergem a Φ(2tf (F −1(1/2))).\nObserve que o quantil amostral de ordem p, assintótica\nξbp, como consequência do Teorema 2.23, tem por distribuição\nN (ξ , 1 p(1 − p)) , onde ξp é o correspondente quantil populacional e \\(F\\) é a função de densidade populacional. Por exemplo, suponha temos uma amostra aleatória da di√stribuição N (µ, σ2) de tamanho n. Seja ξb1/2 a mediana amostral obtida dessa b ( πσ2 )\nTambém devemos ter em consideração que para demonstrarmos o Teorema 2.23 utilizamos a Teorema de Berry- Esseen, o qual depende da existência dos primeiros dois momentos da variável aleatória. Com isso, caso X Cauchy(µ, σ), o Teorema 2.23 não se aplica.",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula02/index.html#gráficos-descritivos",
    "href": "ModuloI/Aula02/index.html#gráficos-descritivos",
    "title": "2  Estatísticas de Ordem",
    "section": "2.5 Gráficos descritivos",
    "text": "2.5 Gráficos descritivos\nVejamos alguns conjuntos de dados disponíveis na linguagem de programação R (R Core Team, 2014), especifi- camente na libraria datasets, que nos permitiram mostrar a utilidade dos momentos amostrais para resumir as informações contidas nos dados. Para consultar estes conjuntos de dados basta digitar library(help = “datasets”) Alguns dos diversos exemplos disponíveis serão apresentados aqui.\nExemplo 2.22 (Puromicina)\nOs dados sobre a velocidade de uma reação enzimática são obtidos por Treloar (1974) e disponíveis no arquivo de dados Puromycin. O número de contagens por minuto de produto radioativo a partir da reação foi medida como uma função da concentração do substrato em partes por milhão (ppm) e a partir destas contagens a taxa\ninicial (ou velocidade) da reação foi calculada (contagens/min/min). O experimento foi realizado uma vez com a enzima tratada com puromicina e depois com a enzima não tratada. A estrutura destes dados tem 23 linhas e 3 colunas, cada coluna contendo as informações das variáveis: conc: um vector numérico de concentrações de substrato (ppm); rate: um vector numérico de taxas de reação instantânea (contagens/min/min); state: um fator com níveis treated (tratada) ou untreated (não tratada). Para a leitura e observação dos nomes das variáveis utilizamos os comandos a seguir: data(Puromycin) names(Puromycin) Uma maneira de obtermos estatísticas descritivas é utilizando as linhas de comando a seguir: summary(rate[state==’treated’]) Min. 1st Qu. Median Mean 3rd Qu. Max. 47.0 104.5 145.5 141.6 193.2 207.0 e summary(rate[state==’untreated’]) Min. 1st Qu. Median Mean 3rd Qu. Max. 51.0 85.0 115.0 110.7 137.5 160.0 para o caso da variável rate, as concentrações, obtidas as estatísticas descritivas segundo os níveis do fator state, se as concentrações foram ou não tratadas com puromicina. No caso das estatísticas descritivas acerca das concentrações de substrato, variável conc, temos: summary(conc[state==’treated’]) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.020 0.060 0.165 0.345 0.560 1.100 e summary(conc[state==’untreated’]) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.0200 0.0600 0.1100 0.2764 0.3900 1.1000 Os valores mínimos é máximos foram registrados sempre com os nomes de Min. e Max., respectivamente. O primeiro e terceiro quantis ou quantis de 25% e 75% respectivos são registrados com os nomes 1st Qu. e 3rd Qu. e, finalizando, o resumo de informações de estatísticas de posição temos os valores de medianas (Median) e médios (Mean).\nExemplo 2.23 (Rock )\nMedições em 48 amostras de rochas de um reservatório de petróleo estão disponíveis no arquivo de dados rock. Este conjunto de dados contem 48 linhas e 4 colunas numéricas, descritas a seguir: area área do espaço de poros, em pixels de 256 por 256; peri perímetro em pixels; shape perímetro/sqrt(area) perm permeabilidade em mili-Darcies. Doze amostras do núcleo de reservatórios de petróleo foram amostrados por 4 seções transversais. Cada amostra foi medida no núcleo para a permeabilidade e cada seção transversal tem uma área total de poros, perímetro total de poros e forma. A fonte destes dados é a BP Research e a análise das imagens foi de Ronit Katz, Oxford University. Na geologia, a permeabilidade é a medida da capacidade de um material (tipicamente uma rocha) para transmitir fluídos. E´ de grande importância na determinação das características de fluxo dos hidrocarbonetos em reservatórios de petróleo e gás e da água nos aquíferos. A unidade de permeabilidade é o Darcy ou, mais habitualmente, o mili- Darcy ou mD.\n\n2.5.1 2.4.1 Gráfico de Boxplot\nEm 1977, John Tukey (Tukey, 1977) publicou uma proposta que posteriormente foi reconhecida como sendo um eficiente método para mostrar cinco número que sumarizam qualquer conjunto de dados. O gráfico proposto é chamado de boxplot (também conhecido como box and whisker plot) e resume as seguintes medidas de posição estatísticas: mediana, quantis inferior e superior e os valores mínimos e máximos. Os quantis inferior e superior entendem-se serem os quantis de 25% e 75%, respectivamente. No caso do exemplo 2.22, deixamos a disposição os dados digitando attach(Puromycin) e com isso podemos mudar o nome dos níveis do fator da forma state=factor(state,labels=c(’Tratada’,’N~ao tratada’)) Então, com os comandos a seguir geramos o gráfico de boxplot, tanto para a variável rate quanto para a variável conc, estas segundo os níveis do fator state. par(mar=c(5,4,3,1)) boxplot(rate ~ state, col = grey(c(0.4,1)), main=’Taxas de reaç~ao instant^anea’)\npara o caso do rate. Observemos que a primeira linha par(mar=c(5,4,3,1)) serve somente para dimensionar a janela gráfica. Para o caso da variável conc utilizamos comandos semelhantes. par(mar=c(5,4,3,1)) boxplot(conc ~ state, col = grey(c(0.4,1)), main=’Concentraç~oes de substrato’) O resultado deste trabalho pode ser observado na Figura 2.3. Interpretemos o gráfico de boxplot. A caixa (box) propriamente contém a metade 50% dos data. O limite superior da caixa indica o percentil 75% dos dados e o limite inferior da caixa indica o percentil 25%. A distancia entre esses dois quantis é conhecida como inter-quantil. A linha na caixa indica o valor de mediana dos dados. Se a linha mediana dentro da caixa não é equidistante dos extremos, diz-se então que os dados são assimétricos. O boxplot da variável rate (esquerda na Figura 2.3) é um exemplo de dados simétricos já a situação da variável conc (direita na Figura 2.3) é um caso clássico de assimetria dos dados. Os extremos do gráfico indicam os valores mínimo e máximo, a menos que valores outliers3 estejam presentes, nesse caso o gráfico de estende ao máximo de 1.5 vezes da distância inter-quantil. Os pontos fora do gráfico são então outliers ou suspeitos de serem outliers. Mais elegante seria utilizar a biblioteca de funções ggplot2, para isso, digitamos: library(ggplot2) Para gerar os gráficos de boxplot respectivos, fazemos: par(mar=c(5,4,3,1)) qplot(state, rate, geom=c(“boxplot”, “jitter”), main=“Taxas de reaç~ao instant^anea”, xlab=““, ylab=” “) e par(mar=c(5,4,3,1)) qplot(state, conc, geom=c(”boxplot”, “jitter”), main=“Concentraç~oes de substrato”, xlab=““, ylab=” “)\n3Em estatística, outlier, valor aberrante ou valor atípico, é uma observação que apresenta um grande afastamento das demais observações em uma amostra. A existência de outliers implica, tipicamente, em prejuízos a interpretação dos resultados dos testes estatísticos aplicados as amostras.\nTaxas de reação instantânea Concentrações de substrato\nTratada Não tratada Tratada Não tratada\nFigura 2.3: Gráfico de boxplot da variável rate à esquerda e da variável conc à direita, segundo os níveis do fator state, se a enzima foi tratada ou não com puromicida. Gráfico gerado utilizando a função R boxplot,\nTaxas de reação instantânea Concentrações de substrato\n200\n0.9\n150\n0.6\n100 0.3\n50\nTratada Não tratada\n0.0\nTratada Não tratada\nFigura 2.4: Gráfico de boxplot da variável rate à esquerda e da variável conc à direita, segundo os níveis do fator state, se a enzima foi tratada ou não com puromicida. Gráfico gerado utilizando a função R qplot, opção geom=c(”boxplot”, ”jitter”).\nobtendo-se assim os gráficos na Figuras 2.4. Além de melhor qualidade gráfica acrescentamos os pontos observados no boxplot, isso permite termos uma ideia também da dispersão dos dados. Vejamos as vantagens do boxplots. Mostra graficamente a posição central dos dados (mediana) e a tendência. Fornece algum indicativo de simetria ou assimetria dos dados. Ao contrário de muitas outras formas de mostrar os dados, o boxplots mostra os outliers. Utilizando o boxplot para cada variável categórica no mesmo gráfico, pode-se facilmente comparar os dados. Esta é a situação no exemplo na Figura 2.3, podemos observar o comportamento das variáveis rate e conc segundo os níveis do fator state. Um detalhe do boxplot é que ele tende a enfatizar as caudas da distribuição, que são os pontos ao extremo nos dados. Também fornece detalhes da distribuição dos dados. Mostrar o histograma (Seção 2.4.2) em conjunto com o boxplot ajuda a entender a distribuição dos dados, constituindo estes dos gráficos ferramentas importantes na análise exploratória. Logicamente, o comportamento dos dados dentro da caixa (box), como podemos perceber nas figuras 2.3 e 2.4, permanece um mistério. Isso porque caso estejam os dados bem espalhados ou não, o gráfico boxplot continua mostrando uma caixa. Somente perceberemos algum comportamento diferente se o valor da mediana estiver mais próximo de um dos extremos desta caixa. Para tentar diminuir essa limitação foi sugerido uma melhoria, obtendo-se o chamada boxplot entalhado (notched boxplot). Com as linhas de comando a seguir se obtém os gráficos na Figura 2.5.\npar(mar=c(5,4,3,1)) boxplot(rate ~ state, col = grey(c(0.4,1)), notch=TRUE, main=’Taxas de reaç~ao instant^anea’)\ne par(mar=c(5,4,3,1)) boxplot(conc ~ state, col = grey(c(0.4,1)), notch=TRUE, main=’Concentraç~oes de substrato’)\nObserva-se que a única diferença é a inclusão da opção notch=TRUE, permanecendo todas as outras instruções iguais. Mais elaborado é o chamado violin plot, mistura de boxplot com estimação de densidade, tema este tratado na Seção 4.3. Este gráfico, introduzido no artigo Hintze & Nelson (1998), sinergicamente combina o gráfico de boxplot e a estimação da densidade, também chamado de histograma suavizado, em uma única tela que revela a estrutura encontrada nos dados. Com as linhas de comando a seguir se obtém os gráficos na Figura 2.6.\npar(mar=c(5,4,3,1)) qplot(state, rate, geom = c(“violin”, “jitter”), notch=TRUE, main=“Taxas de reaç~ao instant^anea”, xlab=““, ylab=” “)\ne par(mar=c(5,4,3,1)) qplot(state, conc, geom=c(“violin”, “jitter”), notch=TRUE, main=“Concentraç~oes de substrato”, xlab=““, ylab=” “)\nEste gráfico é similar ao boxplot excepto que mostra também a densidade de probabilidade dos dados. Pode incluir também um marcador para a média dos dados e uma caixa que indica a distância interquartil, como nos gráficos boxplot. O objetivo do gráfico violin plot é o mesmo do que o boxplot original porém, considera de alguma maneira o comportamento dos dados dentro da caixa (box). Assim, percebemos melhor a distribuição dos dados dentro do intervalo interquartil.\nTaxas de reação instantânea Concentrações de substrato\nTratada Não tratada Tratada Não tratada\nFigura 2.5: Gráfico de boxplot entalhado da variável rate à esquerda e da variável conc à direita, segundo os níveis do fator state, se a enzima foi tratada ou não com puromicida. Gráfico gerado utilizando a função R qplot, opção geom=c(”boxplot”, ”jitter”), notch=TRUE.\nTaxas de reação instantânea Concentrações de substrato\n200\n0.9\n150\n0.6\n100 0.3\n50\nTratada Não tratada\n0.0\nTratada Não tratada\nFigura 2.6: Gráfico de violin plot da variável rate à esquerda e da variável conc à direita, segundo os níveis do fator state, se a enzima foi tratada ou não com puromicida. Gráfico gerado utilizando a função R qplot, opção geom=c(”vioplot”, ”jitter”), notch=TRUE.\n\n\n2.5.2 2.4.2 Histograma\nUm histograma é uma representação gráfica da função de probabilidades ou da função de densidade de um conjunto de dados independentes e foi introduzido pela primeira vez por Karl Pearson4. A representação mais comum do histograma é um gráfico de barras verticais. A palavra histograma é de origem grega, derivada de duas: histos que pode significar testemunha no sentido de aquilo que se vê, como as barras verticais do histograma, e da também palavra grega gramma que significa desenhar, registrar ou escrever. Histograma Histograma com a curva norma\n−2 −1 0 1 2 Dados simulados\n−2 −1 0 1 2 Dados simulados\nFigura 2.7: Gráfico de histograma para dados simulados.\nPara construir um exemplo controlado do gráfico de histograma, simulamos uma amostra de tamanho 150 da distribuição normal padrão, com o comando x=rnorm(150) e, depois, construímos um gráfico colorido com as linhas de comando par(mar=c(5,4,2,1)) hist(x, breaks=12, col=“red”, xlab=“Dados simulados”, ylab=’Frequ^encia’, main=“Histograma”) box() Posteriormente, acrescentamos a este gráfico uma linha com a densidade normal par(mar=c(5,4,2,1)) h=hist(x, breaks=10, col=“red”, xlab=“Dados simulados”, ylab=’Frequ^encia’, main=“Histograma com a curva normal”) xfit=seq(min(x),max(x),length=40) yfit=dnorm(xfit,mean=mean(x),sd=sd(x)) yfit=yfitdiff(h$mids[1:2])length(x) lines(xfit, yfit, col=“blue”, lwd=2) box()\n4Pearson, K. (1895). Contributions to the Mathematical Theory of Evolution. II. Skew Variation in Homogeneous Material. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 186: 343-414.\nDesta forma geramos os gráficos na Figura 2.7. A ideia é mostrar que o histograma assemelha-se ao gráfico da densidade normal, a densidade dos dados.\nHistograma c2(6) Histograma c2(6)\n2 4 6 8 10 12 14 14 intervalos\n2 4 6 8 10 12 14 26 intervalos\nFigura 2.8: Histogramas da distribuição χ2 com 6 graus de liberdade. Número de intervalos 14 e 26, respectivamente.\nO histograma é um gráfico composto por retângulos justapostos em que a base de cada um deles corresponde ao intervalo de classe e a sua altura à respectiva frequência. A construção de histogramas tem caráter preliminar em qualquer estudo e é um importante indicador da distribuição de dados. Pode indicar se uma distribuição aproxima-se de uma densidade normal como pode indicar mistura de densidades, quando os dados apresentam várias modas. Os histogramas podem ser um mau método para determinar a forma de uma distribuição porque são fortemente influenciados pelo número de intervalos utilizados. Por exemplo, decidimos gerar 50 amostras da densidade χ2(6), da forma set.seed(5678) z=rchisq(50, df=6) Os gráficos de histogramas correspondentes com 14 e 26 intervalos são apresentados na Figura 2.8 e foram gerados com as linhas de comando\npar(mar=c(5,4,2,1)) hist(z, breaks=14, col=“blue”, main=expression(paste(’Histograma ’, chi^2,’(6)’)), ylab=’Frequ^encia’, xlab=’14 intervalos’) box()\ne\npar(mar=c(5,4,2,1)) hist(z, breaks=26, col=“blue”, main=expression(paste(’Histograma ’, chi^2,’(6)’)), ylab=’Frequ^encia’, xlab=’26 intervalos’) box()\nNa Figura 2.9 podemos observar os gráficos de histograma obtidos das variáveis descritas no Exemplo 2.23. A situação em (a) representa o caso em a distribuição dos dados de assemelha à distribuição normal, já a situação descrita no gráfico em (b) mostra-se uma mistura de densidades, percebemos a existência de duas modas. (a) Área do espaço de poros (b) Perímetro em pixels\n0 4000 8000 12000 pixels de 256 x 256\n0 1000 3000 5000\nFigura 2.9: Histogramas das variáveis no Exemplo 2.23.\nOutras situações no mesmo exemplo, mas diferentes variáveis, são descritas nos gráficos na Figura 2.10. Nessa figura apresentamos dois gráficos, chamados de (c) e (d), nesta figura. Correspondem, como podemos observar, à distribuições assimétricas e descrevem os dados coletados nas variáveis shape e perm do arquivo de dados Rock, Exemplo 2.23. Os histogramas foram pensados somente para o caso de variáveis contínuas, porém é uma descrição discreta delas. Logicamente, também podemos utiliza-los em situações de variáveis aleatórias discretas, nada impede isso. Estas figuras foram geradas utilizando a configuração padrão do comando hist, isto é, utilizamos uma maneira automática de determinar o número de intervalos, mais adiante dedicamos maior atenção a diferentes formas de calcular este número. Como pode ter sido observado, além de não ficar claro como determinar o número de intervalos nem como delimitar os intervalos, também não ficou claro o que queremos realmente observar com o gráfico desta função. Vejamos agora uma definição mais clara do histograma, esta definição nos permitirá obter propriedades impor- tantes.\n\nPerímetro/sqrt(Área) (d) Permeabilidade\n\n0.1 0.2 0.3 0.4 0.5\n0 200 600 1000 1400 mili−Darcies\nFigura 2.10: Histogramas das variáveis no Exemplo 2.23.\nFoi provado por Robertson (1967) que, dados os intervalos I1, I2, , Ik, o histograma \\(F\\) é um estimador de máxima verossimilhança5 dentre os estimadores expressados como funções simples e semicontínuas superiormente, isto se o fecho de cada intervalos contiver duas ou mais observac¸ões. Os gráficos apresentados nas figuras 2.7, 2.9 e 2.10 são histogramas também segundo a proposta de Robertson (1967). Pode-se observar que este estimador tem duas limitações importantes: a dependência do comprimento do intervalo e o fato de o histograma não constituir uma função contínua. A primeira destas limitações foi amplamente estudada por Wegman (1975). Ele provou que os pontos extremos de cada intervalo Ik devem ser coincidentes com observações e que, se o número mínimo de observações em cada intervalo aumente, conforme aumenta o tamanho da amostra, o estimador \\(F\\) é consistente6. A segunda limitação importante do histograma, isto é, o fato de ele não constituir uma função contínua, incentivou diversos estudos na procura de estimadores contínuos da função de densidade. No Capítulo 3, a Seção 4.3 dedica-se a mostrar estimadores contínuos da função de densidade.\n5Os estimadores de máxima verossimilhanc¸a serão estudados na Seção 4.2 6Estimadores consistentes serão estudados na Seção 3.1.1\nCálculo automático do número de intervalos num histograma Uma questão importante é determinar de maneira automatizada o número de intervalos disjuntos que serão utili- zados para a construção do gráfico. Uma primeira forma de escolher o número de intervalos foi dada por Sturges (1926) e que constitui a forma padrão no R. Conhecida como fórmula de Sturges é dada por k = [log2_{(n)} + 1], (2.41) isto significa que o número de intervalos é a parte inteira do logaritmo base 2 do número de observações mais 1. Outras expressões comumente utilizadas são a fórmula de Scott (Scott, 1979) h = 3.5s/√3 n, onde s é o desvio padrão e a fórmula de Freedman Diacconi (Freedman & Diaconis, 1981) h = 2IQR(x)/√3 n, onde IRQ é a diferença entre o terceiro e o primeiro quantil.\nExemplo 2.24\nNa libraria de funções R robustbase temos disponíveis dados do teor de cálcio e do pH em amostras de colo coletadas em diferentes comunidades da região de Condroz, na Bélgica. Podemos ler estes dados digitando as linhas de comando abaixo, primeiro para escolher a libraria de funções e depois para selecionar os dados. library(robustbase) data(condroz) Temos registadas duas variáveis: Ca que registra o tero de cálcio na amostra de solo e o pH, o pH corres- pondente. Construímos histogramas da variável Ca segundo a três formas de escolha do número de intervalos e os apresentamos na Figura 2.11. Os dados deste exemplo foram publicados em: Hubert, M. and Vandervieren, E. (2006). An Adjusted Boxplot for Skewed Distributions, Technical Report TR-06-11, KULeuven, Section of Statistics, Leuven.\nSturges\nScott\nFreedman−Diaconis\n0 1000 2000 3000 4000 Ca\n0 1000 2000 3000 4000 Ca\n0 1000 2000 3000 4000 Ca\nFigura 2.11: Diferentes histogramas da variável Ca no Exemplo 2.24.\n\n\n2.5.3 2.4.3 Gráficos para verificar normalidade\nUm primeiro gráfico chamado de qq-norm permite a comparação de duas distribuições de probabilidades traçando seus quantis uns contra os outros. Depois exploramos um gráfico mais recente, conhecido como worm plot (gráfico de minhoca), consistindo numa determinada coleção de de qq-norm.\nQQ-norm O gráfico quantil-quantil ou qq-plot, proposto por Wilk & Gnanadesikan (1968), é um dispositivo gráfico explo- ratório utilizado para verificar a validade de um pressuposto de distribuição para um conjunto de dados. Em geral, a ideia básica é a de calcular o valor teoricamente esperado para cada ponto de dados com base na distribuição em questão. Se os dados de fato seguirem a distribuição assumida os pontos deste gráfico formarão aproximadamente uma linha reta. Percebemos que podemos verificar com este gráfico qualquer densidade contínua, eventualmente pode ser uti- lizado também para funções de probabilidade. O qq-plot vai apresentar-se como uma linha reta se a densidade assumida estiver correta. Vejamos o caso particular de verificarmos se a densidade é normal, nesta situação o gráfico qq-plot será chamado de qq-norm. Primeiro consideraremos a situação da densidade normal padrão. Seja z1, z2, , zn uma amostra aleatória de uma distribuição normal com média µ = 0 e desvio padrão σ = 1. As estatísticas de ordem amostrais são z_{(1)} ≤ z_{(2)} ≤ ≤ z_{(n)}· Estes valores desempenharão o papel dos quantis da amostra. Agora, quais devemos tomar como os quantis teóricas correspondentes? Se a função de distribuição cumulada da densidade normal padrão fosse denotada por Φ, usando a notação quantil, se ξq é o q-ésimo quantil de uma distribuição normal, então Φ(ξq) = q, ou seja, a probabilidade de uma amostra normal ser inferior a ξq é, de fato, apenas q. Considere o primeiro valor ordenado z_{(1)}. O que podemos esperar que o valor Φ(z_{(1)}) seja? Intuitivamente, esperamos que essa seja a probabilidade de assumir um valor no intervalo (0, 1/n). Do mesmo modo, espera-se que Φ(z_{(2)}) seja a probabilidade de assumir um valor no intervalo (1/n, 2/n). Continuando, esperamos que Φ(z_{(n)}) seja a probabilidade de assumir um valor no intervalo (n 1)/n, 1). Assim, o quantil teórico desejamos seja definido pelo inverso da função de distribuição acumulada normal padrão. Em particular, o quantil teórico correspondente ao quantil empírico z_{(i)} deve ser\npara i = 1, 2, , n.\nξ = q i − 0, 5 , q n\nQQ−plot nomal\nQQ−plot nomal\nQQ−plot nomal\n−3 −2 −1 0 1 2 3 Quantis teóricos\n−3 −2 −1 0 1 2 3 Quantis teóricos\n−3 −2 −1 0 1 2 3 Quantis teóricos\nFigura 2.12: Diferentes qqplot para dados normais.\nNa Figura 2.12, a esquerda acima exibimos o qq-norm de uma pequena amostra normal de tamanho 5. Os restantes quadros na Figura 2.12 exibem as plotagens de qq-norm para amostras normais de tamanhos n = 100 e\nn = 1000, respectivamente. Como o tamanho da amostra aumenta, os pontos encontram-se mais perto da linha y = x. Estes gráficos (Figura 2.12) foram gerados utilizando as linhas de comando: set.seed(1278) x=rnorm(5) qqnorm(x, xlim=c(-3,3), ylim=c(-3,3), cex=0.6, pch=19, ylab=’Quantis amostrais’, xlab=’Quantis teóricos’, main=’QQ-plot nomal’) qqline(x,col=“red”) text(-1,2,’n=5’) para a situação de amostra de tamanho 5. A primeira linha de comando serve para fixar o gerador de números laetórios e, dessa forma, podermos simular sempre a mesma amostra e reproduzir o gráfico idêntico. Nas outras situações somente muda-se o tamanho da amostra que se quer gerar.\nQQ−plot nomal QQ−plot nomal\n−3 −2 −1 0 1 2 3 Quantis teóricos\n−3 −2 −1 0 1 2 3 Quantis teóricos\nFigura 2.13: Diferentes qqplot para dados não normais. Assim, os comandos para gerar o segundo e terceiro gráficos são: x=rnorm(100) qqnorm(x, xlim=c(-3,3), ylim=c(-3,3), cex=0.6, pch=19, ylab=’Quantis amostrais’, xlab=’Quantis teóricos’, main=’QQ-plot nomal’) qqline(x,col=“red”) text(-1,2,’n=100’)\nx=rnorm(1000) qqnorm(x, xlim=c(-3,3), ylim=c(-3,3), cex=0.6, pch=19, ylab=’Quantis amostrais’, xlab=’Quantis teóricos’, main=’QQ-plot nomal’) qqline(x,col=“red”) text(-1,2,’n=1000’) Caso os dados não forem padronizados bastar aplicar a transformação (X − µ)/σ, onde X representa os dados originais e µb e σb representam os estimadores dos parâmetros µ e σ, respectivamente.\nEstes gráficos podem indicar afastamentos da normalidade por isso apresentamos duas situações de dados não simétricos e com cuadas pesadas. Na Figura 2.13, mostramos o que acontece se os dados forem da distribuição t-Student(8) e da distribuição χ2(5), sempre de tamanho n = 1000. Observe, em particular, que os dados a partir da distribuição t-Student seguem a curva normal bem de perto até os últimos pontos em cada extremo. Na outra situação o afastamento da distribuição normal é evidente. Foi mencionado que o qq-norm é uma situação particular do qq-plot devido a este último permitir comparar os quantis amostrais com os quantis distribucionais. Com isto queremos dizer que o qq-plot serve para verificar se os dados forem t-Student ou χ2(5), por exemplo. Na Figura 2.14 apresentamos a aparência dos gráficos qq-plot caso queira-se verificar se as amostras seguem distribuição t-Student(8) ou χ2(5), respectivamente.\nQQ plot para t−Student(8)\n−4 −2 0 2 4 t−Student(8)\nQQ plot para c2(5)\n0 5 10 15 20 c2(5)\nFigura 2.14: Diferentes qqplot para dados não normais. Os gráficos na Figura 2.14 foram gerados pelas linhas de comandos qqplot(qt(ppoints(1000), df = 8), x, cex=0.6, pch=19, main = “QQ plot para t-Student(8)”, xlab=“t-Student(8)”) qqline(x, distribution = function(p) qt(p, df = 8), prob = c(0.1, 0.6), col = 2) no caso t-Student(8) e qqplot(qchisq(ppoints(1000), df = 5), x, cex=0.6, pch=19, main = expression(“QQ plot para” ~~ {chi^2}(5)), xlab=expression({chi^2}(5))) qqline(x, distribution = function(p) qchisq(p, df = 5), prob = c(0.1, 0.6), col = 2) para o caso χ2(5).\nWorn plot O worm-plot é uma série de parcelas de gráficos qq-plot retificados. Constitui uma ferramenta de diagnóstico para visualização de quão bem um modelo estatístico se ajusta aos dados, para encontrar locais em que o ajuste pode ser melhorado e para comparar o ajuste de diferentes modelos. Na Figura 2.15 mostramos este gráfico para duas situações: a esquerda os dados são normais e a direita os dados são t-Student com 8 graus de liberdade. Nesta situação aparece bem a qualidade da observação com esta\n−4 −2 0 2 4 Unit normal quantile\n−4 −2 0 2 4 Unit normal quantile\nFigura 2.15: Diferentes worm-plot para dados normais.\nfigura. Se os dados forem normais o curva worm-plot ou gráfico de minhoca deve aparentar um verme achatado, os pontos próximos a curva vermelha e com poucas oscilações. Quando aplicamos este gráfico ao caso t-Student percebemos uma oscilação grande no verme e com pontos fugindo da banda de confiança. Isso comprova que os dados não seguem como referência a distribuição normal.\n−4 −2 0 2 4 Unit normal quantile\n−4 −2 0 2 4 Unit normal quantile\nFigura 2.16: Diferentes worm-plot para dados não normais. As linhas a seguir mostram os comandos necessários para gerar os gráficos na Figura 2.15. Utilizamos a libraria de comandos R gamlss (Rigby & Stasinopoulos, 2005).\nlibrary(gamlss) x=rnorm(1000) wp(gamlss(x~1), cex=0.6) x=rt(1000, df=8) wp(gamlss(x~1), cex=0.6)\nNa Figura 2.16, a esquerda temos o caso de dados com distribuição χ2(5) e a direita dados com distribuição Cauchy padrão. Nestas situações fica claro que os dados não são normais. Oa gráficos na figura foram gerados pelas linhas de comando a seguir. x=rchisq(1000, df=5) wp(gamlss(x~1), cex=0.6) x=rcauchy(1000) wp(gamlss(x~1), cex=0.6)",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula02/index.html#exercícios",
    "href": "ModuloI/Aula02/index.html#exercícios",
    "title": "2  Estatísticas de Ordem",
    "section": "2.6 Exercícios",
    "text": "2.6 Exercícios\nExercícios da Seção 2.1 1. Seja X ∼ Bernoulli( 1 ) e considere todas as possíveis amostras aleatórias de tamanho n = 3. Calcule Xn e S2 cada uma das\n2 n oito amostras. Encontre a função de probabilidade de Xn e S2. 2. Um dado é lançado. Seja X o valor da face superior que aparece e X1, X2 duas observações independentes de X. Encontre a função de probabilidade de Xn. 3. Seja X1, , Xn uma amostra aleatória de alguma população. Mostre que (n − 1)Sn\nmax |Xi Xn| &lt; 1≤i≤n\nonde Sn é a raiz quadrada positiva da variância amostral S2.\n√n ,\nExercícios da Seção 2.2 1. Seja (X_{(1)}, X_{(2)}, , X_{(n)}) o conjunto das estatísticas de ordem de n variáveis aleatórias independentes \\(X_1, X_2, \\cdots , X_n\\) com função de densidade comum\nf (x) =\nβe−xβ, se x 0 · 0, caso contrário\n\nMostre que X(s) e X(r) − X(s) são independentes para quaisquer r &gt; s.\nEncontre a função de densidade de X(r+1) − X(r).\nSeja Z1 = nX_{(1)}, Z2 = (n − 1)(X_{(2)} − X_{(1)}), Z3 = (n − 2)(X_{(3)} − X_{(2)}), …, Zn = ((X_{(n)} − X(n−1))). Prove que (Z1, Z2, , Zn) e \\((X_1, X_2, \\cdots , X_n)\\) são identicamente distribuídas.\n\n\nProvar o Teorema 2.1\nSejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias com distribuição geométrica de parâmetros p1, p2, , pn, respectivamente. Prove que Nn = min\\((X_1, X_2, \\cdots , X_n)\\) têm também distribuição geométrica de parâmetro n p = 1 − (1 − pi)· i=1\nAs X1, , Xn variáveis aleatórias independentes e identicamente distribuídas tem por função de probabilidade BN (1; p) se, e somente se, Nn = min(X1, , Xn) tem distribuição geométrica de parâmetro 1 − (1 − p)n.\nSejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias independentes e igualmente distribuídas com função de densidade comum\n\nf (x) =\nσ 0, se x ≤ \nMostre que X_{(1)}, X_{(2)} − X_{(1)}, X_{(3)} − X_{(2)}, , X_{(n)} − X(n−1) são independentes. 6. Sejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias independentes e igualmente distribuídas com função de distribuição acumulada comum\nF (t) =\ntα, se 0 &lt; t &lt; 1  1, se t ≥ 1\npara α &gt; 0. Mostre que X_{(i)}/X_{(n)}, i = 1, 2, , n − 1 e X_{(n)} são independentes. 7. Sejam X1 e X2 duas variáveis aleatórias discretas independentes com função de probabilidade comum P (X = x) = (1 − )x−1, x = 1, 2, ; 0 &lt; &lt; 1· Mostre que X_{(1)} e X_{(2)} − X_{(1)} são independentes. 8. Sejam X1, , Xn duas variáveis aleatórias independentes com função de densidade comum \\(F\\) . Encontre a função de densidade de X_{(1)} e de X_{(n)}.\n\nSejam X_{(1)}, X_{(2)}, , X_{(n)} as estatísticas de ordem de n variáveis aleatórias independentes e igualmente distribuídas \\(X_1, X_2, \\cdots , X_n\\) com função de densidade comum f (x) = 1 se 0 &lt; x &lt; 1 · 0, caso contrário Prove que Y1 = X_{(1)}/X_{(2)}, Y2 = X_{(2)}/X_{(3)}, , Yn−1 = X(n−1)/X_{(n)} e Yn = X_{(n)} são independentes. Encontre a função de densidade conjunta de Y1, Y2, , Yn.\nSejam X1.X2, , Xn variáveis aleatórias independentes identicamente distribuídas não negativas contínuas. Prove que se E|X| &lt; ∞, então E|X(r)| &lt; ∞. Definamos Mn = X_{(n)} = max\\((X_1, X_2, \\cdots , X_n)\\). Mostre que ∫ ∞\n\nEncontre E(Mn) em cada uma das seguintes situações: a) Xk tem como função de distribuição comum \\(F\\) (x) = 1 − e−xβ, se x ≥ 0. b) Xk tem como função de distribuição comum \\(F\\) (x) = x, se 0 &lt; x &lt; 1.\n\nProvar que, qualquer seja a amostra aleatória X1.X2, , Xn sempre cumpre-se que X_{(1)} ≤ X ≤ X_{(n)}.\nDemonstrar o Teorema 2.5.\nDemonstrar o Teorema 2.9.\n\nExercícios da Seção 2.3 1. Demonstre o Corolário 2.17. 2. Demonstre o Corolário 2.18.\n\nSeja X1, , Xn uma amostra aleatória Poisson(). Encontre Var(S2) e compare-a com Var(X). Observe que E(X) = = E(S2).\nSeja \\(X_1, X_2, \\cdots , X_n\\) uma amostra aleatória da função de distribuição \\(F\\) e seja \\(F\\) ∗(x) a função de distribuição amostral. Encontre Cov[F ∗(x), \\(F\\) ∗(y)] para números reais fixos x, y. n n\nSeja \\(F\\) ∗ a função de distribuição empírica de uma amostra aleatória com função de distribuição teórica \\(F\\) . Prove que { ∗ ϵ } 1\nSejam \\(X_1, X_2, \\cdots , X_n\\) n observacões independentes da variável aleatória X. Encontre a distribuição amostral de X, a média amostral, se:\n\n\nX ∼ P ();\nX ∼ Cauchy(1, 0);\nX ∼ χ2(m).\n\n\nSeja X1, , Xn uma amostra aleatória Poisson(). Encontre Var(S2) e compare-a com Var(X). Observe que E(X) = = E(S2).\nDemonstre o Teorema 2.23. [Dica: para quaisquer reais µ e σ &gt; 0, encontre a função de densidade de (U(r) − µ)/σ e mostre que as variáveis padronizadas de U(r), (U(r) − µ)/σ, são assintoticamente N (0, 1) sob as condições do teorema.]\nProvar que o momentos amostral central b1 é sempre zero.",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula02/index.html#pg8",
    "href": "ModuloI/Aula02/index.html#pg8",
    "title": "2  Estatísticas de Ordem",
    "section": "2.3 pg8",
    "text": "2.3 pg8\nDemonstração :\nfrs(x(r), x(s)) =\n∫ x(r)\n∫ t2\n∫ x(s)\n∫ x(s) ∫ +∞\n∫ +∞\n−∞ −∞\nx(r)\nts−2\nx(s)\ntn−1\nn!f (t1) \\(F\\) (tn) dtn dts+1 dts−1 dtr+1 dt1 dtr−1\n= n!\n∫ x(r)\n∫ t2\n∫ x(s)\n∫ x(s) [1 − \\(F\\) (x(s))]n−s\n−∞ −∞\nx(r)\nts−2\n(n − s)!\n×f (t1)f (t2) \\(F\\) (x(s)) dts−1 dtr+1 dt1 dtr−1\n= n!\n[1 − \\(F\\) (x(s))]n−s (n − s)! f (x(s))\nx(r)\n−∞\nt2 f (t1) \\(F\\) (x(r))× −∞\n[F (x(s)) − \\(F\\) (x(r))]s−r−1 × (s − r − 1)! dt1 dtr−1\nn!  \n= (n − s)!(s − r − 1)![1 − \\(F\\) (x\n\n\n\n)]n−s×\n[F (x(r))]r−1\ncaso x(r) &lt; x(s).\n×[F (x(s)) − \\(F\\) (x(r))]s−r−1f (x(s))f (x(r))\n, (r − 1)!\nDe modo semelhante, podemos mostrar que a função de densidade conjunta de X(k1), , X(km) se 1 ≤ k1 &lt;\nk2 &lt; &lt; km ≤ n, 1 ≤ m ≤ n, é dada por fk1k2···km (x(k1), x(k2), , x(km)) =\n(k1\n— 1)!(k2\n— k1\nn! × — 1)! × (n − km)!\n×Fk1−1(x(k ))f (x(k ))[F (x(k )) − \\(F\\) (x(k ))]k2−k1−1f (x(k )) × × ×[F (x(k )) − \\(F\\) (x(k ))]km−1−km−2−1f (x(k ))[1 − \\(F\\) (x(k ))]n−km \\(F\\) (x(k )), caso x(k1) &lt; x(k2) &lt; &lt; x(km) e zero noutras situações.\nExemplo 2.9 (Continuação do Exemplo 2.7) Sabemos que as variáveis aleatórias \\(X_1, X_2, \\cdots , X_n\\) são independentes e tem como função de densidade comum f (x) = 1, se 0 &lt; x &lt; 1 · 0, caso contrário Então, a função de densidade conjunta de X(r) e X(s) é dada por\nfrs\n(x(r)\n, x(s)) =\n n!\nxr−1(x(r) − x(s))s−r−1(1 − x(s))n−s (r − 1)!(s − r − 1)!(n − s)!\n, se x\n\n\n\n&lt; x(s) ·\n\nonde 1 ≤ r &lt; s ≤ n.\n0, caso contrário\nUma situação mais complexa é trabalharmos com funções de estatísticas de ordem. Não temos um resultado simples para o caso de qualquer funções destas estatísticas. Mas, no exemplo a seguir, podemos encontrar um resultado interessante para o comportamento da diferença de estatísticas de ordem.\nExemplo 2.10 Sejam X_{(1)}, X_{(2)}, X_{(3)} as estatísticas de ordem das variáveis aleatórias independentes e igualmente distribuídas X1, X2, X3 com função de densidade comum { βe−xβ, se x ≥ 0 sendo β &gt; 0. Sejam Y1 = X_{(3)} − X_{(2)} e Y2 = X_{(2)}. Mostraremos que Y1 e Y2 são independentes. Para isso primeiro observemos que a função de densidade conjunta de X_{(2)} e X_{(3)} é dada por\nf23(x, y) =\n1!0!0!\n· 0, caso contrário\nA função de densidade conjunta de (Y1, Y2) é então f (y1, y2) = 3!β2(1 − e−y2β )e−y2βe−(y1+y2)β = [3!βe−2y2β (1 e−y2β )][βe−y1β ], se 0 &lt; y &lt; + , 0 &lt; y &lt; + = · 0, caso contrário Do qual segue que Y1 e Y2 são independentes. Duas estatísticas de ordem importantes são o máximo e mínimo. Nesses casos é possível encontrar, de maneira\nanalítica, expressões para a função de distribuição. Vejamos no teorema a seguir as expressões da função de distribuição das estatísticas de ordem X_{(1)} e X_{(n)}.\nDemonstração : Exercício.\nAcerca da função de distribuição de qualquer estatística de ordem temos o resultado a seguir.\nDemonstração : O evento {X(k) ≤ x} ocorre se, e somente se, pelo menos k dos \\(X_1, X_2, \\cdots , X_n\\) são menores ou iguais a x, por isso o somatório começa em k.\nNos dois teoremas seguintes relacionamos a distribuição condicional de estatísticas de ordem, condicionadas em outra estatística de ordem, com a distribuição de estatísticas de ordem de uma população cuja distribuição é uma forma truncada da função de distribuição da população original \\(F\\) .\nDemonstração : A densidade condicional de X(j) dado que X_{(i)} = xi calcula-se dividindo a densidade conjunta de X_{(i)} e X(j), dada em (2.7), pela densidade marginal de X_{(i)}, esta obtida no Teorema 2.4. Temos então que, quando\ni &lt; j ≤ n e xi ≤ xj &lt; ∞,\nf (xj|X_{(i)}\n= x ) = fij(xi, xj) i fi(xi) (n − i)! [ \\(F\\) (xj) − \\(F\\) (xi)]j−i−1\n[ 1 − \\(F\\) (xj)]n−j \\(F\\) (xj)\n(j − i − 1)!(n − j)! 1 − \\(F\\) (xi)\n1 − \\(F\\) (xi) 1 − \\(F\\) (xi)\nO resultado segue observando que \\(F\\) (xj ) − \\(F\\) (xi) e \\(F\\) (xj ) são, respectivamente, as funções de distribuição e de 1 − \\(F\\) (xi) 1 − \\(F\\) (xi) densidade truncando à esquerda em xi a distribuição \\(F\\) .\nNa demonstração do teorema anterior utiliza-se o conceito de distribuição truncada, o que é isso? define-se a seguir este conceito e incluem-se exemplos explicativos.\nCaso a variável aleatória X seja discreta com função de probabilidade P , a distribuição truncada de X é dada por\nP (X = x|X ∈ A) =\nP (X = x, X ∈ A) P (X ∈ A)\n=  \nP (X = x) P (X = a), se x ∈ A a∈A 0, se x ∈/ A\nNa situação X do tipo contínua, com função de densidade \\(F\\) , temos que\nP (X ≤ x|X ∈ A) =\nP (X ≤ x, X ∈ A) = P (X ∈ A)\n∫(−∞,x]∩A\nf (y) dy\n· (2.8)\nConcluindo então que, a função de densidade da distribuição truncada é dada por\nh(x) =\n ∫\nf (x) f (y) dy\n, caso x ∈ A,\n· (2.9)\n 0 A\ncaso x ∈/ A\nExemplo 2.11 Suponhamos X uma variável aleatória com distribuição normal padrão e A = ( , 0]. Então, P (X A) = 1/2, dado que X é simétrica e contínua. Para a densidade truncada temos que { 2f (x), caso − ∞ &lt; x ≤ 0,\nO truncamento é especialmente importante nos casos em que a distribuição \\(F\\) em questão não tem média finita. Se X é uma variável aleatória, truncamos X em algum c &gt; 0, onde c é finito, substituindo X por Xc = X caso |X| c e zero caso |X| &gt; c. Então Xc é X truncada em c e todos os momentos de Xc existem e são finitos. Na verdade, sempre podemos selecionar c suficientemente grande para que P (X ̸= Xc) = P (|X| &gt; c),\nseja arbitrariamente pequena. A distribuição de Xc é então dada por\nP (Xc ≤ x) = P (X ≤ x| |X| ≤ c) = no caso contínuo com função de densidade \\(F\\) e é dada por\nf (y) dy (−∞,x]∩[−c,+c] , P (|X| ≤ c)\nP (Xc = x) =\n \nP (X = x)\nP (X = a) a∈[−c,+c]\n, se x ∈ [−c, +c] ,\n0, se x ∈/ [−c, +c] no caso discreto. Observemos que, para algum α &gt; 0, E(|Xc|)α ≤ cα·\nExemplo 2.12 Caso X Cauchy(0, 1), sabemos que E(X) não existe. Seja c &gt; 0 um número finito, truncando X em c definimos\nEntão\nXc =\nX, caso |X| c, · 0, caso |X| &gt; c\n1 ∫ +c 1\n2 −1\nSendo que a função de densidade truncada é dada por\n 1 1\n1 , caso x ∈ [−c, +c],\nh(x) =\nDesta expressão obtemos que\n2 1 + x2 tan−1(c) ·  0, caso x ∈/ [−c, +c]\n1    ∫ +c   x   \ne também que\nE(Xc) =\n2 tan−1(c)\n−c 1 + x2\ndx = 0,\nE(Xc)2 =\n1    ∫ +c\nx2 dx =\nc   \n— 1·\n2 tan−1(c)\n−c 1 + x2\ntan−1(c)\nPor último, temos o seguinte resultado estabelecendo novamente relação entre estatísticas de ordem e distri- buições truncadas.\nDemonstração : A densidade condicional de X_{(i)} dado que X(j) = xj calcula-se dividindo a densidade conjunta de X_{(i)} e X(j), dada em (2.7), pela densidade marginal de X(j), esta obtida no Teorema 2.4. Temos então que, quando i &lt; j ≤ n e xi ≤ xj &lt; ∞, (j − i)! [ \\(F\\) (xi) ]i−1 [ \\(F\\) (xj) − \\(F\\) (xi)]j−i−1 \\(F\\) (xi) O resultado segue observando que \\(F\\) (xi)/F (xj) e \\(F\\) (xi)/F (xj) são, respectivamente, as funções de distribuição e de densidade truncando à direita em xj a distribuição \\(F\\) .\n\n2.3.1 2.2.2 Quantis\nLembremos que a função de distribuição \\(F\\) é contínua à direita e que o número de descontinuidades é, no máximo, enumerável. Estas são propriedades importantes que farão toda diferença na definição dos quantis amostrais, por isso, demonstraremos as propriedades mencionadas da função de distribuição. A prova de que \\(F\\) é contínua à direita advém do seguinte fato F (x + hn) − \\(F\\) (x) = P (x &lt; X ≤ x + hn), onde {hn} é uma sequência de números reais estritamente positivos tais que limn→∞ hn = 0. Segue, da propriedade de continuidade da função de probabilidade,1 que lim [F (x + hn) F (x)] = 0, n→∞ e, portanto, \\(F\\) é contínua à direita. Definamos por D o conjunto dos pontos de descontinuidade de \\(F\\) e seja D = {x ∈ D : P (X = x) ≥ 1 } , onde n é um inteiro positivo. Dado que \\(F\\) ( ) F ( ) = 1, o número de elementos em Dn não pode exceder n. Logicamente ∞ D = Dn n=1 e, então, o conjunto D é enumerável. Demonstrando-se assim a segunda propriedade importante mencionada da função de distribuição. Definimos a seguir o conceito de quantil teórico e depois mostramos a forma de cálculo.\n1A função de distribuição é contínua, devido a que P lim n→∞\nAn = lim n→∞\nP (An),\nse o limite limn→∞ An existir.\nA função \\(F\\) −1(t), 0 &lt; t &lt; 1 foi definida em (1.29) e é chamada de função inversa de \\(F\\) . O seguinte teorema fornece-nos propriedades úteis. Fica claro que as propriedades apresentadas no seguinte teorema nos permitirão o cálculo dos quantis e é por isso que dedicamos atenção a este conceito.\nDemonstração : Exercício.\nExemplo 2.13\nSeja X Exponencial(). Sabemos que a função de distribuição neste caso é \\(F\\) (x) = 1 e−x/. Resulta que a expressão de qualquer um dos quantis é possível de ser encontrada de maneira exata via\nobtendo-se que\nF (ξp) = p 1 − e−ξp/= p 1 − p = e−ξp/,\nξp = −ln(1 − p)\né a expressão teórica do p-ésimo quantil. Devemos mencionar que a expressão dos quantis está bem definida, no sentido de que o resultado é sempre positivo. Isto é importante porque devemos lembrar que a distribuição exponencial está definida somente para valores positivos, então o quantil teórico deve ser positivo, já que é um dos possíveis valores da variável. Observemos que caso \\(F\\) seja contínua e estritamente crescente, \\(F\\) −1 é definida como F −1(y) = x quando y = \\(F\\) (x)· Ainda podemos observar que, se x0 é um ponto de descontinuidade de \\(F\\) e supondo que F (x−) &lt; y &lt; \\(F\\) (x0) = \\(F\\) (x+) 0 0\nvemos que, embora não exista x tal que y = \\(F\\) (x), \\(F\\) −1(y) é definido como igual a x0. A situação na qual \\(F\\) não é estritamente crescente, por exemplo, caso da variável aleatória ser discreta, podemos escrever\nF (x) =\n= y, caso a ≤ x ≤ b ·  &gt; y, caso x &gt; b\nEntão, qualquer valor a x b poderia ser escolhido como x = \\(F\\) −1(y). A convenção é que, neste caso, definimos F −1(y) = a. Em particular ξ1/2 = \\(F\\) −1(1/2), (2.10) é chamada de mediana de \\(F\\) . Observemos que ξp satisfaz a desigualdade F (ξp− ) ≤ p ≤ \\(F\\) (ξp)· Exemplo 2.14 (Continuação do Exemplo 2.13) Caso p = 1/2, a mediana amostral será ξ1/2 = −ln(1/2) = 0.6931472.",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula04/index.html",
    "href": "ModuloI/Aula04/index.html",
    "title": "4  Função de Distribuição Empírica",
    "section": "",
    "text": "4.1 Exercícios",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Função de Distribuição Empírica</span>"
    ]
  },
  {
    "objectID": "ModuloI/Aula04/index.html#exercícios",
    "href": "ModuloI/Aula04/index.html#exercícios",
    "title": "4  Função de Distribuição Empírica",
    "section": "",
    "text": "Gere 100 observações a partir de uma distribuição \\(N(0,1)\\). Calcule uma faixa de confiança de 95% para a função de distribuição empírica \\(\\widehat{F}_n\\). Repita isso 1000 vezes e veja com que frequência a faixa de confiança contém a verdadeira função de distribuição. Repita usando dados de uma distribuição Cauchy.\nSeja \\(X_1,\\cdots, X_n\\) uma amostra aleatória da distribuição \\(F\\) e seja \\(\\widehat{F}_n\\) a função de distribuição empírica. Para um \\(x\\) fixo, encontre a distribuição limite de \\(\\sqrt{\\widehat{F}_n(x)}\\).\nSejam \\(x\\) e \\(y\\) dois pontos distintos. Encontre \\(\\mbox{Cov}\\Big(\\widehat{F}_n(x),\\widehat{F}_n(y)\\Big)\\).",
    "crumbs": [
      "Módulo I",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Função de Distribuição Empírica</span>"
    ]
  },
  {
    "objectID": "index.html#regras-gerais",
    "href": "index.html#regras-gerais",
    "title": "CE306 - Instrumentação Matemática para Estatística",
    "section": "Regras Gerais",
    "text": "Regras Gerais\nOlá Pessoal,\nDe acordo com o discutido em sala de aula segue algumas regras para o bom andamento do curso:\n\nAs aulas instrucionais serão realizadas de acordo com o cronograma abaixo na sala PA09. Nas terças o horário será das 19:00 às 20:30 e nas quintas o horário será das 20:45 às 22:15.\nAs avaliações serão todas realizadas na plataforma ufprvirtual.ufpr.br de acordo com o cronograma abaixo. Respeitando sempre os dias e horários destinados à disciplina. Só será permitida UMA tentativa.\nSerão realizadas 6 (seis) avaliações durante o semestre conforme cronograma abaixo.\nA nota final será composta da média aritmética das seis avaliações (todas com o mesmo peso).\nNas aulas instrucionais (16 aulas) e avaliações (6 aulas) a presença é OBRIGATÓRIA e será controlado pela chamada oral AO FINAL da aula.\nPara aprovação o aluno deverá comparecer em pelo menos 75% das aulas. De acordo com o cronograma em anexo o aluno deverá comparecer em pelo menos 16 (dezesseis) aulas para ter presença para aprovação.\nPara aprovação o aluno deverá obter média igual ou superior a 70 de acordo com o item 4. Caso a média fique entre 40 e 70 o aluno deverá realizar exame final. A média aritmética da nota do item 4 com a nota do exame final deverá ser maior que 50 para aprovação.\nSó será permitido realizar o exame final alunos que tenham presença suficiente para serem aprovados.\nO cronograma de atividades poderá ser modificado de acordo com o andamento do semestre.\nA mudança nos dias das avaliações deverá ser aceita pela maioria dos alunos presentes no dia da decisão (caso seja necessário).\n\nBom curso a todos.",
    "crumbs": [
      "Apresentação"
    ]
  },
  {
    "objectID": "index.html#sec-cronograma",
    "href": "index.html#sec-cronograma",
    "title": "CE306 - Instrumentação Matemática para Estatística",
    "section": "Cronograma",
    "text": "Cronograma\n\n\n\nData\nConteúdo\nLocal\nPresença\n\n\n\n\n27/02/24\nApresentação do curso\nPA09\nSim\n\n\n29/02/24\nMotivação\nPA09\nSim\n\n\n05/03/24\nFunções\nPA09\nSim\n\n\n07/03/24\nLimites e Continuidade\nPA09\nSim\n\n\n12/03/24\nExercícios\nLivre\nNão\n\n\n14/03/24\nAvaliação 1\nLAB12\nSim\n\n\n19/03/24\nDerivadas\nPA09\nSim\n\n\n21/03/24\nDerivadas\nPA09\nSim\n\n\n26/03/24\nDerivadas + Integrais + Exercicio\nPA09\nSim\n\n\n28/03/24\nExercícios\nLivre\nNão\n\n\n02/04/24\nExercícios\nLivre\nNão\n\n\n04/04/24\nAvaliação 2\nLAB12\nSim\n\n\n09/04/24\nVetores e Matrizes\nPA09\nSim\n\n\n11/04/24\nVetores e Matrizes\nPA09\nSim\n\n\n16/04/24\nExercícios\nLivre\nNão\n\n\n18/04/24\nAvaliação 3\nLAB12\nSim\n\n\n23/04/24\nSistemas lineares e decomposições\nPA09\nSim\n\n\n25/04/24\nSistemas Lineares e decomposições\nPA09\nSim\n\n\n30/04/24\nExercícos\nLivre\nNão\n\n\n02/05/24\nAvaliação 4\nLAB12\nSim\n\n\n07/05/24\nFolga\nLivre\nNão\n\n\n09/05/24\nSistemas não lineares\nPA09\nSim\n\n\n14/05/24\nDiferenciação numérica\nPA09\nSim\n\n\n16/05/24\nExercícios\nLivre\nNão\n\n\n21/05/24\nAvaliação 5\nLAB12\nSim\n\n\n23/05/24\nIntegração numérica\nPA09\nSim\n\n\n28/05/24\nOtimização numérica I\nPA09\nSim\n\n\n30/05/24\nRBRAS\nLivre\nNão\n\n\n04/06/24\nRBRAS\nLivre\nNão\n\n\n06/06/24\nOtimização numérica II\nPA09\nSim\n\n\n11/06/24\nExercícios\nLivre\nNão\n\n\n13/06/24\nExercícios\nLivre\nNão\n\n\n18/06/24\nAvaliação 6\nLAB12\nSim\n\n\n20/06/24\nFolga\nLivre\nNão\n\n\n25/06/24\nSemana de estudos\nLivre\nNão\n\n\n27/06/24\nSemana de estudos\nLivre\nNão\n\n\n02/07/24\nFinal\nLAB12\nSim",
    "crumbs": [
      "Apresentação"
    ]
  },
  {
    "objectID": "index.html#materiais-de-apoio-e-exercícios",
    "href": "index.html#materiais-de-apoio-e-exercícios",
    "title": "CE306 - Instrumentação Matemática para Estatística",
    "section": "Materiais de Apoio e Exercícios",
    "text": "Materiais de Apoio e Exercícios\nPessoal,\nPara cada avaliação eu criei um roteiro para você estudar. Você terá três momentos.\n\nLeitura prévia antes da aula;\nAula instrucional em sala de aula;\nLeitura pós aula;\nExercícios.\n\nO material base para você estudar é o meu livro “Matemática para Ciência de Dados” disponível neste endereço: http://leg.ufpr.br/~wagner/TMCD/\nMUITO CUIDADO! O livro pode não estar disponível no dia da avaliação. Por isso, estude antes!\n\nAvaliação 1:\n\nLeitura do Prefácio + Seção 1.1;\nAssistir e participar das aulas instrucionais;\nReler e refazer os exemplos da Seção 1.1;\nRealizar os exercícios disponíveis na Seção 1.5 referentes a funções, limites e continuidade.\n\n\n\nAvaliação 2:\n\nLeitura das Seções 1.2 e 1.3;\nAssistir e participar das aulas instrucionais;\nReler e refazer os exemplos das Seções 1.2 e 1.3.\nRealizar os exercícios disponíveis na Seção 1.5 referentes a derivadas, integrais e os desafios.\n\n\n\nAvaliação 3:\n\nLeitura das Seções 2.1 e 2.2;\nAssistir e participar das aulas instrucionais;\nReler e refazer os exemplos das Seções 2.1 e 2.2;\nRealizar os exercícios disponíveis na Seção 2.8 referentes vetores e escalares e Matrizes.\n\n\n\nAvaliação 4:\n\nLeitura das Seções 2.3, 2.4, 2.5 e 2.6;\nAssistir e participar das aulas instrucionais;\nReler e refazer os exemplos das Seções 2.3, 2.4, 2.5 e 2.6;\nRealizar os exercícios disponíveis na Seção 2.8 referentes a sistemas lineares e decomposições e o desafio.\n\n\n\nAvaliação 5:\n\nLeitura das Seções 3.1 e 3.2;\nAssistir e participar das aulas instrucionais;\nReler e refazer os exemplos das Seções 3.1 e 3.2;\nRealizar os exercícios disponíveis na Seção 3.6 referentes a equações não-lineares e diferenciação numérica.\n\n\n\nAvaliação 6:\n\nLeitura das Seções 3.3 e 3.4;\nAssistir e participar das aulas instrucionais;\nReler e refazer os exemplos das Seções 3.3 e 3.4;\nRealizar os exercícios disponíveis na Seção 3.6 referentes a integração numérica e otimização numérica.\n\nProf. Wagner",
    "crumbs": [
      "Apresentação"
    ]
  },
  {
    "objectID": "ModuloI/index.html#objetivos-e-público-alvo",
    "href": "ModuloI/index.html#objetivos-e-público-alvo",
    "title": "Prefácio",
    "section": "Objetivos e público alvo",
    "text": "Objetivos e público alvo\nO objetivo deste livro é fornecer aos profissionais das mais diversas áreas um texto introdutório e acessível em tópicos de matemática. Tais tópicos são a base fundamental para compreender e criar grande parte das técnicas de análise de dados, utilizadas por cientistas de dados para resolver problemas práticos diariamente. O objetivo não é ser exaustivo e nem matematicamente rigoroso, mas sim fornecer uma visão geral, intuitiva e muitas vezes computacional sobre os tópicos abordados, dando ênfase para as aplicações em ciência de dados. Além disso, este livro fornece um conjunto de conhecimentos básicos necessários para o estudo de técnicas avançadas de aprendizagem de máquina, tais como redes neurais, redes neurais profundas, modelos hierárquicos bayesianos ou de forma mais geral redes bayesianas probabilísticas.\nO uso de linguagens de programação é primordial em ciência de dados e neste livro utilizou-se a linguagem de programação R. Porém, a linguagem R será utilizada apenas com uma conotação pedagógica, a fim de materializar os conceitos matemáticos abstratos apresentados no texto. Em matemática é comum, quando um resultado importante é obtido, apresentá-lo na forma de um Teorema seguido de sua demonstração. Porém, nem sempre as implicações práticas do Teorema ficam claras para o leitor. Neste sentido, sempre que um resultado importante for apresentado neste material usaremos a linguagem R para ilustrar as suas implicações em termos práticos e como elas afetam as análises de dados.\nÉ importante salientar que este livro está longe de ser um guia prático para a análise de dados ou uma espécie de livro de receitas em que para cada situação um conjunto de procedimentos é apresentado acompanhado do respectivo código de uma ferramenta computacional. Pelo contrário, salvo pelos exemplos motivadores, o livro enfatiza as ferramentas necessárias e em como combiná-las para criar as técnicas de análise de dados. Os objetivos desta abordagem são:\n\ndesmistificar o processo pelos quais os algoritmos resolvem problemas, por exemplo de previsão e classificação;\nmostrar que apesar de existir um conjunto enorme de técnicas, muitas delas são apenas pequenas modificações ou seguem as mesmas premissas de outras e que portanto, entendendo a base o leitor está apto a entender as demais;\npromover um uso qualificado das ferramentas já disponíveis, ou seja, não apenas usar uma rotina computacional já implementada em algum software e interpretar a saída, mas também compreender em linhas gerais o que está sendo realizado dentro do software e naturalmente as limitações e escolhas que devem ser feitas durante as implementações computacionais.\n\nO público-alvo são profissionais que desejam uma introdução acessível aos fundamentos de matemática necessários para o profundo entendimento das técnicas utilizadas por cientistas de dados. Formações usuais destes profissionais incluem, mas não estão limitadas à engenharia, ciência da computação, economia, física, administração, gestão da informação e tecnologia em análise e desenvolvimento de sistemas.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "ModuloI/index.html#seleção-dos-tópicos",
    "href": "ModuloI/index.html#seleção-dos-tópicos",
    "title": "Prefácio",
    "section": "Seleção dos tópicos",
    "text": "Seleção dos tópicos\nSelecionar os principais tópicos para servir ao objetivo deste livro não foi uma tarefa simples. Para tal tarefa nós imaginamos o que gostaríamos que o leitor fosse capaz de entender após ler o livro. Assim, consideramos dois livros fantásticos os quais recomendamos para qualquer um que tenha interesse em técnicas avançadas de ciência de dados, são eles:\n\nDeep Learning, Ian Goodfellow and Yoshua Bengio and Aaro Courville, MIT Press, 2016.\nMathematics for Machine Learning, Marc Peter Deisenroth, A. Aldo Faisal and Cheng Soon Ong, Cambridge, 2019.\n\nAmbos são excelentes livros. O primeiro é focado em deep learning, mas com uma bela introdução sobre tópicos de matemática necessários para o entendimento do livro e uma ampla visão da área de aprendizado de máquina com uma conclusão a respeito das perspectivas da pesquisa na área de deep learning. O segundo é uma descrição impecável da matemática por trás de algumas das principais técnicas de ciência de dados, como análise de componentes principais e máquinas de vetor de suporte.\nPorém, nenhum deles é acessível para grande parte dos profissionais que não são da área de aprendizado de máquina, estatística ou matemática aplicada. Sendo assim, buscamos incluir neste livro grande parte dos conceitos de cálculo diferencial e integral, álgebra matricial e métodos numéricos necessários para uma qualificada apreciação de ambos. O texto foi escrito utilizando o sistema para análise reproduzível knitr. Por meio da linguagem de marcação markdown e a estrutura de livro fornecida pelo pacote bookdown dentro da linguagem R. W.H.B\nCuritiba, Janeiro, 2021.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Prefácio",
    "section": "",
    "text": "Contexto e motivação\nA transformação digital pela qual a sociedade está passando, aliada ao maior acesso a dispositivos tecnológicos como smartphones e tablets conectados à internet vêm revolucionando a forma como vivemos. Neste contexto, as empresas de tecnologia não demoraram para criar diversos produtos em que o lucro é gerado baseado nos dados de seus clientes. Exemplos deste mercado de dados incluem e-mails gratuitos, mídias sociais, plataformas de divulgação de vídeos, portais de informação e busca, entre outros.\nSeguindo esta tendência, empresas de praticamente todos os seguimentos estão procurando em seus dados formas de otimizar a sua operação e gerar mais lucro. Neste cenário de transformação digital surge a profissão do cientista de dados. Este profissional é o responsável por usar métodos científicos para entender e criar valor baseado em dados. Devido a sua flexibilidade e o momento em que vivemos, o profissional de ciência de dados está em alta demanda pelo mercado de trabalho, sendo um dos profissionais mais bem remunerados. Consequentemente, profissionais de outras áreas estão interessados em migrar para a área de ciência de dados e para isto estão procurando por formação adicional.\nA profissão denominada de cientista de dados é extremamente nova e definições precisas sobre as habilidades de tal profissional estão em pleno desenvolvimento. Isto dificulta a formação de profissionais nesta área. Além de ser um desafio para instituições de ensino desenharem cursos que respondam as reais necessidades do mercado de trabalho. Uma busca rápida por ofertas de empregos para cientistas de dados traz uma lista enciclopédica de habilidades que vão desde ferramentas tecnológicas baseadas em softwares proprietários, passando por diversas linguagens de programação, até chegar em algoritmos específicos de aprendizagem de máquina e modelos estatísticos.\nQuando focamos apenas nas diversas técnicas que compõem a caixa de ferramentas do cientista de dados, nos deparamos com uma infinidade de modelos e algoritmos. De forma semelhante, livros que tem no título a expressão ciência de dados ou, mais geralmente, na língua Inglesa Data Science trazem um grande conjunto de técnicas que incluem pelo menos uma ampla gama de modelos estatísticos e de aprendizagem de máquina. Alguns livros chegam a trazer modelos para processamento de linguagem natural, análise de redes, dados espaciais entre outros. Esta grande quantidade de técnicas para análise de dados que faz parte do dia-a-dia do cientista de dados torna-se intimidante para profissionais de outras áreas que buscam um reposicionamento como cientistas de dados. Além disso, é um grande desafio desenhar cursos para tais profissionais, uma vez que não está claro quais são as técnicas que devem receber maior atenção e discutir todas as técnicas em uso pelos cientistas de dados é um trabalho impossível.\nPor outro lado, a grande maioria das técnicas e algoritmos utilizados em aplicações de ciência de dados são herdadas de outras áreas, principalmente da estatística e da ciência da computação, que por sua vez estão alicerçadas em disciplinas básicas da matemática do ensino superior, tais como, cálculo diferencial integral, álgebra matricial e métodos numéricos. Tais disciplinas são conhecidas por muitos profissionais das áreas de engenharia, economia, administração, tecnologia e análise de desenvolvimento de sistemas entre outros. Porém, a forma como tais disciplinas são ministradas nos diversos programas de graduação, bem como a junção destas disciplinas na criação de uma única técnica, torna difícil para tais profissionais identificarem suas aplicações nas ferramentas de análise de dados.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "content/index.html#objetivos-e-público-alvo",
    "href": "content/index.html#objetivos-e-público-alvo",
    "title": "Prefácio",
    "section": "Objetivos e público alvo",
    "text": "Objetivos e público alvo\nO objetivo deste livro é fornecer aos profissionais das mais diversas áreas um texto introdutório e acessível em tópicos de matemática. Tais tópicos são a base fundamental para compreender e criar grande parte das técnicas de análise de dados, utilizadas por cientistas de dados para resolver problemas práticos diariamente. O objetivo não é ser exaustivo e nem matematicamente rigoroso, mas sim fornecer uma visão geral, intuitiva e muitas vezes computacional sobre os tópicos abordados, dando ênfase para as aplicações em ciência de dados. Além disso, este livro fornece um conjunto de conhecimentos básicos necessários para o estudo de técnicas avançadas de aprendizagem de máquina, tais como redes neurais, redes neurais profundas, modelos hierárquicos bayesianos ou de forma mais geral redes bayesianas probabilísticas.\nO uso de linguagens de programação é primordial em ciência de dados e neste livro utilizou-se a linguagem de programação R. Porém, a linguagem R será utilizada apenas com uma conotação pedagógica, a fim de materializar os conceitos matemáticos abstratos apresentados no texto. Em matemática é comum, quando um resultado importante é obtido, apresentá-lo na forma de um Teorema seguido de sua demonstração. Porém, nem sempre as implicações práticas do Teorema ficam claras para o leitor. Neste sentido, sempre que um resultado importante for apresentado neste material usaremos a linguagem R para ilustrar as suas implicações em termos práticos e como elas afetam as análises de dados.\nÉ importante salientar que este livro está longe de ser um guia prático para a análise de dados ou uma espécie de livro de receitas em que para cada situação um conjunto de procedimentos é apresentado acompanhado do respectivo código de uma ferramenta computacional. Pelo contrário, salvo pelos exemplos motivadores, o livro enfatiza as ferramentas necessárias e em como combiná-las para criar as técnicas de análise de dados. Os objetivos desta abordagem são:\n\ndesmistificar o processo pelos quais os algoritmos resolvem problemas, por exemplo de previsão e classificação;\nmostrar que apesar de existir um conjunto enorme de técnicas, muitas delas são apenas pequenas modificações ou seguem as mesmas premissas de outras e que portanto, entendendo a base o leitor está apto a entender as demais;\npromover um uso qualificado das ferramentas já disponíveis, ou seja, não apenas usar uma rotina computacional já implementada em algum software e interpretar a saída, mas também compreender em linhas gerais o que está sendo realizado dentro do software e naturalmente as limitações e escolhas que devem ser feitas durante as implementações computacionais.\n\nO público-alvo são profissionais que desejam uma introdução acessível aos fundamentos de matemática necessários para o profundo entendimento das técnicas utilizadas por cientistas de dados. Formações usuais destes profissionais incluem, mas não estão limitadas à engenharia, ciência da computação, economia, física, administração, gestão da informação e tecnologia em análise e desenvolvimento de sistemas.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "content/index.html#seleção-dos-tópicos",
    "href": "content/index.html#seleção-dos-tópicos",
    "title": "Prefácio",
    "section": "Seleção dos tópicos",
    "text": "Seleção dos tópicos\nSelecionar os principais tópicos para servir ao objetivo deste livro não foi uma tarefa simples. Para tal tarefa nós imaginamos o que gostaríamos que o leitor fosse capaz de entender após ler o livro. Assim, consideramos dois livros fantásticos os quais recomendamos para qualquer um que tenha interesse em técnicas avançadas de ciência de dados, são eles:\n\nDeep Learning, Ian Goodfellow and Yoshua Bengio and Aaro Courville, MIT Press, 2016.\nMathematics for Machine Learning, Marc Peter Deisenroth, A. Aldo Faisal and Cheng Soon Ong, Cambridge, 2019.\n\nAmbos são excelentes livros. O primeiro é focado em deep learning, mas com uma bela introdução sobre tópicos de matemática necessários para o entendimento do livro e uma ampla visão da área de aprendizado de máquina com uma conclusão a respeito das perspectivas da pesquisa na área de deep learning. O segundo é uma descrição impecável da matemática por trás de algumas das principais técnicas de ciência de dados, como análise de componentes principais e máquinas de vetor de suporte.\nPorém, nenhum deles é acessível para grande parte dos profissionais que não são da área de aprendizado de máquina, estatística ou matemática aplicada. Sendo assim, buscamos incluir neste livro grande parte dos conceitos de cálculo diferencial e integral, álgebra matricial e métodos numéricos necessários para uma qualificada apreciação de ambos. O texto foi escrito utilizando o sistema para análise reproduzível knitr. Por meio da linguagem de marcação markdown e a estrutura de livro fornecida pelo pacote bookdown dentro da linguagem R. W.H.B\nCuritiba, Janeiro, 2021.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html",
    "href": "content/Modulo01/index.html",
    "title": "1  Cálculo Diferencial e Integral",
    "section": "",
    "text": "1.1 Funções, limites e continuidade\nPara motivar a ideia de funções imagine que você vai até um agente de seguros para fazer o seguro do seu carro. O agente de seguros com certeza irá fazer uma série de perguntas sobre o veículo, você e seus hábitos. Exemplos usuais de perguntas incluem a sua idade, sexo, estado civil, qual o uso do veículo, onde você costuma estacionar além do modelo e ano do veículo. A partir destas questões a seguradora faz algum processamento, ou seja, usa um modelo para avaliar o risco que você traz para a companhia e consequentemente calcula o valor que você deve pagar pelo seu seguro.\nO importante é você notar o fluxo das informações. Existe um conjunto de entradas: as respostas que você forneceu. Estas respostas são submetidas a algum processamento e ao final existe uma saída, neste caso o preço do seguro. A Figura 1.1 fornece uma ilustração simples da ideia de função.\nFigure 1.1: Ilustração de função.\nNa ilustração da Figura 1.1 as variáveis de entrada foram genericamente denotadas por \\(x_1\\), \\(x_2\\), \\(x_3\\), \\(\\ldots\\), \\(x_p\\) o que significa que temos \\(p\\) entradas. No exemplo do seguro as entradas são as respostas para as \\(p\\) perguntas. As respostas são processadas dentro da função e então uma saída \\(y\\) é gerada. Esta ideia simples pode ser adaptada para uma infinidade de situações práticas no contexto de análise preditiva, classificação, agrupamento entre outras. Alguns exemplos são a concessão de crédito, detecção de potenciais clientes, detecção de softwares ou operações maliciosas entre diversas outras.\nPara qualificar um pouco nosso entendimento de funções é importante entender que tipo de números podem ser inseridos na função e que tipo de número ou números a função deve resultar. Os números racionais são os números da forma \\(\\frac{a}{b}\\), sendo \\(a\\) e \\(b\\) inteiros e \\(b \\neq 0\\). Denotamos o conjunto dos números racionais por \\(\\mathbb{Q}\\), ou seja,\n\\[\n\\mathbb{Q} = \\left \\{ \\frac{a}{b} | a, b \\in \\mathbb{Z}, b \\neq 0 \\right \\}\n\\]\nonde \\(\\mathbb{Z} = \\{\\ldots, -3, -2, -1, 0, 1,2,3, \\ldots \\}\\) é o conjunto dos números inteiros. A notação acima é lida da seguinte forma: \\(\\mathbb{Q}\\) é o conjunto dos números \\(a\\) dividido por \\(b\\), tais que \\(a\\) e \\(b\\) são inteiros e \\(b\\) é diferente de zero. Note que a divisão por zero não é definida. De forma similar, indicamos por \\(\\mathbb{N}\\) o conjunto dos números naturais:\n\\[\n\\mathbb{N} = \\{0,1,2,3,\\ldots \\}.\n\\]\nNão é possível escrever todos os números como a razão entre dois números inteiros, então ao conjunto de números que não são racionais chamamos de irracionais. Por fim, a união de todos os tipos de números mencionados anteriormente, chamamos de números reais e denotamos por \\(\\Re\\). De forma geral, em ciência de dados, vamos fazer distinção apenas entre os números inteiros, os quais algumas vezes estaremos interessados apenas nos não-negativos, ou seja os naturais, e os números reais. Esta distinção também é usada na maioria das linguagens de programação e o R não é uma exceção. Com este conjunto de conceitos estamos aptos a definir o que é uma função.\nNa Definição 1.1 temos a variável de entrada \\(x\\), também chamada de variável independente ou argumento da função \\(f(\\cdot)\\). O conjunto de valores que \\(x\\) pode assumir é chamado de domínio de \\(f(x)\\) e denotamos por \\(D\\). Como resultado da aplicação da função no ponto \\(x\\) temos \\(y\\), que é chamada de variável dependente. A imagem de f(x) denotada por \\(I\\) é a faixa de valores que \\(y\\) pode assumir. Note que em geral o domínio e a imagem são intervalos definidos em termos dos tipos de números que já discutimos: naturais, inteiros, racionais, irracionais, reais ou possíveis intervalos dentro destes. Por exemplo, o intervalo \\((0,1)\\) representa o conjunto dos números reais entre \\(0\\) e \\(1\\), sendo que ambos \\(0\\) e \\(1\\) não pertencem ao intervalo. Em termos de notação temos o seguinte:\n\\[\n\\begin{equation*}\n\\xrightarrow[\\text{Independente}]{x \\quad \\in \\quad D} f(x) \\xrightarrow[\\text{Dependente}]{y \\quad \\in \\quad I}.\n\\end{equation*}\n\\]\nComo já mencionado, a imagem e o domínio de uma função são intervalos. Neste texto vamos fazer distinção entre intervalos aberto e fechado usando a seguinte notação:\nEm linguagem R podemos definir ou criar uma função de forma muito similar ao que fizemos em termos de notação matemática. A partir deste momento, recomendamos que você escolha o seu editor favorito de R como por exemplo o RStudio ou qualquer outro e comece a executar os códigos que serão apresentados no decorrer do texto. Veja a estrutura de uma função em R no Código 1.1.\nCódigo 1.1 Estrutura de função em R.\nminha_funcao &lt;- function(x) {\n  y &lt;- 'algum processamento com x'\n  return(y)\n}\nNo Código 1.1 definimos uma função chamada de minha_funcao. Esta função recebe uma entrada x, faz algum processamento com x, armazena o resultado deste processamento em um objeto chamado y e retorna o valor de y. Interessante notar que grande parte das linguagens interpretadas como R e python são automaticamente tipificadas. Isso significa que não precisamos definir o tipo de valores que serão as entradas e saídas das nossas funções. Isto está em contraste com outras linguagens como C e C++ em que o programador precisa definir o tipo das entradas e das saídas no corpo da função.\nPara materializar esta ideia definimos a função \\(y = x^2\\), ou seja, para cada entrada de \\(x\\) retornamos \\(y\\) que é o quadrado da entrada. Em R temos a seguinte função:\nminha_funcao &lt;- function(x) {\n  y &lt;- x^2\n  return(y)\n}\nCriada a função podemos avaliá-la em alguns pontos para ver o seu comportamento. Por exemplo, \\(f(x = 2)\\) significa avaliar a função no ponto \\(x = 2\\), ou seja, \\(y = 2^2\\) e portanto, \\(y = 4\\). Usando nossa função R temos:\nminha_funcao(x = 2)\n\n[1] 4\nMuitas das operações em R são automaticamente vetorizadas, isso significa que podemos aplicar a função em um vetor de números e obter um vetor de resposta. O conceito de vetor será propriamente definido no Capítulo 2. Por enquanto, interprete um vetor como vários números enfileirados de modo que queremos fazer uma operação com cada um de seus elementos. Para definir um vetor de números em R usamos o operador de concatenação c(). Veja o seguinte exemplo,\nx_vec &lt;- c(-3, -2, -1, 0, 1, 2, 3)\nminha_funcao(x = x_vec)\n\n[1] 9 4 1 0 1 4 9\nO objeto x_vec é um vetor com os números inteiros entre \\(-3\\) até \\(3\\) e aplicamos nossa função a cada um destes números. Note que a saída é um outro vetor de mesmo tamanho do vetor de entrada com a função aplicada a cada um de seus elementos. Neste ponto é interessante falar sobre alguns tipos de objetos em R. Em termos de números temos basicamente os inteiros integer e os reais double. Em geral, se não especificada outra opção, qualquer número vai ser tipificado como double. Para verificar o tipo de um objeto em R usamos a função typeof(). Por exemplo,\n## Define um double (real)\nx &lt;- 1811\ntypeof(x)\n\n[1] \"double\"\n## Define um inteiro explicitamente, note o \"L\" após o número\nx &lt;- 1811L\ntypeof(x)\n\n[1] \"integer\"\nOutra questão importante é o tipo do objeto de saída.\n## Entrada inteiro\ny &lt;- minha_funcao( x = 2L)\ntypeof(y)\n\n[1] \"double\"\n## Entrada double\ny &lt;- minha_funcao( x = 2)\ntypeof(y)\n\n[1] \"double\"\nQuando colocados juntos em um vetor valores integer e double o integer será convertido para double e o objeto gerado terá classe numeric.\nx_vec &lt;- c(2L,  2)\ntypeof(x_vec)\n\n[1] \"double\"\nclass(x_vec)\n\n[1] \"numeric\"\nUma função \\(y = f(x)\\) é dita ser de apenas uma variável e pode ser facilmente desenhada em um espaço bidimensional, o chamado \\(\\Re^2\\). O espaço \\(\\Re^2\\) é formado por todas as duplas ordenadas de valores reais. A variável dependente \\(y\\) é representada no eixo vertical e a variável dependente \\(x\\) é representada no eixo horizontal. Em R a função plot() é a forma mais simples de desenhar o gráfico de uma função. O código abaixo ilustra como desenhar o gráfico da função \\(y = x^2\\) avaliada nos inteiros entre \\(-5\\) e \\(5\\).\n## Criando a função\nminha_funcao &lt;- function(x) {\n  y &lt;- x^2\n  return(y)\n}\n\n## Valores que a função será avaliada\nx_vec &lt;- c(-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5)\n\n## Avaliando a função em cada ponto\ny &lt;- minha_funcao(x = x_vec)\n\n## Gráfico da função\nplot(y ~ x_vec, xlab = \"x\", ylab = expression(y = f(x)))\n\n\n\n\n\n\n\nFigure 1.2: Exemplo de gráfico de função avaliada em alguns pontos.\nÉ comum desenhar o gráfico da função unindo os pontos para dar a noção de continuidade (conceito a ser explicado adiante).\nplot(y ~ x_vec, xlab = \"x\", ylab = expression(y = f(x)), type = \"l\")\n\n\n\n\n\n\n\nFigure 1.3: Exemplo de gráfico de função unindo os pontos de avaliação.\nNo contexto de ciência de dados precisamos de funções um pouco mais elaboradas, o que nos leva as funções parametrizadas e a definição de parâmetro.\nEm geral, os parâmetros mudam o comportamento da função e descrevem quantidades de interesse. Nós vamos usar a notação: \\(y = f(x; \\theta)\\), onde \\(\\theta\\) denota o parâmetro. O conjunto de valores que \\(\\theta\\) pode assumir é chamado de espaço paramétrico e denotado por \\(\\Theta\\). Considere a seguinte função parametrizada \\(y = (x - \\theta)^2\\) cuja versão em R é dada abaixo.\nfx = function(x, theta) {\n  out &lt;- (x - theta)^2\n  return(out)\n}\nPara avaliar esta função precisamos de \\(x\\) e também do valor do parâmetro \\(\\theta\\). A Figura 1.4 mostra o gráfico da função \\(y = (x - \\theta)^2\\) avaliada nos pontos \\(x = (-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5)\\) e \\(\\theta = (-2, 0, 2)\\). É importante notar que, em geral, o parâmetro de uma função será uma quantidade conhecida e fixa, ou seja, não será modificado quando a entrada \\(x\\) for alterada.\nFigure 1.4: Exemplo de função parametrizada.\nNa Figura 1.4 fica claro que o valor do parâmetro \\(\\theta\\) controla o ponto onde a função \\(f(x; \\theta)\\) toca o eixo horizontal, ou seja, este parâmetro controla um aspecto importante da função. De forma mais geral uma função pode ter vários parâmetros. O ideal é que cada parâmetro controle um aspecto da função. No entanto, na prática isso nem sempre é possível. Em termos de notação usamos \\(f(x; \\boldsymbol{\\theta})\\) onde \\(\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\ldots, \\theta_p)^{\\top}\\) em que \\(p\\) denota o número de elementos no vetor de parâmetros \\(\\boldsymbol{\\theta}\\). A notação utilizada corresponde ao transposto do vetor de parâmetros e ficará clara no Capítulo (AM). Considere a seguinte função de dois parâmetros \\[y = \\frac{(x - \\theta_1)^2 }{\\theta_2},\\] cujo gráfico é apresentado na Figura 1.5 para algumas combinações dos parâmetros \\(\\theta_1\\) e \\(\\theta_2\\). Para desenhar o gráfico da Figura 1.5 precisamos primeiro criar a função em R. Note que agora temos dois parâmetros, assim\nfx = function(x, theta) {\n  out &lt;- ((x - theta[1])^2)/theta[2]\n  return(out)\n}\ndefine a função onde o objeto theta é um vetor de tamanho \\(2\\). É importante notar que para acessar os elementos de um vetor em R usamos o nome do vetor acompanhado de [posicao] onde posicao é um número inteiro indicando a posição do elemento de interesse no vetor. O código abaixo avalia a função em alguns pontos para diferentes combinações dos parâmetros e desenha os gráficos.\npar(mar=c(2.6, 2.8, 1.2, 0.5), mgp = c(1.6, 0.6, 0))\nx &lt;- c(-5,-4,-3,-2,-1,0,1,2,3,4,5)\npar(mfrow = c(1,3))\ntt &lt;- c(expression(theta[1] == -2), expression(theta[1] == 0), \n        expression(theta[1] == 2))\ntheta1 &lt;- c(-2,0,2)\nfor(i in 1:3) {\nplot(fx(x, theta = c(theta1[i], 1)) ~ x, xlab = \"x\", \n     ylab = expression(y = f(x,theta)), \n     type = \"o\", ylim = c(0,50), main = tt[i])\npoints(x, fx(x, theta = c(theta1[i], 0.75)), col = \"red\")\nlines(x, fx(x, theta = c(theta1[i], 0.75)), col = \"red\")\npoints(x, fx(x, theta = c(theta1[i], 0.5)), col = \"blue\")\nlines(x, fx(x, theta = c(theta1[i], 0.5)), col = \"blue\")\nlegend(\"top\", legend = c(expression(theta[2] == 1), \n                  expression(theta[2] == 0.75), \n                  expression(theta[2] == 0.5)),\n       col = c(\"black\",\"red\",\"blue\"), pch = 1 , lty = 1)\n}\n\n\n\n\n\n\n\nFigure 1.5: Exemplos de gráficos de funções com dois parâmetros.\nNote que enquanto o parâmetro \\(\\theta_1\\) continua controlando onde a função toca o eixo horizontal, o parâmetro \\(\\theta_2\\) controla a abertura da curva definida por \\(f(x; \\boldsymbol{\\theta})\\). Assim, valores maiores de \\(\\theta_2\\) representam curvas mais abertas. Outros aspectos importantes do gráfico de funções são a declividade e o intercepto.\nA declividade mede a variação \\(\\Delta\\) no valor de \\(y\\) dividido pela variação no valor de \\(x\\), ou seja, declividade é \\(\\frac{\\Delta y}{\\Delta x}\\). A declividade do desenho de uma função pode ser constante, positiva ou negativa. Lembre-se que gráficos são lidos da esquerda para a direita. O intercepto vertical é o ponto no qual o gráfico cruza o eixo vertical e é obtido quando \\(x = 0\\).\nA Figura 1.6 mostra exemplos de retas com declividade constante (A), positiva (B) e negativa (C). Procure identificar onde estão os interceptos.\nFigure 1.6: Exemplos de declividade.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cálculo Diferencial e Integral</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html#introdução",
    "href": "content/Modulo01/index.html#introdução",
    "title": "2  Estatística Não Paramétrica",
    "section": "",
    "text": "Métodos não-paramétricos exigem poucas suposições sobre as populações subjacentes das quais os dados são obtidos. Em particular, os procedimentos não paramétricos abandonam a suposição tradicional de que as populações subjacentes sejam normais.\nOs procedimentos não paramétricos permitem que o usuário obtenha p-valores exatos para testes, probabilidades de cobertura exatas para intervalos de confiança, taxas exatas de erros experimentais para procedimentos de comparação múltipla e probabilidades exatas de cobertura para faixas de confiança sem confiar nas suposições de que as populações subjacentes sejam normais.\nAs técnicas não paramétricas são frequentemente, embora nem sempre, mais fáceis de aplicar do que as suas contrapartes teóricas normais.\nOs procedimentos não paramétricos são geralmente muito fáceis de entender.\nEmbora, à primeira vista, a maioria dos procedimentos não- paramétricos pareça sacrificar muito as informações básicas nas amostras, investigações de eficiência teórica mostraram que esse não é o caso. Normalmente, os procedimentos não-paramétricos são apenas ligeiramente menos eficientes do que os seus concorrentes de teoria normal quando as populações subjacentes são normais e podem ser moderadamente ou muito mais eficientes que os concorrentes quando as populações subjacentes não são normais.\n\n\n\nMétodos não paramétricos são relativamente insensíveis a observações distantes.\nOs procedimentos não paramétricos são aplicáveis em muitas situações em que os procedimentos teóricos normais não podem ser utilizados. Muitos procedimentos não-paramétricos exigem apenas as classificações das observações em vez da magnitude real das observações, enquanto os procedimentos paramétricos exigem as magnitudes.\nNem todos os procedimentos desenvolvidos na estatística paramétrica podem ser aplicados à estatística não-paramétrica.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatística Não Paramétrica</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html",
    "href": "content/Modulo02/index.html",
    "title": "2  Álgebra Matricial",
    "section": "",
    "text": "2.1 Vetores e escalares\nEm termos de notação nós vamos usar letras minúsculas em negrito, por exemplo,\n\\[\n\\mathbf{a} = \\begin{pmatrix}\na_1 & \\ldots & a_n\n\\end{pmatrix} \\quad \\text{ou} \\quad \\mathbf{a} = \\begin{pmatrix}\na_1 \\\\\n\\vdots \\\\\na_n\n\\end{pmatrix}.\n\\]\nQuando os elementos estão organizados em linha dizemos que temos um vetor linha. Por outro lado, quando os elementos estão organizados em coluna dizemos que temos um vetor coluna. Um elemento do vetor é chamado de \\(a_i\\), sendo \\(i\\) a posição do elemento no vetor. O tamanho de um vetor é o seu número de elementos.\nO módulo de um vetor é o seu comprimento\n\\[\n|\\mathbf{a}| = \\sqrt{a_1^2 + \\ldots + a_n^2}.\n\\]\nO vetor unitário é o vetor com comprimento \\(1\\). Podemos padronizar um vetor qualquer para ter tamanho \\(1\\) dividindo cada elemento do vetor pelo seu comprimento,\n\\[\n\\hat{\\mathbf{a}} =  \\frac{\\mathbf{a}}{|\\mathbf{a}|}.\n\\]\nDizemos que dois vetores são iguais se têm o mesmo tamanho e se todos os seus elementos em posições equivalentes são iguais.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Álgebra Matricial</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#amostras-aleatórias",
    "href": "content/Modulo02/index.html#amostras-aleatórias",
    "title": "2  Estatísticas de Ordem",
    "section": "",
    "text": "Definição. Seja \\(X\\) uma variável aleatória com função de distribuição \\(F\\) e \\(X_1, \\cdots, X_n\\) variáveis aleatórias independentes com distribuição comum \\(F\\). Chamaremos a coleção \\(X_1, \\cdots, X_n\\) de uma amostra aletória de tamanho \\(n\\) de \\(F\\) ou simplesmente como \\(n\\) observações independentes de \\(X\\).\n\n\n\n\nDefinição. Sejam \\(X_1, X_2, \\cdots, X_n\\) \\(n\\) observações independentes da variável aleatória \\(X\\) e seja \\(g: \\mathbb{R}^n \\to \\mathbb{R}\\) uma função real derivável. Então a variável aleatória \\(g(X_1, X_2, \\cdots, X_n)\\) é chamada de estatística, desde que não dependa de parâmetros desconhecidos.\n\n\n\nDefinição. Seja \\(X_1, X_2, \\cdots, X_n\\) uma amostra aleatória da função de distribuição \\(F\\). A estatística \\[\\overline{X}_n = \\sum_{i=1}^{n} \\displaystyle \\frac{Xi}{n},\\] é chamada de média amostral e a estatística \\[S_{n}^{2} = \\sum_{i=1}^{n} \\displaystyle \\frac{(X_i - \\overline{X}_n)^2}{n-1}\\] é chama de variância amostral.\n\n\n\n\n\n\n\n\n\n\nFigura 2.1: Representação da função de distribuição Bernoulli para três valores do parâmetro \\(p\\) = 0.3, 0.5 e 0.8. Observe que nesta curva a reta no intervalo (0, 1) depende de 1 - \\(p\\), isso porque a função \\(\\delta\\) é sempre zero para \\(x\\) - 1 nesse intervalo.",
    "crumbs": [
      "Prefácio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#estatísticas-de-ordem",
    "href": "content/Modulo02/index.html#estatísticas-de-ordem",
    "title": "2  Estatísticas de Ordem",
    "section": "2.2 Estatísticas de ordem",
    "text": "2.2 Estatísticas de ordem\nSeja \\((X_1, X_2, \\cdots , X_n)\\) um vetor aleatório n-dimensional e \\((x_1, x_2, \\cdots , x_n)\\) uma \\(n\\)-tupla assumida por \\((X_1, X_2, \\cdots , X_n)\\). Vamos organizar \\(x_1, x_2, \\cdots , x_n\\) em ordem crescente de magnitude, para que \\[x_{(1)}\\le x_{(2)} \\le \\cdots ≤ x_{(n)},\\] onde \\(x_{(1)}\\) = min\\((x_1, x_2, \\cdots , x_n)\\), \\(x_{(2)}\\) é o segundo menor valor em \\(x_1, \\cdots , x_n\\) e assim por diante, \\(x_{(n)}\\) = max\\((x_1, \\cdots , x_n)\\). Se quaisquer dois \\(x_i\\), \\(x_j\\) forem iguais, a ordem não importa.\n\nDefinição. A função \\(X_{(k)}\\) de \\((X_1, \\cdots ,X_n)\\) que assume o valor \\(x_{(k)}\\) em cada possível sequência \\((x_1, x_2, \\cdots , x_n)\\) de valores assumidos por \\((X_1,X_2, \\cdots , X_n)\\) é conhecida como a \\(k\\)-ésima estatística de ordem ou a estatística de ordem \\(k\\). O conjunto \\((X_{(1)},X_{(2)}, \\cdots , X_{(n)})\\) é chamado de estatísticas de ordem para \\((X_1, X_2, \\cdots , X_n)\\).\n\nExemplo. Consideremos \\(X_1\\), \\(X_2\\), \\(X_3\\) três variáveis aleatórias discretas de maneira que, \\(X_1\\) e \\(X_3\\) sejam tais que assumam somente valores 0, 1 e que \\(X_2\\) assuma valores 1, 2, 3. O vetor aleatório \\((X_1\\), \\(X_2\\), \\(X_3)\\) assume os valores: (0, 1, 0), (0, 2, 0), (0, 3, 0), (0, 1, 1), (0, 2, 1), (0, 3, 1), (1, 1, 0), (1, 2, 0), (1, 3, 0), (1, 1, 1), (1, 2, 1) e (1, 3, 1). Então \\(X_{(1)}\\) assume somente valores 0 ou 1; \\(X_{(2)}\\) assume somente valores 0 ou 1 e \\(X_{(3)}\\) assume somente valores 1, 2 ou 3.\n\n\n\n\n\n\nTeorema 2.1\n\n\n\nSeja \\((X_{(1)}, X_{(2)}, \\cdots , X_{(n)})\\) um vetor aleatório de dimensão \\(n\\) e seja \\(X_{(k)}, 1 \\le k \\le n\\), a \\(k\\)-ésima estatística de ordem. Então \\(X_{(k)}\\) é também uma variável aleatória.\n\n\nExercício. Na apresentação dos resultados a seguir assumiremos que \\(X_1, X_2, \\cdots , X_n\\) são variáveis aleatórias independentes e igualmente distribuídas contínuas com função de densidade \\(f\\) . Seja \\(\\{ X_{(1)}, X_{(2)}, \\cdots , X_{(n)} \\}\\) o conjunto das estatística de ordem para \\(X_1, X_2, \\cdots , X_n\\). Dado que todas as \\(X_i\\) são contínuas segue que, com probabilidade 1 \\[X_{(1)} \\le X_{(2)} \\le \\cdots \\le X_{(n)}·\\]\n\n2.2.1 Propriedades das estatísticas de ordem\nComeçaremos o estudo das propriedades encontrando a função de densidade conjunta de \\((X_{(1)}, X_{(2)}, \\cdots , X_{(n)})\\).\n\n\n\n\n\n\nTeorema 2.2\n\n\n\nSejam \\(X_1, \\cdots, X_n\\) variáveis aleatórias contínuas independentes, igualmente distríbuidas com densidade \\(f\\). A função de desindade conjunta de \\((X_{(1)}, \\cdots, X_{(n)})\\) é dada por \\[\nf(x_{(1)}, \\ldots, x_{(n)}) =\n\\begin{cases}\nn! \\prod\\limits_{i=1}^{n} f(x_{(i)}), & \\text{se } x_{(1)} &lt; x_{(2)} &lt; \\cdots &lt; x_{(n)} \\\\\n0, & \\text{caso contrário}\n\\end{cases}.\n\\]\n\n\nDemonstração: A transformação de \\((X_1, \\cdots , X_n)\\) a \\((X_{(1)}, \\cdots , X_{(n)})\\) não é biunívoca. De fato, existem um total de \\(n!\\) possíveis arranjos de \\(x_1, \\cdots , x_n\\) em ordem crescente de magnitude. Assim, existem \\(n!\\) inversas para a transformação.\nPor exemplo, uma das \\(n!\\) permutações pode ser \\[\nx_4 &lt; x_1 &lt; x_{n−1} &lt; x_3 &lt; \\cdots &lt; x_n &lt; x_2·\n\\]\nA inversa correspondente é \\[\nx_4 = x_{(1)}, x_1 = x_{(2)}, \\ x_{n−1} = x_{(3)}, \\ x_3 = x_{(4)} \\cdots x_n = x_{(n−1)}, \\ x_2 = x_{(n)}·\n\\] O determinante Jacobiano desta transformação é a matriz \\(n \\times n\\) identidade com as colunas reorganizadas, isto devido a que cada \\(x_{(i)}\\) é igual a uma, e somente uma, das \\(x_1, x_2, \\cdots , x_n\\). Portanto \\(J = \\pm 1\\) e\n\\[\nf (x_{(2)}, \\ x_{(n)}, \\ x_{(4)}, \\ x_{(1)}, \\ \\cdots , \\ x_{(3)}, \\ x_{(n−1)}) \\ \\mid J \\mid =\n\\prod\\limits_{i=1}^{n} \\ f(x_{(i)}),\n\\]\nquando \\(x_{(1)} &lt; x_{(2)} &lt; \\cdots &lt; x_{(n)}\\). A mesma expressão é válida para cada um dos \\(n!\\) arranjos. Segue então que\n\\[\n\\begin{align*}\nf(x_{(1)}, \\ldots, x_{(n)}) &= \\sum \\prod\\limits_{i=1}^{n} f(x_{(i)}) \\\\\n&\\ \\ \\ \\ \\ \\ \\text{Todas as } n! \\text{ permutações} \\\\\n& = \\begin{cases}\nn! \\prod\\limits_{i=1}^{n} f(x_{(i)}), & \\text{se } x_{(1)} &lt; x_{(2)} &lt; \\cdots &lt; x_{(n)} \\\\\n0, & \\text{caso contrário}\n\\end{cases}.\n\\end{align*}\n\\]\nExemplo. Sejam \\(X_1, \\cdots , X_n\\) variáveis aleatórias independentes com função de densidade comum \\[\nf(x) =\n\\begin{cases}\n1, & \\text{se } 0 &lt; x &lt; 1 \\\\\n0, & \\text{caso contrário}\n\\end{cases}.\n\\] Então a função de densidade conjunta de \\(X_{(1)}, X_{(2)}, \\cdots , X_{(n)}\\) é \\[\nf(x_{(1)}, \\ \\cdots, \\ x_{(n)}) =\n\\begin{cases}\nn!, & \\text{se } 0 &lt; x_{(1)} &lt; x_{(2)} &lt; \\cdots &lt; x_{(n)} \\\\\n0, & \\text{caso contrário}\n\\end{cases}.\n\\]\nEstamos confiados que como resultado do Teorema 2.2 temos funções de densidade. Vejamos neste exemplo se isso é realmente acontece. Consideremos, para simplificar, o caso \\(n\\) = 3 e verifiquemos se a integral da função de densidade é 1. Então\n\\[\n\\begin{align*}\n\\int \\int\\limits_\\mathbb{R} \\int f(x_{(1)},x_{(2)},x_{(3)}) \\ dx_{(1)}dx_{(2)}dx_{(3)})\n& = 6 \\int_{0}^1 \\left[\\int_{x_{(1)}}^1 \\left(\\int_{x_{(2)}}^1 dx_{(3)} \\right) dx_{(2)} \\right] dx_{(1)} \\\\\n& = 6 \\int_{0}^1 \\left[\\int_{x_{(1)}}^1 \\left(1 - x_{(2)} \\right) dx_{(2)} \\right] dx_{(1)} \\\\\n& = 6 \\int_{0}^1 \\left[\\frac{1}{2} - x_{(1}) + \\frac{x^2_{(1)}}{2} \\right] dx_{(1)} = 1. \\\\\n\\end{align*}\n\\]\nUm detalhe interessante é que esta e outras propriedades demonstradas aqui somente são válidas quando as variáveis aleatórias são contínuas. Isso não significa que estatísticas de ordem não possam ser definidas no caso discreto. O que estamos dizendo é que estas propriedades somente podem ser demonstradas no caso contínuo.\nExemplo. Consideremos a situação em que temos somente três variáveis aleatórias independentes \\(X_1\\), \\(X_2\\) e \\(X_3\\) com distribuição geométrica de parâmetro \\(p\\), isto é,\n\\[\nP (X = x; p) = (1 − p)p^x, \\ \\ \\ \\ \\    x = 0, 1, 2, \\cdots\n\\] Encontremos \\(P (X_{(1)} &lt; X_{(2)} &lt; X_{(3)})\\). Nesta situação a probabilidade requerida pode ser escrita como: \\[\n\\begin{align*}\nP (X_{(1)} &lt; X_{(2)} &lt; X_{(3)})  =  1 − P (X_1 = X_2 \\neq X_3) − P (X_1 = X_3 \\neq X_2) \\\\\n−P (X_2 = X_3 \\neq X_1) − P (X_1 = X_2 = X_3)\n\\end{align*}\n\\] a qual pode ser escrita como \\[\n\\begin{align*}\nP (X_{(1)} &lt; X_{(2)} &lt; X_{(3)})\n& = 1 − 3P (X_1 = X_2 \\neq X_3) − P (X_1 = X_2 = X_3) \\\\\n& = 1 − 3 [P (X_1 = X_2) − P (X_1 = X_2 = X_3)] − P (X_1 = X_2 = X_3) \\\\\n& = 1 − 3P (X_1 = X_2) + 2P (X_1 = X_2 = X_3)· \\\\\n\\end{align*}\n\\]\nNão é difícil perceber que \\[\nP(X_1 = X_2) = \\frac{(1-p)^2}{1-p^2},\n\\]\ne que \\[\nP(X_1 = X_2 = X_3) = \\frac{(1-p)^3}{1-p^3},\n\\]\ndo qual obtemos que \\[\nP(X_{(1)} = X_{(2)} = X_{(3)}) = \\frac{6p^3}{(1-p)(1+p+p^2)}.\n\\] As propriedades das estatísticas de ordem que serão demonstradas valerão somente caso as variáveis sejam contínuas. Isto deve-se a que, caso as variáveis sejam discretas, a probabilidade\n\\[\nP (X_{(1)} = X_{(2)} = \\cdots = X_{(n)}) \\neq 0,\n\\]\ncomo vai ser mostrado no seguinte exemplo. Acontece que o fato da probabilidade das estatística de ordem poderem coincidir, com probabilidade diferente de zero, altera a estrutura da demonstração e não nos permite obtermos estes resultados para o caso discreto.\nExemplo. Sejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias independentes assumindo somente 0 e 1 com probabilidade 1/2. Observemos que \\[\n\\begin{align*}\nP(X_{(1)} = X_{(2)} = \\cdots = X_{(n)})\n& = \\prod\\limits_{k=1}^{n} P(X_{(k)} = 0) + \\prod\\limits_{k=1}^{n} P(X_{(k)} = 1)  \\\\\n& = \\prod\\limits_{k=1}^{n} P(X_{(k)} = 0) + \\prod\\limits_{k=1}^{n} P(X_{k} = 1) = \\frac{1}{2^{n-1}} . \\\\\n\\end{align*}\n\\]\nEstudemos agora o comportamento marginal, ou seja, nos interessa agora encontrar a função de distribuição marginal de cada estatística de ordem.\n\n\n\n\n\n\nTeorema 2.3\n\n\n\nSejam \\(X_1, \\cdots, X_n\\) variáveis aleatórias contínuas independentes e igualmente distribuídas e \\((X_{(1)}, \\cdots, X_{(n)})\\) as estatísticas de ordem. A função de densidade marginal de \\(X_{(r)}\\) é dada por \\[\nf_r(x_{(r)}) = \\frac{n!}{(r-1)!(n-r)!}[F(x_{(r)})]^{r-1}[1-F(x_{(r)})]^{n-r}f(x_{(r)}),\n\\] onde \\(F\\) é a função de distribuição comum de \\(X_1, \\cdots, X_n\\).\n\n\nDemonstração : Partimos da expressão da função de densidade conjunta das estatísticas de ordem obtida no Teorema 2.2. Então,\n$$ \\[\\begin{align*}\nf_r(x_{(r)})\n& = n!f(x_{(r)})  \n\\int_{-\\infty}^{x_{(r)}} \\int_{-\\infty}^{x_{(r-1)}} \\cdots\n\\int_{-\\infty}^{x_{(2)}} \\int_{x_{(r)}}^{+\\infty} \\int_{x_{(r+1)}}^{+\\infty} \\cdots\n\\int_{x_{(n-1)}}^{+\\infty}\n\\prod\\limits_{i \\neq r}^{n} f(t_i) \\\n\\text{d}t_n \\cdots\\text{d}t_{r+1} \\ \\text{d}t_{1} \\cdots \\text{d}t_{r-1}  \\\\\n\n& = n!f(x_{(r)})\n\\frac{[1-F(x_{(r)})]^{n-r}}{(n-r)!}\n\\int_{-\\infty}^{x_{(r)}} \\cdots\n\\int_{x_{(-\\infty)}}^{x_{(2)}}\n\\prod\\limits_{i =1}^{r-1} f(t_i) \\ \\text{d}t_i \\\\\n\n& = n!f(x_{(r)})\n\\frac{[1-F(x_{(r)})]^{n-r}}{(n-r)!}\n\\frac{[F(x_{(r)})]^{r-1}}\n{(r-1)!}.\n\n\\end{align*}\\]\\end{align*} $$\nComo utilidade deste teorema podemos mencionar o fato de agora podermos encontrar os momentos das estatística de ordem. Faremos isso como consequência do seguinte exemplo.\nExemplo. Sejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias independentes \\(U\\) (0, 1). Então $$ f_r(x_{(r)}) =\n\\[\\begin{cases}\n\\frac{n!}{(r-1)!(n-r)!} x_{(r)}^{r-1}(1-x_{(r)})^{n-r},\n& \\text{se } 0 &lt; x_{(r)} &lt; 1 \\\\\n\n& \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  (1 \\leq r \\leq n) \\\\\n0, & \\text{caso contrário}\n\\end{cases}\\]\n. $$\nObservemos que, na situação do exemplo acima,\n\\[\nX_{(r)} \\sim \\beta(r, n − r + 1),\n\\]\nlogo, valem os resultados da distribuição Beta e, por exemplo,\n\\[\nE(X_{(r)}) = r/(n + 1)·\n\\]\nPara uma densidade qualquer e somente quatro variáveis aleatórias a forma da densidade marginal, de uma qualquer estatística de ordem, é mostrada no seguinte exemplo.\nExemplo. Sejam \\(X_1, X_2, X_3 ,X_4\\) variáveis aleatórias independentes com densidade comum \\(f\\). A função de densidade conjunta das estatísticas de ordem \\(X_{(1)}, X_{(2)}, X_{(3)}, X_{(4)}\\) é\n$$ f(x_{(1)}, x_{(2)}, x_{(3)}, x_{(4)}) =\n\\[\\begin{cases}\n4!f (x_{(1)})f (x_{(2)})f (x_{(3)})f (x_{(4)}),\n& \\text{se }    x_{(1)} &lt; x_{(2)} &lt; x_{(3)} &lt; x_{(4)} \\\\\n\n0,  \n& \\text{caso contrário}\n\\end{cases}\\]\n. $$\nVamos calcular a função de densidade marginal de \\(X_{(2)}\\). Temos que, se \\(x_{(1)} &lt; x_{(2)} &lt; x_{(3)} &lt; x_{(4)}\\)\n$$ \\[\\begin{align*}\nf2(x_{(2)})\n& =  4! \\int \\int \\int \\int f(t_1) f(x_{(2)}) f(t_3) f(t_4)\n\\ \\text{d}t_1 \\ \\text{d}t_3 \\ \\text{d}t_4 \\\\\n\n& =  4! f(x_{(2)})\n\\int_{-\\infty}^{x_{(2)}}\n\\int_{2}^{+\\infty}\n\\left[\\int_{t_3}^{+\\infty} f(t_4) \\ \\text{d}t_4\\right]\nf(t_3) f(t_1) \\ \\text{d}t_3 \\ \\text{d}t_1  \\\\\n\n& =  4! f(x_{(2)})\n\\int_{-\\infty}^{x_{(2)}}\n\\Biggl\\{\n\\int_{x_{(2)}}^{+\\infty}[1 - F(t_3)]f(t_3) \\text{d}t_3\n\\Biggl\\}\nf{(t_1)} \\text{d}t_1\\\\\n\n& =  4! f(x_{(2)})\n\\int_{-\\infty}^{x_{(2)}}\n\\frac{[1-F(x_{(2)})]^2}{2}\nf(t_1) \\ \\text{d}t_1 =\n4! f(x_{(2)})\n\\frac{[1-F(x_{(2)})]^2}{2}\nF(x_{(2)})\n\n·\n\\end{align*}\\] $$\nEvidentemente, a expressão acima coincide com o resultado apresentado no Teorema 2.3.",
    "crumbs": [
      "Prefácio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#pg8",
    "href": "content/Modulo02/index.html#pg8",
    "title": "2  Estatísticas de Ordem",
    "section": "2.3 pg8",
    "text": "2.3 pg8\nDemonstração :\nfrs(x(r), x(s)) =\n∫ x(r)\n∫ t2\n∫ x(s)\n∫ x(s) ∫ +∞\n∫ +∞\n−∞ −∞\nx(r)\nts−2\nx(s)\ntn−1\nn!f (t1) \\(F\\) (tn) dtn dts+1 dts−1 dtr+1 dt1 dtr−1\n= n!\n∫ x(r)\n∫ t2\n∫ x(s)\n∫ x(s) [1 − \\(F\\) (x(s))]n−s\n−∞ −∞\nx(r)\nts−2\n(n − s)!\n×f (t1)f (t2) \\(F\\) (x(s)) dts−1 dtr+1 dt1 dtr−1\n= n!\n[1 − \\(F\\) (x(s))]n−s (n − s)! f (x(s))\nx(r)\n−∞\nt2 f (t1) \\(F\\) (x(r))× −∞\n[F (x(s)) − \\(F\\) (x(r))]s−r−1 × (s − r − 1)! dt1 dtr−1\nn!  \n= (n − s)!(s − r − 1)![1 − \\(F\\) (x\n\n\n\n)]n−s×\n[F (x(r))]r−1\ncaso x(r) &lt; x(s).\n×[F (x(s)) − \\(F\\) (x(r))]s−r−1f (x(s))f (x(r))\n, (r − 1)!\nDe modo semelhante, podemos mostrar que a função de densidade conjunta de X(k1), , X(km) se 1 ≤ k1 &lt;\nk2 &lt; &lt; km ≤ n, 1 ≤ m ≤ n, é dada por fk1k2···km (x(k1), x(k2), , x(km)) =\n(k1\n— 1)!(k2\n— k1\nn! × — 1)! × (n − km)!\n×Fk1−1(x(k ))f (x(k ))[F (x(k )) − \\(F\\) (x(k ))]k2−k1−1f (x(k )) × × ×[F (x(k )) − \\(F\\) (x(k ))]km−1−km−2−1f (x(k ))[1 − \\(F\\) (x(k ))]n−km \\(F\\) (x(k )), caso x(k1) &lt; x(k2) &lt; &lt; x(km) e zero noutras situações.\nExemplo 2.9 (Continuação do Exemplo 2.7) Sabemos que as variáveis aleatórias \\(X_1, X_2, \\cdots , X_n\\) são independentes e tem como função de densidade comum f (x) = 1, se 0 &lt; x &lt; 1 · 0, caso contrário Então, a função de densidade conjunta de X(r) e X(s) é dada por\nfrs\n(x(r)\n, x(s)) =\n n!\nxr−1(x(r) − x(s))s−r−1(1 − x(s))n−s (r − 1)!(s − r − 1)!(n − s)!\n, se x\n\n\n\n&lt; x(s) ·\n\nonde 1 ≤ r &lt; s ≤ n.\n0, caso contrário\nUma situação mais complexa é trabalharmos com funções de estatísticas de ordem. Não temos um resultado simples para o caso de qualquer funções destas estatísticas. Mas, no exemplo a seguir, podemos encontrar um resultado interessante para o comportamento da diferença de estatísticas de ordem.\nExemplo 2.10 Sejam X_{(1)}, X_{(2)}, X_{(3)} as estatísticas de ordem das variáveis aleatórias independentes e igualmente distribuídas X1, X2, X3 com função de densidade comum { βe−xβ, se x ≥ 0 sendo β &gt; 0. Sejam Y1 = X_{(3)} − X_{(2)} e Y2 = X_{(2)}. Mostraremos que Y1 e Y2 são independentes. Para isso primeiro observemos que a função de densidade conjunta de X_{(2)} e X_{(3)} é dada por\nf23(x, y) =\n1!0!0!\n· 0, caso contrário\nA função de densidade conjunta de (Y1, Y2) é então f (y1, y2) = 3!β2(1 − e−y2β )e−y2βe−(y1+y2)β = [3!βe−2y2β (1 e−y2β )][βe−y1β ], se 0 &lt; y &lt; + , 0 &lt; y &lt; + = · 0, caso contrário Do qual segue que Y1 e Y2 são independentes. Duas estatísticas de ordem importantes são o máximo e mínimo. Nesses casos é possível encontrar, de maneira\nanalítica, expressões para a função de distribuição. Vejamos no teorema a seguir as expressões da função de distribuição das estatísticas de ordem X_{(1)} e X_{(n)}.\nDemonstração : Exercício.\nAcerca da função de distribuição de qualquer estatística de ordem temos o resultado a seguir.\nDemonstração : O evento {X(k) ≤ x} ocorre se, e somente se, pelo menos k dos \\(X_1, X_2, \\cdots , X_n\\) são menores ou iguais a x, por isso o somatório começa em k.\nNos dois teoremas seguintes relacionamos a distribuição condicional de estatísticas de ordem, condicionadas em outra estatística de ordem, com a distribuição de estatísticas de ordem de uma população cuja distribuição é uma forma truncada da função de distribuição da população original \\(F\\) .\nDemonstração : A densidade condicional de X(j) dado que X_{(i)} = xi calcula-se dividindo a densidade conjunta de X_{(i)} e X(j), dada em (2.7), pela densidade marginal de X_{(i)}, esta obtida no Teorema 2.4. Temos então que, quando\ni &lt; j ≤ n e xi ≤ xj &lt; ∞,\nf (xj|X_{(i)}\n= x ) = fij(xi, xj) i fi(xi) (n − i)! [ \\(F\\) (xj) − \\(F\\) (xi)]j−i−1\n[ 1 − \\(F\\) (xj)]n−j \\(F\\) (xj)\n(j − i − 1)!(n − j)! 1 − \\(F\\) (xi)\n1 − \\(F\\) (xi) 1 − \\(F\\) (xi)\nO resultado segue observando que \\(F\\) (xj ) − \\(F\\) (xi) e \\(F\\) (xj ) são, respectivamente, as funções de distribuição e de 1 − \\(F\\) (xi) 1 − \\(F\\) (xi) densidade truncando à esquerda em xi a distribuição \\(F\\) .\nNa demonstração do teorema anterior utiliza-se o conceito de distribuição truncada, o que é isso? define-se a seguir este conceito e incluem-se exemplos explicativos.\nCaso a variável aleatória X seja discreta com função de probabilidade P , a distribuição truncada de X é dada por\nP (X = x|X ∈ A) =\nP (X = x, X ∈ A) P (X ∈ A)\n=  \nP (X = x) P (X = a), se x ∈ A a∈A 0, se x ∈/ A\nNa situação X do tipo contínua, com função de densidade \\(F\\) , temos que\nP (X ≤ x|X ∈ A) =\nP (X ≤ x, X ∈ A) = P (X ∈ A)\n∫(−∞,x]∩A\nf (y) dy\n· (2.8)\nConcluindo então que, a função de densidade da distribuição truncada é dada por\nh(x) =\n ∫\nf (x) f (y) dy\n, caso x ∈ A,\n· (2.9)\n 0 A\ncaso x ∈/ A\nExemplo 2.11 Suponhamos X uma variável aleatória com distribuição normal padrão e A = ( , 0]. Então, P (X A) = 1/2, dado que X é simétrica e contínua. Para a densidade truncada temos que { 2f (x), caso − ∞ &lt; x ≤ 0,\nO truncamento é especialmente importante nos casos em que a distribuição \\(F\\) em questão não tem média finita. Se X é uma variável aleatória, truncamos X em algum c &gt; 0, onde c é finito, substituindo X por Xc = X caso |X| c e zero caso |X| &gt; c. Então Xc é X truncada em c e todos os momentos de Xc existem e são finitos. Na verdade, sempre podemos selecionar c suficientemente grande para que P (X ̸= Xc) = P (|X| &gt; c),\nseja arbitrariamente pequena. A distribuição de Xc é então dada por\nP (Xc ≤ x) = P (X ≤ x| |X| ≤ c) = no caso contínuo com função de densidade \\(F\\) e é dada por\nf (y) dy (−∞,x]∩[−c,+c] , P (|X| ≤ c)\nP (Xc = x) =\n \nP (X = x)\nP (X = a) a∈[−c,+c]\n, se x ∈ [−c, +c] ,\n0, se x ∈/ [−c, +c] no caso discreto. Observemos que, para algum α &gt; 0, E(|Xc|)α ≤ cα·\nExemplo 2.12 Caso X Cauchy(0, 1), sabemos que E(X) não existe. Seja c &gt; 0 um número finito, truncando X em c definimos\nEntão\nXc =\nX, caso |X| c, · 0, caso |X| &gt; c\n1 ∫ +c 1\n2 −1\nSendo que a função de densidade truncada é dada por\n 1 1\n1 , caso x ∈ [−c, +c],\nh(x) =\nDesta expressão obtemos que\n2 1 + x2 tan−1(c) ·  0, caso x ∈/ [−c, +c]\n1    ∫ +c   x   \ne também que\nE(Xc) =\n2 tan−1(c)\n−c 1 + x2\ndx = 0,\nE(Xc)2 =\n1    ∫ +c\nx2 dx =\nc   \n— 1·\n2 tan−1(c)\n−c 1 + x2\ntan−1(c)\nPor último, temos o seguinte resultado estabelecendo novamente relação entre estatísticas de ordem e distri- buições truncadas.\nDemonstração : A densidade condicional de X_{(i)} dado que X(j) = xj calcula-se dividindo a densidade conjunta de X_{(i)} e X(j), dada em (2.7), pela densidade marginal de X(j), esta obtida no Teorema 2.4. Temos então que, quando i &lt; j ≤ n e xi ≤ xj &lt; ∞, (j − i)! [ \\(F\\) (xi) ]i−1 [ \\(F\\) (xj) − \\(F\\) (xi)]j−i−1 \\(F\\) (xi) O resultado segue observando que \\(F\\) (xi)/F (xj) e \\(F\\) (xi)/F (xj) são, respectivamente, as funções de distribuição e de densidade truncando à direita em xj a distribuição \\(F\\) .\n\n2.3.1 2.2.2 Quantis\nLembremos que a função de distribuição \\(F\\) é contínua à direita e que o número de descontinuidades é, no máximo, enumerável. Estas são propriedades importantes que farão toda diferença na definição dos quantis amostrais, por isso, demonstraremos as propriedades mencionadas da função de distribuição. A prova de que \\(F\\) é contínua à direita advém do seguinte fato F (x + hn) − \\(F\\) (x) = P (x &lt; X ≤ x + hn), onde {hn} é uma sequência de números reais estritamente positivos tais que limn→∞ hn = 0. Segue, da propriedade de continuidade da função de probabilidade,1 que lim [F (x + hn) F (x)] = 0, n→∞ e, portanto, \\(F\\) é contínua à direita. Definamos por D o conjunto dos pontos de descontinuidade de \\(F\\) e seja D = {x ∈ D : P (X = x) ≥ 1 } , onde n é um inteiro positivo. Dado que \\(F\\) ( ) F ( ) = 1, o número de elementos em Dn não pode exceder n. Logicamente ∞ D = Dn n=1 e, então, o conjunto D é enumerável. Demonstrando-se assim a segunda propriedade importante mencionada da função de distribuição. Definimos a seguir o conceito de quantil teórico e depois mostramos a forma de cálculo.\n1A função de distribuição é contínua, devido a que P lim n→∞\nAn = lim n→∞\nP (An),\nse o limite limn→∞ An existir.\nA função \\(F\\) −1(t), 0 &lt; t &lt; 1 foi definida em (1.29) e é chamada de função inversa de \\(F\\) . O seguinte teorema fornece-nos propriedades úteis. Fica claro que as propriedades apresentadas no seguinte teorema nos permitirão o cálculo dos quantis e é por isso que dedicamos atenção a este conceito.\nDemonstração : Exercício.\nExemplo 2.13\nSeja X Exponencial(). Sabemos que a função de distribuição neste caso é \\(F\\) (x) = 1 e−x/. Resulta que a expressão de qualquer um dos quantis é possível de ser encontrada de maneira exata via\nobtendo-se que\nF (ξp) = p 1 − e−ξp/= p 1 − p = e−ξp/,\nξp = −ln(1 − p)\né a expressão teórica do p-ésimo quantil. Devemos mencionar que a expressão dos quantis está bem definida, no sentido de que o resultado é sempre positivo. Isto é importante porque devemos lembrar que a distribuição exponencial está definida somente para valores positivos, então o quantil teórico deve ser positivo, já que é um dos possíveis valores da variável. Observemos que caso \\(F\\) seja contínua e estritamente crescente, \\(F\\) −1 é definida como F −1(y) = x quando y = \\(F\\) (x)· Ainda podemos observar que, se x0 é um ponto de descontinuidade de \\(F\\) e supondo que F (x−) &lt; y &lt; \\(F\\) (x0) = \\(F\\) (x+) 0 0\nvemos que, embora não exista x tal que y = \\(F\\) (x), \\(F\\) −1(y) é definido como igual a x0. A situação na qual \\(F\\) não é estritamente crescente, por exemplo, caso da variável aleatória ser discreta, podemos escrever\nF (x) =\n= y, caso a ≤ x ≤ b ·  &gt; y, caso x &gt; b\nEntão, qualquer valor a x b poderia ser escolhido como x = \\(F\\) −1(y). A convenção é que, neste caso, definimos F −1(y) = a. Em particular ξ1/2 = \\(F\\) −1(1/2), (2.10) é chamada de mediana de \\(F\\) . Observemos que ξp satisfaz a desigualdade F (ξp− ) ≤ p ≤ \\(F\\) (ξp)· Exemplo 2.14 (Continuação do Exemplo 2.13) Caso p = 1/2, a mediana amostral será ξ1/2 = −ln(1/2) = 0.6931472.",
    "crumbs": [
      "Prefácio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#momentos-amostrais",
    "href": "content/Modulo02/index.html#momentos-amostrais",
    "title": "2  Estatísticas de Ordem",
    "section": "2.4 Momentos amostrais",
    "text": "2.4 Momentos amostrais\nNesta seção vamos estudar algumas estatísticas amostrais comumente utilizadas e suas distribuições.\nObservemos que nFn(x) é o número de Xk (1 ≤ k ≤ n) menores ou iguais a x. Se X_{(1)}, X_{(2)}, , X_{(n)} são as estatísticas de ordem de \\(X_1, X_2, \\cdots , X_n\\) então claramente\nFn(x) =  \nk , se X n\n\n\n\n≤ x &lt; X\n(k+1)\n, (k = 1, 2, , n − 1)\n· (2.11)\n 1, se x ≥ X_{(n)}\ncom esperança e variância\nVar[Fb\nE[Fn(x)] = \\(F\\) (x) (2.13)\nF (x)[1 − \\(F\\) (x)]\nDemonstração : Dado que δ(x − Xi), i = 1, 2, , n são variáveis aleatórias independentes igualmente distribuídas cada uma com função de probabilidade P [δ(x − Xi) = 1] = P (x − Xi ≥ 0) = \\(F\\) (x) e P [δ(x − Xi) = 0] = 1 − \\(F\\) (x), sua soma nF ∗(x) é uma variável aleatória com distribuição Binomial(n, p), onde p = \\(F\\) (x). As relações (2.12), (2.13) e (2.14) seguem-se imediatamente.\nDemonstração :\nE´ uma consequência da Lei dos Grandes Números .\nCorolário 2.12\nonde Z ∼ N (0, 1).\n√n[F (x) F (x)] √F (x)[1 − \\(F\\) (x)] −→ Z quando n → ∞,\nDemonstração :\nE´ consequência do Teorema do Limite Central.\nExemplo 2.15\nVamos apresentar o conceito de função distribuição empírica no caso de termos uma amostra aleatória da distribuição N (0, 1). A lista de comandos na linguagem de programação R está disponível abaixo. O primeiro comando destina-se a fixar o gerador de amostras e, assim, em qualquer momento podemos obter a mesma amostra aleatória. Na Figura 2.2 mostramos a forma da distribuição empírica, de três formas diferentes, para uma amostra de tamanho 12. A representação da função de distribuição empírica é realizada permitindo escolher qual utilizar segundo o agrado.\nlwd = 2\n−1.5 −1.0 −0.5 0.0 0.5\nx\n−1.5 −1.0 −0.5 0.0 0.5\nx\n−1.5 −1.0 −0.5 0.0 0.5\nx\nFigura 2.2: Representação da função de distribuição amostral ou empírica, de três formas diferentes, para uma amostra normal padrão de tamanho 12.\nA linhas de comando a seguir permitiram-nos gerar os gráficos na Figura 2.2: construímos : set.seed(5739); x=rnorm(12); Fn=ecdf(x) par(mar=c(5,4,3,1), cex=0.9) plot(Fn, main=““) plot(Fn, verticals = TRUE, do.points = FALSE, main=”“) plot(Fn , lwd = 2, main=”“); mtext(”lwd = 2”, adj = 1) xx=unique(sort(c(seq(-3, 2, length = 201), knots(Fn12)))) lines(xx, Fn(xx), col = “blue”) abline(v = knots(Fn), lty = 2, col = “gray70”) Observemos que a convergência da distribuição empírica, segundo o Teorema 2.10, é para cada valor de x. E´ possível fazer uma demonstração da convergência em probabilidade simultaneamente para todos os x, ou seja, da convergência uniforme.\nDemonstração : Seja ϵ &gt; 0. Escolhemos um inteiro k &gt; 1/ϵ e números −∞ = x0 &lt; x1 ≤ x2 ≤ ≤ xk−1 &lt; xk = ∞, tais que \\(F\\) (x−) ≤ j/k ≤ \\(F\\) (xj), para j = 1, , k − 1. Observe que se xj−1 &lt; xj, então\nPela Lei dos Grandes Números\nF (x−) − \\(F\\) (xj−1) ≤ ϵ·\nq.c. Fn(xj) −→ \\(F\\) (xj) e — q.c. −\npara j = 1, , k − 1. Consequentemente,\nFbn(xj ) −→ \\(F\\) (xj ),\n∗ − q.c. ∆n = max{|Fbn(xj) − \\(F\\) (xj)|, |Fn (xj ) − \\(F\\) (xj)|, j = 1, , k − 1} −→ 0·\nSeja x arbitrário e encontremos j tal que xj−1 &lt; x ≤ xj. Então, Fbn(x) − \\(F\\) (x) ≤ Fbn(x−) − \\(F\\) (xj−1) ≤ Fbn(x−) − \\(F\\) (x−) + ϵ,\ne\nIsto implica que\nFbn(x) − \\(F\\) (x) ≥ Fbn(xj−1) − \\(F\\) (x−) ≥ Fbn(xj−1) − \\(F\\) (xj−1) − ϵ·\nq.c. sup |Fn(x) F (x)| ∆n + ϵ ϵ· x Como isso vale para todo ϵ &gt; 0, o teorema segue.\nAgora, dado que \\(F\\) ∗(x) tem pontos de salto em Xi, i = 1, 2, , n é claro que existem todos os momentos de \\(F\\) ∗(x). Vamos considerar alguns valores típicos da função de distribuição \\(F\\) , chamados de estatísticas amostrais. Escrevamos a = 1 ∑ Xk, (2.15)\npara os momentos de ordem k ao redor do 0 (zero). Aqui ak, serão chamados de momentos amostrais de ordem k. Com esta notação\nO momento amostral central é definido por\nn a1 = Xi n i=1\n= X·\nb = 1 ∑(X − a )k = 1 ∑(X\n— X) · (2.16)\nLogicamente,\nk n i 1 i=1\nn i i=1\nb = 0 e b\n= (n − 1 ) S2·\nComo mencionado anteriormente, não chamamos b2 a variaˆncia amostral. S2\nserá chamada como a variaˆncia\namostral por razões que se tornarão claras posteriormente. Temos que b2 = a2 − a2· Para a função geradora de momentos de Fn podemos afirmar que n\nMFbn\n\n= 1 etXi · n\n\ni=1\nDefinições similares são realizadas para momentos amostrais de distribuições multivariadas. Por exemplo, se (X1, Y2), (X2, Y2), , (Xn, Yn) é uma amostra de uma distribuição bivariada, podemos escrever n n X = 1 ∑ X , Y = 1 ∑ Y\npara as duas médias amostrais e para os momentos de segunda ordem centrais escrevemos\nb20\nn = (Xi n i=1\n— X) , b02\nn = (Yi n i=1\n— Y ) ,\nMais uma vez, escrevemos\nb11\nn\nn = (Xi n i=1\n— X)(Yi\n— Y )·\nn\nS2 = 1 ∑(X\n— X)2, S2 = 1 ∑(Y\n— Y ) , (2.17)\npara as duas variaˆncias amostrais e para a covariância amostral utilizamos n\nS11\n= 1 (X n − 1 i=1\n— X)(Yi\n— Y )· (2.18)\nEm particular, o coeficiente de correlação amostral é definido por b11 S11\nR = 20\nb02\n= · S1S2\nPode ser demonstrado que |R| ≤ 1 e que os valores extremos ±1 ocorrem somente quando todos os pontos amostrais (X1, Y2), (X2, Y2), , (Xn, Yn) estão alinhados. Correspondendo a uma amostra \\(X_1, X_2, \\cdots , X_n\\) de observações em \\(F\\) , p-ésimo quantil amostral é definido como o p-ésimo quantil da função de distribuição amostral, ou seja, como \\(F\\) −1. Os quatis amostrais são definidos de maneira similar. Então, se 0 &lt; p &lt; 1, o quantil amostral de ordem p,\nr = [np] se n é um número par [np] + 1 se n é um número ímpar\n· (2.19)\nComo usual, [x] denota o maior inteiro x. Observe que, se [n] for par, podemos escolher qualquer valor entre X([np]) e X([np]+1) como o p-ésimo quantil amostral. Então, se p = 1 e n par podemos escolher qualquer valor entre X(n/2) e X(n/2+1), os dois valores do meio, como a mediana amostral. Habitualmente é escolhido o ponto médio. Assim, a mediana amostral é definida como\nξb1/2 = \nX((n+1)/2) se n é ímpar X(n/2) + X((n/2)+1) se n é par\n· (2.20)\nObserve que\n2 [n + 1] = (n + 1 )\n2 2 se n é ímpar. Consideraremos agora os momentos de características amostrais. Nos seguintes desenvolvimentos denotaremos E(Xk) = mk e E[(X µ)k] = µk como os momentos populacionais e os momentos populacionais centrais de k-ésima ordem, respectivamente. Nas situações onde utilizamos mk ou µk assumiremos que estes existem. Também, σ2 representará a variância populacional.\nDemonstração : Para provar (2.23) observemos que\n(∑n\nXi = ∑\nX3 + 3 ∑ ∑\nX2Xk + ∑ ∑ ∑ XiXjXk,\ni=1\ni=1\ni=1 j=1 j̸=k\ni=1 j=1 k=1 i̸=j, i̸=k j̸=k\ndesta expressão obtemos o resultado em (2.23). Similarmente\n(∑n )4\n( n )  n n n\n\n∑ ∑ ∑\nXi =\n∑ Xi ∑ X3 + 3 ∑ ∑ X2Xj +\ni j k\ni=1\ni=1\nn\n i=1\ni i=1 j=1 i̸=j n n\ni=1 j=1 k=1 i̸=j, i̸=k j̸=k\n= ∑ X4 + 4 ∑ ∑ XiX3 + 3 ∑ ∑ X2X2\ni i=1\ni=1 j=1 i̸=j\nj i j i=1 j=1 i̸=j\nn n n n n n n = +6 ∑ ∑ ∑ X2XjXk + ∑ ∑ ∑ ∑ XiXjXkXl·\ni=1 j=1 k=1 i̸=j, i̸=k j̸=k\ni=1 j=1 k=1 l=1 i̸=j, i̸=k, i̸=l j̸=k, j̸=l k̸=l\nUm detalhe importante é que os momentos centrais podem ser calculados a partir dos momentos, por exemplo, µ2 = E[(X − µ)2] = m2 − µ2, µ3 = E[(X − µ)3] = m3 − 3µm2 + 2µ3\ne assim por diante. Sabemos agora como calcular os momentos, até quarta ordem, de X. Vejamos a seguir como calcular os momentos centrais.\nDemonstração : Temos que µ (X) = E(X − µ)3 = E {∑n\n(X − µ)3} = ∑n\nE(X\n3 µ3 — µ) = ·\n3\nNo caso do quarto momento central\nn3 i=1 i\n1\nn3\n{∑n\ni=1 i n2\n}\nda qual obtemos que\nµ (X) = E(X µ)4 = E n4\ni=1\n(Xi − µ)4 ,\n1 µ4(X) =\nE(Xi − µ)4 +\n_{(4)} 1 + ∑ ∑\nE{(Xi − µ)2(Xj − µ)2}·\nn4 i=1\n2 n4\ni=1 j=1 i̸=j\nDesenvolvendo adequadamente chegamos ao resultado em (2.26).\nExemplo 2.16\n, Xn uma amostra aleatória da distribuição Gamma(α, β). Sabemos da Seção 1.2 que E(X) = αβ, Var(X) = αβ2\nmk = βk(α + k − 1)(α + k − 2) α, k ≥ 1· αβ2 E(X) = αβ, Var(X) = n 1 1 µ (X) = µ = (6α3β3 + 3α2β3 + 2αβ3)· 3 n2 3 n\nAté o momento estudamos como calcular os momentos da média amostral. Mais complexo é obter expressões para os momentos da variância amostral S2. O teorema a seguir dedica-se ao objetivo de encontrarmos expressões, até segunda ordem, dos momentos amostrais centrais. Como consequência deste resultado obtemos os momentos da variaˆncia amostral.\nDemonstração : Temos que\nn E(b2) = E n i=1\nX2 n2\nn 2 Xi i=1\n= m2 −\n1  n E \nX2 + ∑\n∑ X2Xj\nAgora\n= m2\n1 — n2 [nm2\n\nn(n − 1)µ2] = ( n − 1 ) (m\n\n— µ )·\nn2b2 =\nn\ni=1\n2\n(Xi − µ)2 − n(X − µ)2 ·\nEscrevendo Yi = Xi − µ, vemos que E(Yi) = 0, Var(Yi) = σ2 e E(Y 4) = µ4. Temos então que\nn2 E(b2) = E\nn i=1 n\n2\nY 2 − nY 2\nn n\n n n n \n= E ∑ Y 4 + ∑ ∑ Y 2Y 2 − 2 ∑ ∑ Y 2Y 2 + ∑ Y 4\n\n1 3 ∑ ∑\n\nY 2Y 2 + ∑\nY 4 ·\nSegue então que\nn i j i=1 j=1 i̸=j\ni=1\ni \n2 1 n2 E(b2) = nµ + n(n − 1)σ2 − [n(n − 1)σ4 + nµ ] + [3n(n − 1)σ4 + nµ ]\n= (n − 2 + 1 ) µ + (n − 2 + 3 ) (n − 1)µ2 · (µ\n= σ2)\nPortanto\nn 4 n 2 2\nVar(b2) = E(b2) − [ E(b2)]2\n= (n − 2 +\n1 ) µ4\n\n(n − 1) (n − 2 + 3 µ 2 —\n\n( n − 1 )2\n= (n − 2 +\n1 ) µ4\nµ2 + (n − 1)(3 − n) ,\ncomo afirmado. As relações (2.29) e (2.30) podem ser provadas de forma semelhante.\nEste é justamente o motivo pelo qual chamamos S2 e não b2 de variância amostral.\nExemplo 2.17 (Continuação do Exemplo 2.16)\ninteir Nesta situação, σ2 = αβ2, µ2 = σ2 e µ4 = m4 − 4m3µ + 6m2µ2 − 3µ4. Obtemos que E(S2) = αβ2 e Var)(S2) = µ4 + 3 − n α2β4· n n(n − 1)\nO seguinte resultado fornece uma justificativa para a nossa definição de covariaˆncia amostral.\nDemonstração : Do Corolário 2.17 sabemos que E(S2) = σ2 e E(S2) = σ2. Para provar que E(S11) = ρσ1σ2 1 1 2 2 observemos que Xi é independente de Xj, (i ̸= j) e de Yj, (i ̸= j). Temos que\nAgora\n(n − 1) E(S11) = E\nE{(Xi − X)(Yi − Y )} =\nn i=1\n(Xi − X)(Yi − Y )] ·\n( ∑n Yj\n∑n Yj\n∑n Xj ∑n\nYj )\ne segue que\n1 = E(XY ) − n [ E(XY ) + (n − 1) E(X) E(Y )] 1 − n [ E(XY ) + (n − 1) E(X) E(Y )] 1 − n2 [n E(XY ) + n(n − 1) E(X) E(Y )] = n − 1 [ E(XY ) E(X) E(Y )] n\n(n − 1) E(S11) = n ( ) [ E(XY ) − E(X) E(Y )], n − 1\nisto é\nE(S11) = E(XY ) − E(X) E(Y ) = Cov(X, Y ) = ρσ1σ2·\nA seguir, voltamos nossa atenção para as distribuições das características da amostra. Existem várias possi- bilidades. Se for necessária a distribuição exata o método de transformação de variáveis pode ser utilizado. As vezes, a técnica da função geradora de momentos pode ser aplicada. Assim, se \\(X_1, X_2, \\cdots , X_n\\) é uma amostra aleatória de uma população com distribuição para a qual existe a função geradora de momentos, a função geradora de momentos da média amostral X é dada por n M (t) = E(etXi/n) = [MX(t/n)]n , (2.32) i=1 onde MX é a função geradora de momentos da distribuição populacional. Se MX (t) tiver alguma forma conhecida seria possível escrever a função de probabilidade ou de densidade de X. Embora este método tem a desvantagem óbvia que se aplica apenas à distribuições para as quais existem todos os momentos, veremos sua efetividade na situação importante de amostras da distribuição normal.\nExemplo 2.18\nSeja \\(X_1, X_2, \\cdots , X_n\\) uma amostra aleatória de tamanho n da distribuição Gama(α, 1). Nesta situação podemos encontrar a função de densidade de X. Temos que\nMX (t) = [MX\n(t/n)]n = 1 , t (1 − t/n)αn n\n&lt; 1,\nda qual obtemos que X ∼ Gama(nα, 1/n).\nExemplo 2.19\nSeja \\(X_1, X_2, \\cdots , X_n\\) uma amostra aleatória da distribuição Uniforme no intervalo (0, 1). Considere a média geométrica\nYn =\nn\ni=1\n1/n Xi ·\nSabemos que log(Yn) = (1/n) ∑n log(Xi) e, desta forma, log(Yn) é a média amostral de log(X1), , log(Xn). A função de densidade comum de log(X1), , log(Xn) é\nex, se x &lt; 0 f (x) = , 0, caso contrário\nque é a distribuição exponencial negativa com parâmetro β = 1. Vemos que a função geradora de momentos de log(Yn) é dada por\nMlog(Yn)\nn (t) = E(et log(Xi)/n) = , (1 t/n)n i=1\ne a função de densidade de log(Yn) é dada por\nflog(Yn)\n\n= \n\nnn Γ_{(n)}[−y]\nn−1\neny\n, se − ∞ &lt; y &lt; 0 ·\n 0, caso contrário\nSegue então que Yn tem por função de densidade\nfYn\n\n= \n\nnn y Γ_{(n)}\nn−1\n[− log(y)]\nn−1\n, se 0 &lt; y &lt; 1 ·\n\nVoltemos ao quantil amostral de ordem p,\n0, caso contrário\nξbp, o qual sabemos é ou X([np]) ou X([np]+1) dependendo se [np] é\num número par ou ímpar, como definido em (2.19). Simplificando, vamos discutir as propriedades de X([np]), onde p ∈ (0, 1) e n é grande. Isso, por sua vez, nos informará sobre as propriedades de ξp. Primeiro observemos que, se U1, U2, , Un é uma amostra aleatória da distribuição U (0, 1) então, pelo Teorema 2.3, temos que\ndo qual obtemos que\nU([np]) ∼ Beta([np], n − [np] + 1),\n[np]\nE(U([np])) =\nn + 1\nn−→→∞ p,\nCov(U , U\n) = n np1\n−→ p (1 − p )·\nUtilizando este resultado e a desigualdade de Chebychev, demonstramos que U −P→ p· (2.33)\nIsso gera a questão\nξbp −→ ξp?\nqualquer seja a distribuição da amostra aleatória X1, , Xn. Para respondermos a pergunta acima vamos utilizar o Lema de Hoeffding, ou seja, para respondermos se o quantil amostral de ordem p converge em probabilidade para o quantil teórico correspondente, utilizaremos o seguinte resultado devido a Hoeffding (1963).\nDemonstração : Dado que as variáveis aleatórias são limitadas ao intervalo (0, 1), sabemos que ehX ≤ (1 − X) + Xeh, isto deve-se a que a função exponencial ehX é convexa e, portanto, seu gráfico é limitado por cima no intervalo 0 ≤ X ≤ 1 pela linha que conecta as ordenadas X = 0 e X = 1. Então E(ehX ) ≤ (1 − E(X)) + E(X)eh· (2.35)\nSeja Sn = ∑n\nXi. Sabemos que\nP (Sn − E(Sn) ≥ nt) = E(1[Sn− E(Sn)−nt≥0]),\ntambém sabemos que\n1[Sn− E(Sn)−nt≥0] ≤ exp (h(Sn − E(Sn) − nt)),\nqualquer seja h uma constante positiva arbitrária. Então P Sn − E(Sn) ≥ nt ≤ E eh(Sn− E(Sn)−nt) (2.36) e como estamos assumindo que as variáveis são independentes, podemos escrever\n( ( ))\n∏ ( ( ))\nEscrevendo µi = E(Xi) temos, pela expressão em (2.35) que E(eh(Xi−µi)) ≤ e−hµi ((1 − µi) + µieh) = ef(h), (2.38) onde \\(F\\) (h) = −hµi + ln(1 − µi + µieh). As primeiras duas derivadas são:\n′ µi\n′′ µie−h(1 − µi)\nf (h) = −µi + e−h(1 − µ ) + µ\ne f (h) = [µi\n\ne−h(1 − µ )]2 ·\nµi\nNa segunda derivada, escolhendo u = µ + e−h(1 − µ ) 0 &lt; u &lt; 1. Portanto, \\(F\\) ′′(h) ≤ 1 . Pela série de Taylor\n\nvemos que este quociente é da forma u(1 − u), sendo\nEntão, pela expressão em (2.38)\nf (h) ≤\nf (0) + \\(F\\) ′(0)h +\n1 h2 = 8\n1 h2· 8\nSubstituindo em (2.36) temos que\nE(eh(Xi−µi)) ≤ e 1 h2 ·\nP (Sn\n— E(Sn\n) ≥ nt) ≤ e−nht+ 1 nh2 ,\ne o mínimo no expoente é atingido quando h = 4t. Então, o mínimo do limite superior da probabilidade é exp(−2nt2).\nDevemos lembrar que esta não é a única maneira de termos uma taxa de convergência para Teorema do Limite Central. Por exemplo, se Y1, Y2, , Yn forem variáveis aleatórias independentes e identicamente distribuídas, utilizando o Teorema de Berry-Esseen2, temos que\n( ∑n ∑\n) ( √ Var(Y1))\nC E|Y1\n— E(Y1)|\nP i=1\nXi −\ni=1\nE(Xi) ≥ nt ≤ Φ t n\n\n√n\n\nVar3/2(Y ) ·\n2\nDemonstração : Berry (1941); Esseen (1942).\nPode-se consultar o livro de Feller (1971) para uma demonstração moderna.\nExemplo 2.20\nCaso a amostra aleatória seja Bernoulli(µ), temos que n Xk ∼ Binomial(n, µ)· i=1 Então, segundo a desigualdade de Hoeffding\nP (X − µ ≥ t) ≤ exp(−2nt2)· Uma vantagem da desigualdade no Lema de Hoeffding é que não assume-se conhecimento da variância e, em geral, o limite da probabilidade é mais acurado do que outras desigualdades. Caso as variáveis aleatórias sejam limitadas como a ≤ Xi ≤ b, com a &lt; b, o limite superior da desigualdade (2.34) seria exp − 2nt2/(b − a)2 .\nExemplo 2.21\nSejam X1, , Xn variáveis aleatórias com distribuição U ( 1, 1). Nesta situação E(X) = 0, a = 1 e b = 1. A desigualdade de Hoeffding assume a forma P (X ≥ t) ≤ exp ( − nt2/2)·\nDemonstração : Para ϵ &gt; 0 qualquer, podemos escrever P (|ξp − ξp| &gt; ϵ) = P (ξp &gt; ξp + ϵ) + P (ξp &lt; ξp − ϵ)· Pelo Teorema 2.9, podemos escrever P (ξbp &gt; ξp + ϵ) = P (p &gt; Fbn(ξp + ϵ))\nn = P i=1\n1[Xi&gt;ξp+ϵ] &gt; n(1 − p))\nn = P i=1\nVi −\n∑i=1\nE(Vi) &gt; nδ1),\nonde Vi = 1[Xi&gt;ξp+ϵ] e δ1 = \\(F\\) (ξp + ϵ) − p. Da mesma forma, P (ξbp &lt; ξp − ϵ) = P (p &gt; Fbn(ξp − ϵ))\nn = P i=1\nWi −\n∑i=1\nE(Wi) &gt; nδ2),\nonde Wi = 1[Xi&lt;ξp−ϵ] e δ2 = p − \\(F\\) (ξp − ϵ) − p. Portanto, utilizando o Lema de Hoeffding (Lema 2.20), temos P (ξbp &gt; ξp + ϵ) ≤ exp(−2nδ2) P (ξbp &lt; ξp − ϵ) ≤ exp(−2nδ2)· Colocando δϵ = min{δ1, δ2}, a prova está completa.\nDemonstramos que\nlim P (|ξbp − ξp| &gt; ϵ) ≤ lim 2 exp(−2nδ2) = 0,\no qual significa que ξp −→ ξp. Em outras palavras, sempre que ξp seja solução única da desigualdade \\(F\\) (ξp ) ≤ p ≤ \\(F\\) (ξp), 0 &lt; p &lt; 1, o quantil amostral converge em probabilidade para o quantil populacional e isto sempre acontece nas distribuições contínuas. Um detalhe importante é que para demonstrarmos a convergência em probabilidade de ξp utilizamos o Lema de Hoeffding e ele depende da existência da esperança. O seguinte resultado fornece a distribuição assintótica da r-ésima estatística de ordem amostral de uma po- pulação com uma função de distribuição \\(F\\) , absolutamente contínua, e função de densidade \\(F\\) .\nDemonstração : Vamos demonstrar somente para o caso p = 1/2. Observemos que ξ1/2 é mediana única dado que f (ξ1/2) &gt; 0. Primeiro, consideremos que n seja ímpar, por exemplo, n = 2m − 1, logo P [√n(X(m) − \\(F\\) −1(1/2)) ≤ t] = P (X(m) ≤ t/√n + \\(F\\) −1(1/2))·\nSeja Sn o número de X que excedem t/ n + F (1/2). Então\nPercebemos que\nt X(m) ≤ √n + F\n(1/2) se, e somente se, Sn ≤ m − 1 =\nn − 1 · 2\nSn ∼ Binomial(n, 1 − \\(F\\) (F −1(1/2) + t/√n))· Fazendo pn = 1 − \\(F\\) (F −1(1/2) + t/√n), temos que\nP [√n(X\n\n\n\n— F −1(1/2)) ≤ t] = P (Sn\n≤ n − 1 )\n( Sn − npn 1 (n − 1) − npn )\n= P\nUtilizando o Teorema de Berry-Esseen, temos que\n√npn(1 − pn) ≤ √npn(1 − p ) · n\n{ ( n − 1 ) ( 1 (n − 1) − npn )}\nlim P n→∞\nSn ≤ 2\n— Φ √np\n(1 − pn)\n= 0·\nEscrevendo\n1 (n − 1) − npn npn(1 − pn)\n=\n√n( 1 − pn) 1/2 √n( − 1 + \\(F\\) (t/√n + \\(F\\) −1(1/2)))\n= 2t\n1/2 F (t/√n + \\(F\\) −1(1/2)) − \\(F\\) (F −1(1/2))\n−→ 2tf\n(F −1(1/2))·\nEntão\n( 1 (n − 1) − npn )\n( ( −1 ))\nΦ npn ou\n(1 − pn)\n≈ Φ 2tf F\n(1/2)\n√n(X\n\n− F\n\n( 1 )) −D→ N (0,\n4f 2\n1 (F −1(1/2)\n)) ·\nQuando n é par, digamos n = 2m, ambos P (√n X(m) F −1(1/2) t) quanto P (√n X(m+1) F −1(1/2) t) convergem a Φ(2tf (F −1(1/2))).\nObserve que o quantil amostral de ordem p, assintótica\nξbp, como consequência do Teorema 2.23, tem por distribuição\nN (ξ , 1 p(1 − p)) , onde ξp é o correspondente quantil populacional e \\(F\\) é a função de densidade populacional. Por exemplo, suponha temos uma amostra aleatória da di√stribuição N (µ, σ2) de tamanho n. Seja ξb1/2 a mediana amostral obtida dessa b ( πσ2 )\nTambém devemos ter em consideração que para demonstrarmos o Teorema 2.23 utilizamos a Teorema de Berry- Esseen, o qual depende da existência dos primeiros dois momentos da variável aleatória. Com isso, caso X Cauchy(µ, σ), o Teorema 2.23 não se aplica.",
    "crumbs": [
      "Prefácio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#gráficos-descritivos",
    "href": "content/Modulo02/index.html#gráficos-descritivos",
    "title": "2  Estatísticas de Ordem",
    "section": "2.5 Gráficos descritivos",
    "text": "2.5 Gráficos descritivos\nVejamos alguns conjuntos de dados disponíveis na linguagem de programação R (R Core Team, 2014), especifi- camente na libraria datasets, que nos permitiram mostrar a utilidade dos momentos amostrais para resumir as informações contidas nos dados. Para consultar estes conjuntos de dados basta digitar library(help = “datasets”) Alguns dos diversos exemplos disponíveis serão apresentados aqui.\nExemplo 2.22 (Puromicina)\nOs dados sobre a velocidade de uma reação enzimática são obtidos por Treloar (1974) e disponíveis no arquivo de dados Puromycin. O número de contagens por minuto de produto radioativo a partir da reação foi medida como uma função da concentração do substrato em partes por milhão (ppm) e a partir destas contagens a taxa\ninicial (ou velocidade) da reação foi calculada (contagens/min/min). O experimento foi realizado uma vez com a enzima tratada com puromicina e depois com a enzima não tratada. A estrutura destes dados tem 23 linhas e 3 colunas, cada coluna contendo as informações das variáveis: conc: um vector numérico de concentrações de substrato (ppm); rate: um vector numérico de taxas de reação instantânea (contagens/min/min); state: um fator com níveis treated (tratada) ou untreated (não tratada). Para a leitura e observação dos nomes das variáveis utilizamos os comandos a seguir: data(Puromycin) names(Puromycin) Uma maneira de obtermos estatísticas descritivas é utilizando as linhas de comando a seguir: summary(rate[state==’treated’]) Min. 1st Qu. Median Mean 3rd Qu. Max. 47.0 104.5 145.5 141.6 193.2 207.0 e summary(rate[state==’untreated’]) Min. 1st Qu. Median Mean 3rd Qu. Max. 51.0 85.0 115.0 110.7 137.5 160.0 para o caso da variável rate, as concentrações, obtidas as estatísticas descritivas segundo os níveis do fator state, se as concentrações foram ou não tratadas com puromicina. No caso das estatísticas descritivas acerca das concentrações de substrato, variável conc, temos: summary(conc[state==’treated’]) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.020 0.060 0.165 0.345 0.560 1.100 e summary(conc[state==’untreated’]) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.0200 0.0600 0.1100 0.2764 0.3900 1.1000 Os valores mínimos é máximos foram registrados sempre com os nomes de Min. e Max., respectivamente. O primeiro e terceiro quantis ou quantis de 25% e 75% respectivos são registrados com os nomes 1st Qu. e 3rd Qu. e, finalizando, o resumo de informações de estatísticas de posição temos os valores de medianas (Median) e médios (Mean).\nExemplo 2.23 (Rock )\nMedições em 48 amostras de rochas de um reservatório de petróleo estão disponíveis no arquivo de dados rock. Este conjunto de dados contem 48 linhas e 4 colunas numéricas, descritas a seguir: area área do espaço de poros, em pixels de 256 por 256; peri perímetro em pixels; shape perímetro/sqrt(area) perm permeabilidade em mili-Darcies. Doze amostras do núcleo de reservatórios de petróleo foram amostrados por 4 seções transversais. Cada amostra foi medida no núcleo para a permeabilidade e cada seção transversal tem uma área total de poros, perímetro total de poros e forma. A fonte destes dados é a BP Research e a análise das imagens foi de Ronit Katz, Oxford University. Na geologia, a permeabilidade é a medida da capacidade de um material (tipicamente uma rocha) para transmitir fluídos. E´ de grande importância na determinação das características de fluxo dos hidrocarbonetos em reservatórios de petróleo e gás e da água nos aquíferos. A unidade de permeabilidade é o Darcy ou, mais habitualmente, o mili- Darcy ou mD.\n\n2.5.1 2.4.1 Gráfico de Boxplot\nEm 1977, John Tukey (Tukey, 1977) publicou uma proposta que posteriormente foi reconhecida como sendo um eficiente método para mostrar cinco número que sumarizam qualquer conjunto de dados. O gráfico proposto é chamado de boxplot (também conhecido como box and whisker plot) e resume as seguintes medidas de posição estatísticas: mediana, quantis inferior e superior e os valores mínimos e máximos. Os quantis inferior e superior entendem-se serem os quantis de 25% e 75%, respectivamente. No caso do exemplo 2.22, deixamos a disposição os dados digitando attach(Puromycin) e com isso podemos mudar o nome dos níveis do fator da forma state=factor(state,labels=c(’Tratada’,’N~ao tratada’)) Então, com os comandos a seguir geramos o gráfico de boxplot, tanto para a variável rate quanto para a variável conc, estas segundo os níveis do fator state. par(mar=c(5,4,3,1)) boxplot(rate ~ state, col = grey(c(0.4,1)), main=’Taxas de reaç~ao instant^anea’)\npara o caso do rate. Observemos que a primeira linha par(mar=c(5,4,3,1)) serve somente para dimensionar a janela gráfica. Para o caso da variável conc utilizamos comandos semelhantes. par(mar=c(5,4,3,1)) boxplot(conc ~ state, col = grey(c(0.4,1)), main=’Concentraç~oes de substrato’) O resultado deste trabalho pode ser observado na Figura 2.3. Interpretemos o gráfico de boxplot. A caixa (box) propriamente contém a metade 50% dos data. O limite superior da caixa indica o percentil 75% dos dados e o limite inferior da caixa indica o percentil 25%. A distancia entre esses dois quantis é conhecida como inter-quantil. A linha na caixa indica o valor de mediana dos dados. Se a linha mediana dentro da caixa não é equidistante dos extremos, diz-se então que os dados são assimétricos. O boxplot da variável rate (esquerda na Figura 2.3) é um exemplo de dados simétricos já a situação da variável conc (direita na Figura 2.3) é um caso clássico de assimetria dos dados. Os extremos do gráfico indicam os valores mínimo e máximo, a menos que valores outliers3 estejam presentes, nesse caso o gráfico de estende ao máximo de 1.5 vezes da distância inter-quantil. Os pontos fora do gráfico são então outliers ou suspeitos de serem outliers. Mais elegante seria utilizar a biblioteca de funções ggplot2, para isso, digitamos: library(ggplot2) Para gerar os gráficos de boxplot respectivos, fazemos: par(mar=c(5,4,3,1)) qplot(state, rate, geom=c(“boxplot”, “jitter”), main=“Taxas de reaç~ao instant^anea”, xlab=““, ylab=” “) e par(mar=c(5,4,3,1)) qplot(state, conc, geom=c(”boxplot”, “jitter”), main=“Concentraç~oes de substrato”, xlab=““, ylab=” “)\n3Em estatística, outlier, valor aberrante ou valor atípico, é uma observação que apresenta um grande afastamento das demais observações em uma amostra. A existência de outliers implica, tipicamente, em prejuízos a interpretação dos resultados dos testes estatísticos aplicados as amostras.\nTaxas de reação instantânea Concentrações de substrato\nTratada Não tratada Tratada Não tratada\nFigura 2.3: Gráfico de boxplot da variável rate à esquerda e da variável conc à direita, segundo os níveis do fator state, se a enzima foi tratada ou não com puromicida. Gráfico gerado utilizando a função R boxplot,\nTaxas de reação instantânea Concentrações de substrato\n200\n0.9\n150\n0.6\n100 0.3\n50\nTratada Não tratada\n0.0\nTratada Não tratada\nFigura 2.4: Gráfico de boxplot da variável rate à esquerda e da variável conc à direita, segundo os níveis do fator state, se a enzima foi tratada ou não com puromicida. Gráfico gerado utilizando a função R qplot, opção geom=c(”boxplot”, ”jitter”).\nobtendo-se assim os gráficos na Figuras 2.4. Além de melhor qualidade gráfica acrescentamos os pontos observados no boxplot, isso permite termos uma ideia também da dispersão dos dados. Vejamos as vantagens do boxplots. Mostra graficamente a posição central dos dados (mediana) e a tendência. Fornece algum indicativo de simetria ou assimetria dos dados. Ao contrário de muitas outras formas de mostrar os dados, o boxplots mostra os outliers. Utilizando o boxplot para cada variável categórica no mesmo gráfico, pode-se facilmente comparar os dados. Esta é a situação no exemplo na Figura 2.3, podemos observar o comportamento das variáveis rate e conc segundo os níveis do fator state. Um detalhe do boxplot é que ele tende a enfatizar as caudas da distribuição, que são os pontos ao extremo nos dados. Também fornece detalhes da distribuição dos dados. Mostrar o histograma (Seção 2.4.2) em conjunto com o boxplot ajuda a entender a distribuição dos dados, constituindo estes dos gráficos ferramentas importantes na análise exploratória. Logicamente, o comportamento dos dados dentro da caixa (box), como podemos perceber nas figuras 2.3 e 2.4, permanece um mistério. Isso porque caso estejam os dados bem espalhados ou não, o gráfico boxplot continua mostrando uma caixa. Somente perceberemos algum comportamento diferente se o valor da mediana estiver mais próximo de um dos extremos desta caixa. Para tentar diminuir essa limitação foi sugerido uma melhoria, obtendo-se o chamada boxplot entalhado (notched boxplot). Com as linhas de comando a seguir se obtém os gráficos na Figura 2.5.\npar(mar=c(5,4,3,1)) boxplot(rate ~ state, col = grey(c(0.4,1)), notch=TRUE, main=’Taxas de reaç~ao instant^anea’)\ne par(mar=c(5,4,3,1)) boxplot(conc ~ state, col = grey(c(0.4,1)), notch=TRUE, main=’Concentraç~oes de substrato’)\nObserva-se que a única diferença é a inclusão da opção notch=TRUE, permanecendo todas as outras instruções iguais. Mais elaborado é o chamado violin plot, mistura de boxplot com estimação de densidade, tema este tratado na Seção 4.3. Este gráfico, introduzido no artigo Hintze & Nelson (1998), sinergicamente combina o gráfico de boxplot e a estimação da densidade, também chamado de histograma suavizado, em uma única tela que revela a estrutura encontrada nos dados. Com as linhas de comando a seguir se obtém os gráficos na Figura 2.6.\npar(mar=c(5,4,3,1)) qplot(state, rate, geom = c(“violin”, “jitter”), notch=TRUE, main=“Taxas de reaç~ao instant^anea”, xlab=““, ylab=” “)\ne par(mar=c(5,4,3,1)) qplot(state, conc, geom=c(“violin”, “jitter”), notch=TRUE, main=“Concentraç~oes de substrato”, xlab=““, ylab=” “)\nEste gráfico é similar ao boxplot excepto que mostra também a densidade de probabilidade dos dados. Pode incluir também um marcador para a média dos dados e uma caixa que indica a distância interquartil, como nos gráficos boxplot. O objetivo do gráfico violin plot é o mesmo do que o boxplot original porém, considera de alguma maneira o comportamento dos dados dentro da caixa (box). Assim, percebemos melhor a distribuição dos dados dentro do intervalo interquartil.\nTaxas de reação instantânea Concentrações de substrato\nTratada Não tratada Tratada Não tratada\nFigura 2.5: Gráfico de boxplot entalhado da variável rate à esquerda e da variável conc à direita, segundo os níveis do fator state, se a enzima foi tratada ou não com puromicida. Gráfico gerado utilizando a função R qplot, opção geom=c(”boxplot”, ”jitter”), notch=TRUE.\nTaxas de reação instantânea Concentrações de substrato\n200\n0.9\n150\n0.6\n100 0.3\n50\nTratada Não tratada\n0.0\nTratada Não tratada\nFigura 2.6: Gráfico de violin plot da variável rate à esquerda e da variável conc à direita, segundo os níveis do fator state, se a enzima foi tratada ou não com puromicida. Gráfico gerado utilizando a função R qplot, opção geom=c(”vioplot”, ”jitter”), notch=TRUE.\n\n\n2.5.2 2.4.2 Histograma\nUm histograma é uma representação gráfica da função de probabilidades ou da função de densidade de um conjunto de dados independentes e foi introduzido pela primeira vez por Karl Pearson4. A representação mais comum do histograma é um gráfico de barras verticais. A palavra histograma é de origem grega, derivada de duas: histos que pode significar testemunha no sentido de aquilo que se vê, como as barras verticais do histograma, e da também palavra grega gramma que significa desenhar, registrar ou escrever. Histograma Histograma com a curva norma\n−2 −1 0 1 2 Dados simulados\n−2 −1 0 1 2 Dados simulados\nFigura 2.7: Gráfico de histograma para dados simulados.\nPara construir um exemplo controlado do gráfico de histograma, simulamos uma amostra de tamanho 150 da distribuição normal padrão, com o comando x=rnorm(150) e, depois, construímos um gráfico colorido com as linhas de comando par(mar=c(5,4,2,1)) hist(x, breaks=12, col=“red”, xlab=“Dados simulados”, ylab=’Frequ^encia’, main=“Histograma”) box() Posteriormente, acrescentamos a este gráfico uma linha com a densidade normal par(mar=c(5,4,2,1)) h=hist(x, breaks=10, col=“red”, xlab=“Dados simulados”, ylab=’Frequ^encia’, main=“Histograma com a curva normal”) xfit=seq(min(x),max(x),length=40) yfit=dnorm(xfit,mean=mean(x),sd=sd(x)) yfit=yfitdiff(h$mids[1:2])length(x) lines(xfit, yfit, col=“blue”, lwd=2) box()\n4Pearson, K. (1895). Contributions to the Mathematical Theory of Evolution. II. Skew Variation in Homogeneous Material. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 186: 343-414.\nDesta forma geramos os gráficos na Figura 2.7. A ideia é mostrar que o histograma assemelha-se ao gráfico da densidade normal, a densidade dos dados.\nHistograma c2(6) Histograma c2(6)\n2 4 6 8 10 12 14 14 intervalos\n2 4 6 8 10 12 14 26 intervalos\nFigura 2.8: Histogramas da distribuição χ2 com 6 graus de liberdade. Número de intervalos 14 e 26, respectivamente.\nO histograma é um gráfico composto por retângulos justapostos em que a base de cada um deles corresponde ao intervalo de classe e a sua altura à respectiva frequência. A construção de histogramas tem caráter preliminar em qualquer estudo e é um importante indicador da distribuição de dados. Pode indicar se uma distribuição aproxima-se de uma densidade normal como pode indicar mistura de densidades, quando os dados apresentam várias modas. Os histogramas podem ser um mau método para determinar a forma de uma distribuição porque são fortemente influenciados pelo número de intervalos utilizados. Por exemplo, decidimos gerar 50 amostras da densidade χ2(6), da forma set.seed(5678) z=rchisq(50, df=6) Os gráficos de histogramas correspondentes com 14 e 26 intervalos são apresentados na Figura 2.8 e foram gerados com as linhas de comando\npar(mar=c(5,4,2,1)) hist(z, breaks=14, col=“blue”, main=expression(paste(’Histograma ’, chi^2,’(6)’)), ylab=’Frequ^encia’, xlab=’14 intervalos’) box()\ne\npar(mar=c(5,4,2,1)) hist(z, breaks=26, col=“blue”, main=expression(paste(’Histograma ’, chi^2,’(6)’)), ylab=’Frequ^encia’, xlab=’26 intervalos’) box()\nNa Figura 2.9 podemos observar os gráficos de histograma obtidos das variáveis descritas no Exemplo 2.23. A situação em (a) representa o caso em a distribuição dos dados de assemelha à distribuição normal, já a situação descrita no gráfico em (b) mostra-se uma mistura de densidades, percebemos a existência de duas modas. (a) Área do espaço de poros (b) Perímetro em pixels\n0 4000 8000 12000 pixels de 256 x 256\n0 1000 3000 5000\nFigura 2.9: Histogramas das variáveis no Exemplo 2.23.\nOutras situações no mesmo exemplo, mas diferentes variáveis, são descritas nos gráficos na Figura 2.10. Nessa figura apresentamos dois gráficos, chamados de (c) e (d), nesta figura. Correspondem, como podemos observar, à distribuições assimétricas e descrevem os dados coletados nas variáveis shape e perm do arquivo de dados Rock, Exemplo 2.23. Os histogramas foram pensados somente para o caso de variáveis contínuas, porém é uma descrição discreta delas. Logicamente, também podemos utiliza-los em situações de variáveis aleatórias discretas, nada impede isso. Estas figuras foram geradas utilizando a configuração padrão do comando hist, isto é, utilizamos uma maneira automática de determinar o número de intervalos, mais adiante dedicamos maior atenção a diferentes formas de calcular este número. Como pode ter sido observado, além de não ficar claro como determinar o número de intervalos nem como delimitar os intervalos, também não ficou claro o que queremos realmente observar com o gráfico desta função. Vejamos agora uma definição mais clara do histograma, esta definição nos permitirá obter propriedades impor- tantes.\n\nPerímetro/sqrt(Área) (d) Permeabilidade\n\n0.1 0.2 0.3 0.4 0.5\n0 200 600 1000 1400 mili−Darcies\nFigura 2.10: Histogramas das variáveis no Exemplo 2.23.\nFoi provado por Robertson (1967) que, dados os intervalos I1, I2, , Ik, o histograma \\(F\\) é um estimador de máxima verossimilhança5 dentre os estimadores expressados como funções simples e semicontínuas superiormente, isto se o fecho de cada intervalos contiver duas ou mais observac¸ões. Os gráficos apresentados nas figuras 2.7, 2.9 e 2.10 são histogramas também segundo a proposta de Robertson (1967). Pode-se observar que este estimador tem duas limitações importantes: a dependência do comprimento do intervalo e o fato de o histograma não constituir uma função contínua. A primeira destas limitações foi amplamente estudada por Wegman (1975). Ele provou que os pontos extremos de cada intervalo Ik devem ser coincidentes com observações e que, se o número mínimo de observações em cada intervalo aumente, conforme aumenta o tamanho da amostra, o estimador \\(F\\) é consistente6. A segunda limitação importante do histograma, isto é, o fato de ele não constituir uma função contínua, incentivou diversos estudos na procura de estimadores contínuos da função de densidade. No Capítulo 3, a Seção 4.3 dedica-se a mostrar estimadores contínuos da função de densidade.\n5Os estimadores de máxima verossimilhanc¸a serão estudados na Seção 4.2 6Estimadores consistentes serão estudados na Seção 3.1.1\nCálculo automático do número de intervalos num histograma Uma questão importante é determinar de maneira automatizada o número de intervalos disjuntos que serão utili- zados para a construção do gráfico. Uma primeira forma de escolher o número de intervalos foi dada por Sturges (1926) e que constitui a forma padrão no R. Conhecida como fórmula de Sturges é dada por k = [log2_{(n)} + 1], (2.41) isto significa que o número de intervalos é a parte inteira do logaritmo base 2 do número de observações mais 1. Outras expressões comumente utilizadas são a fórmula de Scott (Scott, 1979) h = 3.5s/√3 n, onde s é o desvio padrão e a fórmula de Freedman Diacconi (Freedman & Diaconis, 1981) h = 2IQR(x)/√3 n, onde IRQ é a diferença entre o terceiro e o primeiro quantil.\nExemplo 2.24\nNa libraria de funções R robustbase temos disponíveis dados do teor de cálcio e do pH em amostras de colo coletadas em diferentes comunidades da região de Condroz, na Bélgica. Podemos ler estes dados digitando as linhas de comando abaixo, primeiro para escolher a libraria de funções e depois para selecionar os dados. library(robustbase) data(condroz) Temos registadas duas variáveis: Ca que registra o tero de cálcio na amostra de solo e o pH, o pH corres- pondente. Construímos histogramas da variável Ca segundo a três formas de escolha do número de intervalos e os apresentamos na Figura 2.11. Os dados deste exemplo foram publicados em: Hubert, M. and Vandervieren, E. (2006). An Adjusted Boxplot for Skewed Distributions, Technical Report TR-06-11, KULeuven, Section of Statistics, Leuven.\nSturges\nScott\nFreedman−Diaconis\n0 1000 2000 3000 4000 Ca\n0 1000 2000 3000 4000 Ca\n0 1000 2000 3000 4000 Ca\nFigura 2.11: Diferentes histogramas da variável Ca no Exemplo 2.24.\n\n\n2.5.3 2.4.3 Gráficos para verificar normalidade\nUm primeiro gráfico chamado de qq-norm permite a comparação de duas distribuições de probabilidades traçando seus quantis uns contra os outros. Depois exploramos um gráfico mais recente, conhecido como worm plot (gráfico de minhoca), consistindo numa determinada coleção de de qq-norm.\nQQ-norm O gráfico quantil-quantil ou qq-plot, proposto por Wilk & Gnanadesikan (1968), é um dispositivo gráfico explo- ratório utilizado para verificar a validade de um pressuposto de distribuição para um conjunto de dados. Em geral, a ideia básica é a de calcular o valor teoricamente esperado para cada ponto de dados com base na distribuição em questão. Se os dados de fato seguirem a distribuição assumida os pontos deste gráfico formarão aproximadamente uma linha reta. Percebemos que podemos verificar com este gráfico qualquer densidade contínua, eventualmente pode ser uti- lizado também para funções de probabilidade. O qq-plot vai apresentar-se como uma linha reta se a densidade assumida estiver correta. Vejamos o caso particular de verificarmos se a densidade é normal, nesta situação o gráfico qq-plot será chamado de qq-norm. Primeiro consideraremos a situação da densidade normal padrão. Seja z1, z2, , zn uma amostra aleatória de uma distribuição normal com média µ = 0 e desvio padrão σ = 1. As estatísticas de ordem amostrais são z_{(1)} ≤ z_{(2)} ≤ ≤ z_{(n)}· Estes valores desempenharão o papel dos quantis da amostra. Agora, quais devemos tomar como os quantis teóricas correspondentes? Se a função de distribuição cumulada da densidade normal padrão fosse denotada por Φ, usando a notação quantil, se ξq é o q-ésimo quantil de uma distribuição normal, então Φ(ξq) = q, ou seja, a probabilidade de uma amostra normal ser inferior a ξq é, de fato, apenas q. Considere o primeiro valor ordenado z_{(1)}. O que podemos esperar que o valor Φ(z_{(1)}) seja? Intuitivamente, esperamos que essa seja a probabilidade de assumir um valor no intervalo (0, 1/n). Do mesmo modo, espera-se que Φ(z_{(2)}) seja a probabilidade de assumir um valor no intervalo (1/n, 2/n). Continuando, esperamos que Φ(z_{(n)}) seja a probabilidade de assumir um valor no intervalo (n 1)/n, 1). Assim, o quantil teórico desejamos seja definido pelo inverso da função de distribuição acumulada normal padrão. Em particular, o quantil teórico correspondente ao quantil empírico z_{(i)} deve ser\npara i = 1, 2, , n.\nξ = q i − 0, 5 , q n\nQQ−plot nomal\nQQ−plot nomal\nQQ−plot nomal\n−3 −2 −1 0 1 2 3 Quantis teóricos\n−3 −2 −1 0 1 2 3 Quantis teóricos\n−3 −2 −1 0 1 2 3 Quantis teóricos\nFigura 2.12: Diferentes qqplot para dados normais.\nNa Figura 2.12, a esquerda acima exibimos o qq-norm de uma pequena amostra normal de tamanho 5. Os restantes quadros na Figura 2.12 exibem as plotagens de qq-norm para amostras normais de tamanhos n = 100 e\nn = 1000, respectivamente. Como o tamanho da amostra aumenta, os pontos encontram-se mais perto da linha y = x. Estes gráficos (Figura 2.12) foram gerados utilizando as linhas de comando: set.seed(1278) x=rnorm(5) qqnorm(x, xlim=c(-3,3), ylim=c(-3,3), cex=0.6, pch=19, ylab=’Quantis amostrais’, xlab=’Quantis teóricos’, main=’QQ-plot nomal’) qqline(x,col=“red”) text(-1,2,’n=5’) para a situação de amostra de tamanho 5. A primeira linha de comando serve para fixar o gerador de números laetórios e, dessa forma, podermos simular sempre a mesma amostra e reproduzir o gráfico idêntico. Nas outras situações somente muda-se o tamanho da amostra que se quer gerar.\nQQ−plot nomal QQ−plot nomal\n−3 −2 −1 0 1 2 3 Quantis teóricos\n−3 −2 −1 0 1 2 3 Quantis teóricos\nFigura 2.13: Diferentes qqplot para dados não normais. Assim, os comandos para gerar o segundo e terceiro gráficos são: x=rnorm(100) qqnorm(x, xlim=c(-3,3), ylim=c(-3,3), cex=0.6, pch=19, ylab=’Quantis amostrais’, xlab=’Quantis teóricos’, main=’QQ-plot nomal’) qqline(x,col=“red”) text(-1,2,’n=100’)\nx=rnorm(1000) qqnorm(x, xlim=c(-3,3), ylim=c(-3,3), cex=0.6, pch=19, ylab=’Quantis amostrais’, xlab=’Quantis teóricos’, main=’QQ-plot nomal’) qqline(x,col=“red”) text(-1,2,’n=1000’) Caso os dados não forem padronizados bastar aplicar a transformação (X − µ)/σ, onde X representa os dados originais e µb e σb representam os estimadores dos parâmetros µ e σ, respectivamente.\nEstes gráficos podem indicar afastamentos da normalidade por isso apresentamos duas situações de dados não simétricos e com cuadas pesadas. Na Figura 2.13, mostramos o que acontece se os dados forem da distribuição t-Student(8) e da distribuição χ2(5), sempre de tamanho n = 1000. Observe, em particular, que os dados a partir da distribuição t-Student seguem a curva normal bem de perto até os últimos pontos em cada extremo. Na outra situação o afastamento da distribuição normal é evidente. Foi mencionado que o qq-norm é uma situação particular do qq-plot devido a este último permitir comparar os quantis amostrais com os quantis distribucionais. Com isto queremos dizer que o qq-plot serve para verificar se os dados forem t-Student ou χ2(5), por exemplo. Na Figura 2.14 apresentamos a aparência dos gráficos qq-plot caso queira-se verificar se as amostras seguem distribuição t-Student(8) ou χ2(5), respectivamente.\nQQ plot para t−Student(8)\n−4 −2 0 2 4 t−Student(8)\nQQ plot para c2(5)\n0 5 10 15 20 c2(5)\nFigura 2.14: Diferentes qqplot para dados não normais. Os gráficos na Figura 2.14 foram gerados pelas linhas de comandos qqplot(qt(ppoints(1000), df = 8), x, cex=0.6, pch=19, main = “QQ plot para t-Student(8)”, xlab=“t-Student(8)”) qqline(x, distribution = function(p) qt(p, df = 8), prob = c(0.1, 0.6), col = 2) no caso t-Student(8) e qqplot(qchisq(ppoints(1000), df = 5), x, cex=0.6, pch=19, main = expression(“QQ plot para” ~~ {chi^2}(5)), xlab=expression({chi^2}(5))) qqline(x, distribution = function(p) qchisq(p, df = 5), prob = c(0.1, 0.6), col = 2) para o caso χ2(5).\nWorn plot O worm-plot é uma série de parcelas de gráficos qq-plot retificados. Constitui uma ferramenta de diagnóstico para visualização de quão bem um modelo estatístico se ajusta aos dados, para encontrar locais em que o ajuste pode ser melhorado e para comparar o ajuste de diferentes modelos. Na Figura 2.15 mostramos este gráfico para duas situações: a esquerda os dados são normais e a direita os dados são t-Student com 8 graus de liberdade. Nesta situação aparece bem a qualidade da observação com esta\n−4 −2 0 2 4 Unit normal quantile\n−4 −2 0 2 4 Unit normal quantile\nFigura 2.15: Diferentes worm-plot para dados normais.\nfigura. Se os dados forem normais o curva worm-plot ou gráfico de minhoca deve aparentar um verme achatado, os pontos próximos a curva vermelha e com poucas oscilações. Quando aplicamos este gráfico ao caso t-Student percebemos uma oscilação grande no verme e com pontos fugindo da banda de confiança. Isso comprova que os dados não seguem como referência a distribuição normal.\n−4 −2 0 2 4 Unit normal quantile\n−4 −2 0 2 4 Unit normal quantile\nFigura 2.16: Diferentes worm-plot para dados não normais. As linhas a seguir mostram os comandos necessários para gerar os gráficos na Figura 2.15. Utilizamos a libraria de comandos R gamlss (Rigby & Stasinopoulos, 2005).\nlibrary(gamlss) x=rnorm(1000) wp(gamlss(x~1), cex=0.6) x=rt(1000, df=8) wp(gamlss(x~1), cex=0.6)\nNa Figura 2.16, a esquerda temos o caso de dados com distribuição χ2(5) e a direita dados com distribuição Cauchy padrão. Nestas situações fica claro que os dados não são normais. Oa gráficos na figura foram gerados pelas linhas de comando a seguir. x=rchisq(1000, df=5) wp(gamlss(x~1), cex=0.6) x=rcauchy(1000) wp(gamlss(x~1), cex=0.6)",
    "crumbs": [
      "Prefácio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#exercícios",
    "href": "content/Modulo02/index.html#exercícios",
    "title": "2  Estatísticas de Ordem",
    "section": "2.6 Exercícios",
    "text": "2.6 Exercícios\nExercícios da Seção 2.1 1. Seja X ∼ Bernoulli( 1 ) e considere todas as possíveis amostras aleatórias de tamanho n = 3. Calcule Xn e S2 cada uma das\n2 n oito amostras. Encontre a função de probabilidade de Xn e S2. 2. Um dado é lançado. Seja X o valor da face superior que aparece e X1, X2 duas observações independentes de X. Encontre a função de probabilidade de Xn. 3. Seja X1, , Xn uma amostra aleatória de alguma população. Mostre que (n − 1)Sn\nmax |Xi Xn| &lt; 1≤i≤n\nonde Sn é a raiz quadrada positiva da variância amostral S2.\n√n ,\nExercícios da Seção 2.2 1. Seja (X_{(1)}, X_{(2)}, , X_{(n)}) o conjunto das estatísticas de ordem de n variáveis aleatórias independentes \\(X_1, X_2, \\cdots , X_n\\) com função de densidade comum\nf (x) =\nβe−xβ, se x 0 · 0, caso contrário\n\nMostre que X(s) e X(r) − X(s) são independentes para quaisquer r &gt; s.\nEncontre a função de densidade de X(r+1) − X(r).\nSeja Z1 = nX_{(1)}, Z2 = (n − 1)(X_{(2)} − X_{(1)}), Z3 = (n − 2)(X_{(3)} − X_{(2)}), …, Zn = ((X_{(n)} − X(n−1))). Prove que (Z1, Z2, , Zn) e \\((X_1, X_2, \\cdots , X_n)\\) são identicamente distribuídas.\n\n\nProvar o Teorema 2.1\nSejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias com distribuição geométrica de parâmetros p1, p2, , pn, respectivamente. Prove que Nn = min\\((X_1, X_2, \\cdots , X_n)\\) têm também distribuição geométrica de parâmetro n p = 1 − (1 − pi)· i=1\nAs X1, , Xn variáveis aleatórias independentes e identicamente distribuídas tem por função de probabilidade BN (1; p) se, e somente se, Nn = min(X1, , Xn) tem distribuição geométrica de parâmetro 1 − (1 − p)n.\nSejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias independentes e igualmente distribuídas com função de densidade comum\n\nf (x) =\nσ 0, se x ≤ \nMostre que X_{(1)}, X_{(2)} − X_{(1)}, X_{(3)} − X_{(2)}, , X_{(n)} − X(n−1) são independentes. 6. Sejam \\(X_1, X_2, \\cdots , X_n\\) variáveis aleatórias independentes e igualmente distribuídas com função de distribuição acumulada comum\nF (t) =\ntα, se 0 &lt; t &lt; 1  1, se t ≥ 1\npara α &gt; 0. Mostre que X_{(i)}/X_{(n)}, i = 1, 2, , n − 1 e X_{(n)} são independentes. 7. Sejam X1 e X2 duas variáveis aleatórias discretas independentes com função de probabilidade comum P (X = x) = (1 − )x−1, x = 1, 2, ; 0 &lt; &lt; 1· Mostre que X_{(1)} e X_{(2)} − X_{(1)} são independentes. 8. Sejam X1, , Xn duas variáveis aleatórias independentes com função de densidade comum \\(F\\) . Encontre a função de densidade de X_{(1)} e de X_{(n)}.\n\nSejam X_{(1)}, X_{(2)}, , X_{(n)} as estatísticas de ordem de n variáveis aleatórias independentes e igualmente distribuídas \\(X_1, X_2, \\cdots , X_n\\) com função de densidade comum f (x) = 1 se 0 &lt; x &lt; 1 · 0, caso contrário Prove que Y1 = X_{(1)}/X_{(2)}, Y2 = X_{(2)}/X_{(3)}, , Yn−1 = X(n−1)/X_{(n)} e Yn = X_{(n)} são independentes. Encontre a função de densidade conjunta de Y1, Y2, , Yn.\nSejam X1.X2, , Xn variáveis aleatórias independentes identicamente distribuídas não negativas contínuas. Prove que se E|X| &lt; ∞, então E|X(r)| &lt; ∞. Definamos Mn = X_{(n)} = max\\((X_1, X_2, \\cdots , X_n)\\). Mostre que ∫ ∞\n\nEncontre E(Mn) em cada uma das seguintes situações: a) Xk tem como função de distribuição comum \\(F\\) (x) = 1 − e−xβ, se x ≥ 0. b) Xk tem como função de distribuição comum \\(F\\) (x) = x, se 0 &lt; x &lt; 1.\n\nProvar que, qualquer seja a amostra aleatória X1.X2, , Xn sempre cumpre-se que X_{(1)} ≤ X ≤ X_{(n)}.\nDemonstrar o Teorema 2.5.\nDemonstrar o Teorema 2.9.\n\nExercícios da Seção 2.3 1. Demonstre o Corolário 2.17. 2. Demonstre o Corolário 2.18.\n\nSeja X1, , Xn uma amostra aleatória Poisson(). Encontre Var(S2) e compare-a com Var(X). Observe que E(X) = = E(S2).\nSeja \\(X_1, X_2, \\cdots , X_n\\) uma amostra aleatória da função de distribuição \\(F\\) e seja \\(F\\) ∗(x) a função de distribuição amostral. Encontre Cov[F ∗(x), \\(F\\) ∗(y)] para números reais fixos x, y. n n\nSeja \\(F\\) ∗ a função de distribuição empírica de uma amostra aleatória com função de distribuição teórica \\(F\\) . Prove que { ∗ ϵ } 1\nSejam \\(X_1, X_2, \\cdots , X_n\\) n observacões independentes da variável aleatória X. Encontre a distribuição amostral de X, a média amostral, se:\n\n\nX ∼ P ();\nX ∼ Cauchy(1, 0);\nX ∼ χ2(m).\n\n\nSeja X1, , Xn uma amostra aleatória Poisson(). Encontre Var(S2) e compare-a com Var(X). Observe que E(X) = = E(S2).\nDemonstre o Teorema 2.23. [Dica: para quaisquer reais µ e σ &gt; 0, encontre a função de densidade de (U(r) − µ)/σ e mostre que as variáveis padronizadas de U(r), (U(r) − µ)/σ, são assintoticamente N (0, 1) sob as condições do teorema.]\nProvar que o momentos amostral central b1 é sempre zero.",
    "crumbs": [
      "Prefácio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estatísticas de Ordem</span>"
    ]
  },
  {
    "objectID": "content/Modulo04/index.html",
    "href": "content/Modulo04/index.html",
    "title": "4  Função de Distribuição Empírica",
    "section": "",
    "text": "4.1 Exercícios",
    "crumbs": [
      "Prefácio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Função de Distribuição Empírica</span>"
    ]
  },
  {
    "objectID": "content/Modulo04/index.html#exercícios",
    "href": "content/Modulo04/index.html#exercícios",
    "title": "4  Função de Distribuição Empírica",
    "section": "",
    "text": "Gere 100 observações a partir de uma distribuição \\(N(0,1)\\). Calcule uma faixa de confiança de 95% para a função de distribuição empírica \\(\\widehat{F}_n\\). Repita isso 1000 vezes e veja com que frequência a faixa de confiança contém a verdadeira função de distribuição. Repita usando dados de uma distribuição Cauchy.\nSeja \\(X_1,\\cdots, X_n\\) uma amostra aleatória da distribuição \\(F\\) e seja \\(\\widehat{F}_n\\) a função de distribuição empírica. Para um \\(x\\) fixo, encontre a distribuição limite de \\(\\sqrt{\\widehat{F}_n(x)}\\).\nSejam \\(x\\) e \\(y\\) dois pontos distintos. Encontre \\(\\mbox{Cov}\\Big(\\widehat{F}_n(x),\\widehat{F}_n(y)\\Big)\\).",
    "crumbs": [
      "Prefácio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Função de Distribuição Empírica</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html#funções-limites-e-continuidade",
    "href": "content/Modulo01/index.html#funções-limites-e-continuidade",
    "title": "1  Cálculo Diferencial e Integral",
    "section": "",
    "text": "Definição 1.1\n\n\n\nUma função escrita como \\(y = f(x)\\) associa um número \\(y\\) a cada valor de \\(x\\).\n\n\n\n\n\n\nIntervalo aberto não contém as extremidades: notação \\((a,b)\\).\nIntervalo fechado contém as extremidades: notação \\([a,b]\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinição 1.2\n\n\n\nParâmetro é uma quantidade conhecida que indexa ou parametriza uma determinada função.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.1 Funções com duas ou mais variáveis independentes\nAté aqui discutimos funções com apenas uma variável de entrada. No entanto, em termos práticos precisamos de funções com um número arbitrário de variáveis independentes. Lembre do exemplo da companhia seguradora, onde um conjunto de \\(p\\) perguntas ou variáveis independentes serão combinadas por um modelo para fornecer o preço que deve ser pago pelo seguro. Em termos de notação vamos utilizar \\(\\boldsymbol{x} = (x_1, \\ldots, x_p)^{\\top}\\) para representar um vetor linha transposto (vetor coluna). Novamente os conceitos de vetor e de transposto serão formalmente definidos no Capítulo 2, onde vamos falar de Álgebra Matricial.\n\n\n\n\n\n\nDefinição 1.3\n\n\n\nUma função escrita como \\(y = f(\\boldsymbol{x})\\) associa um número \\(y\\) a cada vetor de entrada \\(\\boldsymbol{x}\\).\n\n\nNote que a Definição 1.3 é ligeiramente diferente da Definição 1.1, onde agora um vetor de entradas resultará em apenas um número de saída. Cuidado também para não confundir a forma como o R vetoriza as funções de uma única variável independente, com funções de múltiplas variáveis independente. Vamos ver um exemplo para esclarecer e ilustrar as diferenças.\nExample 1.1 Considere a função de duas variáveis \\(x_1\\) e \\(x_2\\) definida por\n\\[\nf(x_1, x_2) = \\sqrt{25 - x_1^2 - x_2^2},\n\\] avalie a função nos pontos \\(\\boldsymbol{x} = (0, 0)\\), \\(\\boldsymbol{x} = (3, 0)\\) e desenhe seu gráfico.\nPrimeiro, é importante verificar que o domínio de \\(f(\\boldsymbol{x})\\) é o conjunto de todas as duplas ordenadas \\((x_1, x_2)\\) tal que \\(25 - x_1^2 - x_2^2 \\geq 0\\). Uma vez que a raiz quadrada de números negativos não existe. Vamos implementar esta função em R para avaliar seu valor nos pontos pedidos.\nCódigo 1.2 Exemplo de função bidimensional (entrada vetor).\n\nfx1x2 &lt;- function(x) {\n  y = sqrt(25 - x[1]^2 - x[2]^2)\n  return(y)\n}\n\nO primeiro ponto a notar é que agora precisamos entrar com um vetor de tamanho 2. Vamos avaliar a função nos pontos pedidos, ou seja, \\[y = \\sqrt{25 - 0^2 - 0^2} = 5 \\quad \\text{e} \\quad y = \\sqrt{25 - 3^2 - 0^2} = 4.\\] Novamente, em R temos\n\nentrada1 &lt;- c(0, 0)\nentrada2 &lt;- c(3, 0)\nfx1x2(x = entrada1)\n\n[1] 5\n\n\n\nfx1x2(x = entrada2)\n\n[1] 4\n\n\nLembre-se que no caso de funções de uma única variável de entrada o R automaticamente vetorizava a operação, ou seja, aplicava a função a cada ponto do vetor de entrada. Vejamos o que acontece caso a mesma estratégia seja usada em nossa função com duas variáveis de entrada.\n\nx &lt;- c(entrada1, entrada2)\nfx1x2(x = x)\n\n[1] 5\n\n\nPela forma como a função fx1x2() captura o vetor de entrada pelas suas posições, todos os valores além da posição \\(2\\) foram ignorados pela fx1x2(). Neste caso, uma das formas de avaliar a função em mais de um ponto é usar uma instrução for percorrendo uma matriz de entradas por linha.\n\nentrada &lt;- matrix(c(entrada1, entrada2), ncol = 2, nrow = 2, byrow = TRUE)\nentrada\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    3    0\n\n\n\nsaida &lt;- c()\nfor(i in 1:2) {\n  saida[i] &lt;- fx1x2(entrada[i,])\n}\nsaida\n\n[1] 5 4\n\n\nNão se preocupe com a sintaxe R neste momento. Apenas note que para obter um valor de saída foi necessário combinar dois valores de entrada.\nDesenhar o gráfico de uma função com mais de uma entrada é uma tarefa mais complicada do que no caso de uma única variável de entrada. Note que agora o gráfico da função é o conjunto das triplas ordenadas \\((y, x_1, x_2)\\) que satisfazem a função. Neste caso estamos no espaço \\(\\Re^3\\).\nPara desenhar o gráfico da função do exemplo 1.1 precisamos primeiro montar uma grade de valores combinando um conjunto de valores para \\(x_1\\) com um conjunto de valores para \\(x_2\\). Este processo é ilustrado da Figura 1.7 (A). O segundo passo é avaliar a função em cada um dos pontos criados, processo ilustrado na Figura 1.7 (B). Note que em alguns casos a função retornou NaN isso significa que a função não tem um valor associado naquele ponto. Neste caso estamos avaliando a função fora do seu domínio. O último passo é encontrar uma forma de representar o valor da função no gráfico. A forma mais popular é representar o valor usando uma paleta de cores, conforme ilustrado na Figura 1.7 (C).\n\n\n\n\n\n\n\n\nFigure 1.7: Passo-a-passo para desenhar uma função de duas variáveis independentes.\n\n\n\n\n\nNos gráficos apresentados na Figura 1.7 utilizamos uma grade com apenas \\(25\\) valores, o que resultou em um representação grosseira da função. Porém, podemos aumentar essa grade melhorando assim a representação da função, conforme apresentado na Figura 1.8, onde usamos uma grade com \\(2500\\) valores. É usual também incluir as chamadas “curvas de nível,” que são linhas que mostram onde a função assume os mesmos valores.\n\n\n\n\n\n\n\n\nFigure 1.8: Ilustração do gráfico de uma função de duas variáveis de entrada.\n\n\n\n\n\nPara funções com mais de duas variáveis de entrada não temos uma forma simples de representação gráfica. O usual é fixar um conjunto de entradas e desenhar o gráfico da função na direção das variáveis não fixadas, usando os gráficos vistos para funções de uma ou duas entradas. Por fim, funções com duas ou mais variáveis independentes também podem ser parametrizadas de forma análoga à forma descrita para funções de uma variável independente, conforme a Definição 1.4.\n\n\n\n\n\n\nDefinição 1.4\n\n\n\nUma função escrita como \\(y = f(\\boldsymbol{x};\\boldsymbol{\\theta})\\) associa um número \\(y\\) a cada vetor de entrada \\(\\boldsymbol{x}\\) e \\(\\boldsymbol{\\theta}\\) denota um vetor de parâmetros conhecidos.\n\n\n\n\n1.1.2 Funções especiais\nDada a complexidade das aplicações em ciência de dados é comum se deparar com funções mais elaboradas. Nesta subseção vamos apresentar algumas das funções mais comuns em ciência de dados.\n\n\n\n\n\n\nDefinição 1.5\n\n\n\nFunções polinomiais são funções do tipo \\[y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\ldots \\beta_p x^p.\\]\n\n\nPor exemplo, as funções polinomiais de grau até três são apresentadas abaixo:\n\nFunção linear: \\(y = \\beta_0 + \\beta_1 x\\).\nFunção quadrática: \\(y = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\).\nFunção cúbica: \\(y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3\\).\n\nSeus respectivos gráficos são apresentados na Figura 1.9.\n\n\n\n\n\n\n\n\nFigure 1.9: Exemplos de gráficos de funções polinomiais.\n\n\n\n\n\nAlguns pontos importantes a notar:\n\nEm todas as funções os parâmetros são representados pela letra \\(\\beta\\) associada a um índice para distinguir entre os coeficientes.\ngráfico da função linear é sempre uma reta.\nO gráfico de uma função quadrática é uma parábola aberta para cima se \\(\\beta_2 &gt; 0\\) e para baixo se \\(\\beta_2 &lt; 0\\).\nO intercepto é dado por \\(\\beta_0\\) em todas as funções.\nNas funções lineares o parâmetro \\(\\beta_1\\) representa a declividade da linha.\nA função cúbica pode ser simplificada para quadrática fazendo \\(\\beta_3 = 0\\) e para linear fazendo ambos \\(\\beta_3 = \\beta_2 = 0\\).\n\nEm R podemos facilmente escrever as funções polinomiais explicitamente ou usar a função poly(). Veja ?poly para exemplos de como declarar polinômios em R usando bases ortogonais para evitar problemas numéricos.\n\n\n\n\n\n\nDefinição 1.6\n\n\n\nFunções do tipo potência são funções da forma \\[y = x^a,\\] onde \\(y\\) é a variável dependente, \\(x\\) a variável independente e \\(a\\) um expoente constante (parâmetro).\n\n\nPor definição, \\(x^0 = 1\\), ou seja, qualquer número elevado a \\(0\\) é igual a \\(1\\). Note que um número sem expoente está elevado a \\(1\\). As propriedades mais importantes das funções potência são:\n1.\\(x^a (x^c) = x^{a+c}\\);\n2.\\((x^a)^c = x^{ac}\\);\n3.\\((xz)^a = x^a (z^a)\\);\n4.\\(\\left ( \\frac{x}{z} \\right )^c = \\frac{x^c}{z^c}\\);\n5.\\(\\frac{1}{x^a} = x^{-a}\\);\n6.\\(\\frac{x^a}{x^c} = x^{a-c}\\);\n7.\\(\\sqrt{x} = x^{1/2}\\);\n8.\\(\\sqrt[a]{x} = x^{1/a}\\);\n9.\\(\\sqrt[c]{x^a} = x^{a/c}\\).\n\n\n\n\n\n\nDefinição 1.7\n\n\n\nFunções exponenciais são funções compostas de uma base \\(a\\) constante e de um expoente variável, ou seja, \\[y = a^x,\\] onde \\(a\\) é maior que zero e diferente de \\(1\\). Note que novamente, temos um exemplo de função parametrizada.\n\n\nFunções exponenciais são usadas para representar taxas constantes de crescimento discreto. Exemplos comuns são os problemas relacionados a juros compostos, descontos e depreciação. Em muitos problemas práticos é comum inserir alguns parâmetros extras para controlar o comportamento de funções exponenciais, por exemplo\n\\[\ny = b a^{cx}.\n\\]\nUma aplicação simples é calcular o valor futuro de um investimento a taxa de juros constante em um período fixo de tempo. Suponha que você investiu \\(R\\$ 1000,00\\) a uma taxa de juros anual de \\(8\\%\\) por 10 anos. O valor que você terá ao final do período é de \\(1000(1 + 0,08)^{10} = 2158,92\\).\n\n\n\n\n\n\nDefinição 1.8\n\n\n\nFunções exponenciais naturais são funções exponenciais que tem como sua base \\(e = \\lim_{n \\to \\infty} \\left [ 1 + (1/n) \\right ]^n = 2,718281828.\\)\n\n\nAs funções exponenciais naturais descrevem taxas constantes de crescimento contínuo ao invés de intervalos discretos. São muito utilizadas para compor distribuições de probabilidade, para descrever taxas de crescimento populacional, entre outros. Note que na Definição 1.8 temos uma notação diferente, \\(\\lim_{n \\to \\infty}\\), que ainda não foi definida. Esta notação é lida como no limite quando \\(n\\) tende a infinito. A ideia deste novo operador é justamente o que ele sugere, ou seja, o que acontece com a função quando um de seus parâmetros neste caso o \\(n\\) recebe valores muito elevados. Nós vamos ver mais detalhes sobre limites na próxima seção. A seguir são apresentadas algumas propriedades importantes de expoentes naturais:\n\n\\(e^0 = 1\\).\n\\(e^{1} = e = 2,71828\\).\n\\(e^a (e^b) = e^{a+b}\\).\n\\((e^a)^b = e^{ab}\\).\n\\(\\frac{e^{a}}{e^{b}} = e^{a-b}\\).\n\nEm R a função exponencial está disponível por meio da função exp(). Veja alguns exemplos\n\nexp(0)\n\n[1] 1\n\n\n\nexp(1)\n\n[1] 2.718282\n\n\n\nall.equal(exp(5)*exp(10), exp(5+10))\n\n[1] TRUE\n\n\n\n\n\n\n\n\nDefinição 1.9\n\n\n\nFunções logarítmicas ou logaritmo é a potência à qual uma dada base deve ser elevada para se obter um particular número.\n\n\nLogaritmos comuns utilizam a base \\(10\\) e são escritos \\(\\log_{10}\\). Por exemplo, desde que \\(10^2 = 100\\), \\(2\\) é o \\(\\log\\) de \\(100\\). De maneira similar, para qualquer função exponencial \\(y = a^x\\), onde \\(a\\) é a base e \\(x\\) o expoente, \\[\\log_a y = x\\] \\(x\\) é a potência à qual \\(a\\) deve ser elevado, para obter-se \\(y\\). Para números que não são potências exatas a obtenção dos logaritmos é feita via interpolação. Os logaritmos na base natural \\(e\\) são chamados de logaritmos naturais ou neperianos e denotados por \\(\\log_e\\) ou simplesmente \\(\\ln\\). A formação destes logaritmos é mais complexa e fora do escopo deste material. Porém, para fins de aplicações o R fornece a função log() para obter logaritmos em qualquer base. Algumas relações entre funções logarítmicas e exponenciais.\n\nSe \\(\\log_{10} y = 2x\\), então \\(y = 10^{2x}.\\)\nSe \\(\\log_{a} y = xz\\), então \\(y = a^{xz}.\\)\nSe \\(\\ln y = 5t\\), então \\(y = e^{5t}.\\)\nSe \\(y = a^{3x}\\), então \\(\\log_{a} y = 3x.\\)\nSe \\(y = 10^{6x}\\), então \\(\\log_{10} y = 6x.\\)\nSe \\(y = e^{t+1}\\), então \\(\\ln y = t + 1.\\)\n\nOutras funções importantes no contexto de redes neurais artificiais são as seguintes:\n\nFunção sigmóide ou logística: \\(y = \\frac{1}{1+ e^{-x} }\\), onde \\(I = (0,1)\\) e \\(D = \\Re\\);\nFunção tangente hiperbólica: \\(y = \\frac{e^x- e^{-x}}{e^{x} + e^{-x}}\\), onde \\(I = (-1,1)\\) e \\(D = \\Re\\).\nFunção linear retificada (ReLU): \\(y = \\max\\{0,x\\}\\), onde \\(I = \\Re_{+}\\) e \\(D = \\Re\\).\nFunção leaky ReLU: \\(y = \\max\\{\\alpha x, x\\}\\), onde \\(\\alpha\\) é uma parâmetro conhecido, \\(I = \\Re\\) e \\(D = \\Re\\).\n\nPor fim, a Figura 1.10 apresenta os gráficos de algumas das funções apresentadas.\n\n\n\n\n\n\n\n\nFigure 1.10: Exemplos de gráficos de funções: (A) potência (a = 2); (B) exponencial natural; (C) Log natural; (D) Log 10; (E) Sigmóide; (F) Tangente hiperbólica; (G) ReLU; (H) Leaky ReLU.\n\n\n\n\n\n\n\n1.1.3 Limites e continuidade\nNo decorrer da nossa discussão sobre funções nos deparamos com o conceito de limite, por exemplo na definição da função exponencial natural. Nesta subseção vamos definir o conceito de limite e algumas de suas implicações para o estudo de funções.\n\n\n\n\n\n\nDefinição 1.10\n\n\n\nSe uma função \\(f(x)\\) se aproxima de um número \\(L\\) conforme \\(x\\) tende a um número \\(a\\) vindo da direita ou da esquerda, dizemos que o limite de \\(f(x)\\) tende a \\(L\\) quando \\(x\\) tende a \\(a\\).\n\n\nUsaremos a notação \\[\\lim_{x \\to a } f(x) = f(a) = L.\\] O limite pode não existir, mas se existir será único. Vamos ver um exemplo trivial, considere o limite \\[\\lim_{x \\to 1} (x + 1) = 2.\\] Graficamente temos ```{r out.width=“80%”, echo=FALSE} #| label: fig-18 #| fig-cap: knitr::include_graphics(“./img/plotSQmu-1.png”)” id=“fig:lim1”&gt; \n\nFigura 1.11: Ilustração de limite - Trivial.\n::: Considere o limite \\[\\lim_{x \\to 1} \\frac{x^2 - 1}{x-1} = ?\\] Note que neste caso tomando \\(x = 1\\) nos leva a uma divisão por zero. Graficamente, temos ```{r out.width=“80%”, echo=FALSE} #| label: fig-18 #| fig-cap: knitr::include_graphics(“./img/plotSQmu-1.png”)” id=“fig:lim2”&gt; \n\nFigura 1.12: Ilustração de limite - Não trivial\n::: No entanto, podemos manipular a equação de modo que \\[\\lim_{x \\to 1} \\frac{x^2 - 1}{x-1} =  \\lim_{x \\to 1} \\frac{(x+1)(x-1)}{x-1} = \\lim_{x \\to 1} (x+1) = 2. \\] O que nos leva a definição intuitiva de limite.\n\n\n\n\n\n\nDefinição 1.11\n\n\n\nDefinição intuitiva O limite de uma função é o valor que achamos natural para ela em um determinado ponto.\n\n\nMunidos da definição de limite podemos definir o conceito de funções contínuas.\n\n\n\n\n\n\nDefinição 1.12\n\n\n\n*Dizemos que uma função é contínua em \\(x = a\\) se três condições forem satisfeitas:\n1.\\(f(a)\\) existe, 1.\\(\\lim_{x \\to a} f(x)\\) existe e 1.\\(\\lim_{x \\to a} f(x) = f(a).\\)\n\n\nContinuidade em termos práticos significa que pequenas variações na variável independente levam a pequenas variações na variável dependente. O Teorema do valor intermediário no diz que se a função \\(f(x)\\) é contínua no intervalo fechado \\([a,b]\\), então existe pelo menos um número \\(c\\) em \\([a,b]\\) tal que \\(f(c) = M\\). A implicação direta desse teorema é que se \\(f(x)\\) é contínua seu gráfico não contém salto vertical. Em geral podemos pensar em funções contínuas como sendo funções suaves. Considere a seguinte função não contínua em \\(0\\), cujo gráfico é apresentado na Figura 1.13. \\[\\lim_{x \\to 0} \\frac{|x|}{x} = \\left\\{\\begin{matrix}\n-1 \\quad x &lt; 0 \\\\\n1 \\quad x &gt; 0.\n\\end{matrix}\\right. \\] ```{r out.width=“80%”, echo=FALSE} #| label: fig-18 #| fig-cap: knitr::include_graphics(“./img/plotSQmu-1.png”)” id=“fig:naocont”&gt; \n\nFigura 1.13: Ilustração de função não contínua.\n::: Para finalizar esta subseção, vejamos algumas propriedades importantes de limites que mostram que podemos operar com limites de forma muito similar ao que fazemos com escalares (números). Se \\(\\lim_{x \\to p} f(x) = L_1\\) e \\(\\lim_{x \\to p} g(x) = L_2\\), então\n1.O limite de uma soma é igual à soma dos limites das parcelas; \\[\\lim_{x \\to p}[f(x) + g(x)] = \\lim_{x \\to p}f(x) + \\lim_{x \\to p} g(x) = L_1 + L_2.\\] 1.Uma constante \\(k\\) pode sair do limite sem alterar a solução; \\[\\lim_{x \\to p} k f(x) = k \\lim_{x \\to p} f(x) = k L_1.\\] 1.O limite de um produto é igual ao produto dos limites; \\[\\lim_{x \\to p} f(x)g(x) =  \\lim_{x \\to p} f(x) \\lim_{x \\to p} g(x) = L_1 L_2.\\] 1.O limite da razão é a razão dos limites, desde que o denominador não seja zero; \\[\\lim_{x \\to p} \\frac{f(x)}{g(x)} = \\frac{L_1}{L_2},\\] desde que \\(L_2 \\neq 0\\).\nNesta subseção dois importantes conceitos foram apresentados, o de limite e de continuidade de uma função. Ambos serão úteis para definirmos a derivada de uma função, assunto da próxima seção. ::: :::",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cálculo Diferencial e Integral</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#funções-limites-e-continuidade",
    "href": "content/Modulo02/index.html#funções-limites-e-continuidade",
    "title": "2  Cálculo Diferencial e Integral para Cientista de Dados",
    "section": "",
    "text": "Ganhar experiência com a interpretação de equações matemáticas.\nPraticar a implementação computacional de funções matemáticas.\nDesenhar e interpretar o gráfico de funções uni e bidimensionais.\nRevisar e ilustrar computacionalmente propriedades de funções do tipo potência, exponencial e logarítmos.\n\n\n2.1.1 Implementação de funções e seus gráficos\nPara os exercícios abaixo use a função plot() com a opção type = &quot;l&quot; para desenhar o gráfico das funções. Lembre-se que computacionalmente você vai avaliar a função em um conjunto de pontos. Para criar esse conjunto de pontos use a função seq(a, b, l = tamanho) onde a e b são os limites inferior e superior do intervalo e l determina o número de pontos dentro do intervalo. Recomendo que para esses exercícios você use l = 100. Você pode consultar a minha solução clicando no botão Solution. Note que a minha solução é apenas uma sugestão. O importante é você desenvolver a habilidade de traduzir uma equação matemática para o computador e desenhar o gráfico associado.\n\nImplemente a função \\(f(x) = \\sqrt{x}\\) e desenhe seu gráfico no intervalo \\((0,3)\\).\n\n\nx &lt;- seq(0, 3, l = 100)\nfx &lt;- function(x) {\n  sqrt(x)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(f(x) = \\log(x)\\) e desenhe seu gráfico no intervalo \\((-5,5)\\).\n\n\nx &lt;- seq(-5, 5, l = 100)\nfx &lt;- function(x) {\n  log(x)\n}\ny &lt;- fx(x = x)\n\nWarning in log(x): NaNs produzidos\n\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint:\n\n\n\nNote que o domínio da função \\(\\log\\) é apenas os reais positivos. Assim, a parte negativa não faz sentido para este gráfico.\n\n\n\nImplemente a função \\(\\log_{10}(x)\\) e desenhe seu gráfico no intervalo \\((0,5)\\).\n\n\nx &lt;- seq(0, 5, l = 100)\nfx &lt;- function(x) {\n  log10(x)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(\\exp(x)\\) e desenhe seu gráfico no intervalo \\((0,1)\\).\n\n\nx &lt;- seq(0, 1, l = 100)\nfx &lt;- function(x) {\n  exp(x)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(\\Gamma(x)\\) e desenhe seu gráfico no intervalo \\((0.5, 3)\\).\n\n\nx &lt;- seq(0.5, 3, l = 100)\nfx &lt;- function(x) {\n  gamma(x)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(f(x) = \\frac{1}{x}\\) e desenhe seu gráfico no intervalo \\((-1, 1)\\).\n\n\nx1 &lt;- seq(-1, 0, l = 50)\nx2 &lt;- seq(0, 1, l = 50)\nfx &lt;- function(x) {\n  1/x\n}\ny1 &lt;- fx(x = x1)\ny2 &lt;- fx(x = x2)\nplot(c(y1, y2) ~ c(x1, x2), type = \"l\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint:\n\n\n\nNote que neste exercício o ideal é dividir o domínio de \\(f(x)\\) em duas partes, uma vez que a função é descontinua em \\(x = 0\\). Avalie a função no ponto \\(x = 0\\) para ver o que o R retorna.\n\n\n\nImplemente a função \\(f(x) = |x - 1| + 2\\) e desenhe seu gráfico no intervalo \\((-5, 5)\\).\n\n\nx &lt;- seq(-5, 5, l = 100)\nfx &lt;- function(x) {\n  abs(x - 1) + 2\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(f(x) = \\mathrm{beta}(x, 0.5)\\) e desenhe seu gráfico no intervalo \\((0, 1)\\).\n\n\nx &lt;- seq(0, 1, l = 100)\nfx &lt;- function(x) {\n  beta(a = x, b = 0.5)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint:\n\n\n\nVeja a documentão da função beta ?beta.\n\n\n\nImplemente a função \\(f(x) = (x-1)^3\\) e desenhe seu gráfico no intervalo \\((-3, 5)\\).\n\n\nx &lt;- seq(-3, 5, l = 100)\nfx &lt;- function(x) {\n  (x - 1)^3\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(f(x) = \\frac{(x+1)}{x}\\) e desenhe seu gráfico no intervalo \\((-3, 3)\\).\n\n\nx1 &lt;- seq(-3, 0, l = 100)\nx2 &lt;- seq(0, 3, l = 100)\nfx &lt;- function(x) {\n  (x+1)/x\n}\ny1 &lt;- fx(x = x1)\ny2 &lt;- fx(x = x2)\nplot(c(y1, y2) ~ c(x1, x2), type = \"l\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint:\n\n\n\nNote novamente a descontinuidade de \\(f(x)\\) no ponto \\(x = 0\\).\n\n\n\n\n2.1.2 Funções parametrizadas\nPara os exercícios abaixo você deve fazer o gráfico como uma função de \\(x\\) com o parâmetro \\(\\theta\\) fixado. Tenha cuidado tanto com o domínio de \\(f(x)\\) quanto com o espaço paramétrico de \\(\\theta\\), ou seja, o conjunto de valores que \\(\\theta\\) pode assumir. Para entender como o parâmetro controla a curva você deve desenhar o gráfico usando diversos valores para \\(\\theta\\).\n\n2.1.2.1 Considere a função \\(f(x; \\theta) = \\left( x \\log \\frac{x}{\\theta} - x + \\theta\\right)\\).\n\nImplemente a função e desenhe seu gráfico com \\(\\theta = 10\\).\n\n\nx &lt;- seq(0, 20,  l = 100)\nfx &lt;- function(x, theta) {\n  out &lt;- x*log(x/theta) - x + theta\n  return(out)\n}\ny &lt;- fx(x = x, theta = 10)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nQual é o domínio de \\(f(x)\\)?\n\n\nReais\nIntervalo (0,1)\nReais estritamente positivos\nNaturais\n\n\nQual é o espaço paramétrico de \\(\\theta\\)?\n\n\nReais\nIntervalo (0,1)\nReais estritamente positivos\nInteiros positivos\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para baixo.\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para baixo.\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para cima.\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para cima.\n\n\n\n2.1.2.2 Considere a função \\(f(x; \\theta) = \\binom{100}{x} \\exp \\left\\{x \\log \\frac{\\theta}{1-\\theta} +100 \\log(1 - \\theta) \\right\\}\\).\n\nImplemente a função e desenhe seu gráfico considerando \\(\\theta = 0.40\\).\n\n\nx &lt;- 0:100\nfx &lt;- function(x, theta) {\n  out &lt;- choose(n = 100, k = x) * exp(x * log(theta/(1-theta)) + 100*log(1- theta))\n  return(out)\n}\ny &lt;- fx(x = x, theta = 0.4)\nbarplot(y ~ x)\n\n\n\n\n\n\n\n\n\nQual é o domínio de \\(f(x)\\)?\n\n\nReais\nIntervalo (0,1)\nInteiros (0, 100)\nInteiros de [0, 100]\n\n\nQual é o espaço paramétrico de \\(\\theta\\)?\n\n\nReais ✗\nIntervalo (0,1) ✓\nReais estritamente positivos ✗\nReais estritamente negativo ✗\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para baixo. ✗\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para baixo. ✓\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para cima. ✗\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para cima. ✗\n\n\n\n2.1.2.3 Considere a função \\(f(x; \\theta) = \\sum_{i=1}^n \\left( \\frac{x_i}{\\theta} -\\log \\left\\{ \\frac{x_i}{\\theta} \\right \\} -1 \\right )\\).\n\nImplemente a função e desenhe seu gráfico considerando \\(\\theta = 10\\).\n\n\nfx &lt;- function(x, theta) {\n  out &lt;- (x/theta) - log(x/theta) - 1\n  return(out)\n}\nx &lt;- seq(5, 15, l = 100)\ny &lt;- fx(x = x, theta = 10)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nQual é o domínio de \\(f(x)\\)?\n\n\nReais ✗\nIntervalo (0,1) ✗\nReais estritamente positivos ✓\nIntervalo (0,2π] ✗\n\n\nQual é o espaço paramétrico de \\(\\theta\\)?\n\n\nReais ✗\nIntervalo (0,1) ✗\nReais estritamente positivos ✓\nIntervalo (0,2π] ✗\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para baixo.\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para baixo.\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para cima.\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para cima.\n\n\n\n2.1.2.4 Considere a função \\(f(x; \\theta) = (1 - \\cos(x - \\theta))\\).\n\nImplemente a função e desenhe seu gráfico considerando \\(\\theta = 2\\).\n\n\nfx &lt;- function(x, theta) {\n  out &lt;- (1 - cos(x - theta))\n  return(out)\n}\nx &lt;- seq(0, 2*pi, l = 100)\ny &lt;- fx(x = x, theta = 2)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nEntre as opções abaixo para o domínio de \\(f(x)\\) qual garante que \\(f(x)\\) tenha apenas um mínimo relativo?\n\n\nReais ✗\nInteiros ✗\nReais estritamente positivos ✗\nIntervalo (0,2π] ✓\n\n\nConsiderando b) qual é o espaço paramétrico de \\(\\theta\\)?\n\n\nReais ✗\nIntervalo (0,1) ✗\nReais estritamente positivos ✗\nIntervalo (0,2π] ✓\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para baixo. ✗\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para baixo. ✗\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para cima. ✓\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para cima. ✗\n\n\n\n2.1.2.5 Considere a função \\(f(x; \\theta, p) = 2\\left \\{ \\frac{x^{(2-p)}}{(1-p)(2-p)} - \\frac{x \\theta^{(1-p)}}{1-p} + \\frac{\\theta^{(2-p)}}{2-p} \\right \\}\\).\n\nImplemente a função e desenhe seu gráfico considerando \\(\\theta = 5\\) e \\(p = 1.5\\).\n\n\nfx &lt;- function(x, theta, p) {\n  term1 &lt;- ( x^(2-p) )/( (1-p)*(2-p) )\n  term2 &lt;- (x*(theta^(1-p)))/(1-p)\n  term3 &lt;- (theta^(2-p))/(2-p)\n  out &lt;- 2*(term1 - term2 + term3)\n  return(out)\n}\nx &lt;- seq(0, 20, l = 100)\ny &lt;- fx(x = x, theta = 5, p = 1.5)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nQual é o domínio de \\(f(x)\\)?\n\n\nReais ✗\nInteiros ✗\nReais estritamente positivos ✓\nIntervalo (0,2π]. ✗\n\n\nQual o espaço paramétrico de \\(\\theta\\) e \\(p\\)?\n\n\n\\(\\theta\\) é real e \\(p\\) é estritamente positivo. ✗\nIntervalo (0,1) para ambos ✗\n\\(\\theta\\) é real e \\(p \\in (1,2)\\). ✗\n\\(\\theta\\) é real estritamente positivo e \\(p \\in (1,2)\\) ✓\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro \\(\\theta\\) indica o ponto de minimo relativo e a curva é côncava para baixo. ✗\nO parâmetro \\(\\theta\\) indica o ponto de máximo relativo e a curva é côncava para baixo. ✗\nO parâmetro \\(\\theta\\) indica o ponto de minimo relativo e a curva é côncava para cima. ✓\nO parâmetro \\(\\theta\\) indica o ponto de máximo relativo e a curva é côncava para cima. ✗\n\n\n\n\n2.1.3 Limites\n\n2.1.3.1 Considere a seguinte função \\(f(x) = \\sqrt{x} + x\\).\n\nEsboce o gráfico e marque o ponto \\(x = 0\\).\n\n\nx &lt;- seq(0, 2,  l = 100)\nfx &lt;- function(x) {\n  out &lt;- sqrt(x) + x\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = 0, y = fx(x = 0), pch = 18)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to 0 } ( \\sqrt{x} + x)\\).\n\n\n-2 ✗\n4 ✗\n0 ✓\n6/5 ✗\n1 ✗\n\n\n\n2.1.3.2 Considere a seguinte função \\(f(x) = \\frac{x^2 + x}{ x + 3}\\).\n\nEsboce o gráfico e marque o ponto \\(x = 2\\).\n\n\nx &lt;- seq(0, 4,  l = 100)\nfx &lt;- function(x) {\n  out &lt;- (x^2 + x)/(x + 3)\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = 2, y = fx(x = 2), pch = 18)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to 2 } \\frac{x^2 + x}{ x + 3}\\).\n\n\n6/5 ✓\n4 ✗\n-2 ✗\n1 ✗\n6 ✗\n\n\n\n2.1.3.3 Considere a seguinte função \\(f(x) = \\frac{x^2 - 4}{x-2}\\).\n\nEsboce o gráfico e marque o ponto \\(x = 2\\).\n\n\nx &lt;- c(seq(1, 2, l = 50), 2, seq(2, 3, l = 50))\nfx &lt;- function(x) {\n  out &lt;- (x^2 - 4)/(x - 2)\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = 2, y = 4, pch = 1)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to 2 } \\frac{x^2 - 4}{x - 2}\\).\n\n\n-2 ✗\n4 ✓\n0 ✗\n6/5 ✗\n1 ✗\n\n\n\n2.1.3.4 Considere a seguinte função \\(f(x) = \\frac{x^2 - 1}{x + 1}\\).\n\nEsboce o gráfico e marque o ponto \\(x = -1\\).\n\n\nx &lt;- seq(-3, 0,  l = 100)\nfx &lt;- function(x) {\n  out &lt;- (x^2 - 1)/(x + 1)\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = -1, y = -2, pch = 1)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to -1 } \\frac{x^2 - 1}{x + 1}\\).\n\n\n-2 ✗\n4 ✓\n0 ✗\n6/5 ✗\n1 ✗\n\n\n\n2.1.3.5 Considere a seguinte função \\(f(x) = \\sin(x)\\).\n\nEsboce o gráfico e marque o ponto \\(x = 0\\).\n\n\nx &lt;- seq(-3, 3,  l = 100)\nfx &lt;- function(x) {\n  out &lt;- sin(x)\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = 0, y = fx(x = 0), pch = 18)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to 0 } \\sin(x)\\).\n\n\n-2 ✗\n4 ✗\n0 ✓\n6/5 ✗\n1 ✗\n\n\n\n\n2.1.4 Continuidade\nConsidere as seguintes funções:\n\n\\(f(x) = \\sqrt{x}\\) em \\(x = 0\\).\n\\(f(x) = \\frac{x^2 - 4}{x-2}\\) em \\(x = 2\\).\n\\(f(x) = \\left\\{\\begin{matrix} x \\quad \\text{se} \\quad x &lt; 1 \\\\ \\frac{1}{x} \\quad \\text{se} \\quad x &gt; 1 \\quad \\text{em} \\quad x = 1 \\end{matrix}\\right.\\)\n\\(f(x) = \\Gamma(x)\\) em \\(x = 2\\).\n\\(f(x) = \\frac{|x-2|}{x-2}\\) em \\(x = 2\\).\n\nUsando a definição intuitiva de limite marque a alternativa correta\n\na), b) e d) são contínuas. ✗\ne), b) e a) são contínuas. ✗\nb), c) e e) são não contínuas ✓\nb), c) e d) são não contínuas ✗\nApenas d) é não contínua. ✗\n\n\n\n2.1.5 Funções especiais\nIlustre computacionalmente cada uma das seguintes propriedades das funções do tipo potência.\n\n\\(x^a (x^c) = x^{a+c}\\);\n\\((x^a)^c = x^{ac}\\);\n\\((xz)^a = x^a (z^a)\\);\n\\(\\left ( \\frac{x}{z} \\right )^c = \\frac{x^c}{z^c}\\);\n\\(\\frac{1}{x^a} = x^{-a}\\);\n\\(\\frac{x^a}{x^c} = x^{a-c}\\);\n\\(\\sqrt{x} = x^{1/2}\\);\n\n\nx &lt;- 5\nz &lt;- 3\na &lt;- 2\nc &lt;- 4\nall.equal((x^a)*(x^c),x^(a+c))\n\n[1] TRUE\n\nall.equal((x^a)^c, x^(a*c))\n\n[1] TRUE\n\nall.equal((x*z)^a, (x^a) * (z^a))\n\n[1] TRUE\n\nall.equal(((x/z)^c), ((x^c)/(z^c)))\n\n[1] TRUE\n\nall.equal(1/(x^a) , x^(-a))\n\n[1] TRUE\n\nall.equal((x^a)/(x^c), x^(a-c))\n\n[1] TRUE\n\nall.equal(sqrt(x), x^0.5)\n\n[1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cálculo Diferencial e Integral para Cientista de Dados</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#derivadas",
    "href": "content/Modulo02/index.html#derivadas",
    "title": "2  Cálculo Diferencial e Integral para Cientista de Dados",
    "section": "2.2 Derivadas",
    "text": "2.2 Derivadas\nOs objetivos deste tutorial são:\n\nDerivar funções triviais.\nObter a equação da reta tangente a uma função.\nCálculo de derivadas usando a regra da cadeia.\nAproximar funções usando a expansão em séries de Taylor.\n\n\n2.2.1 Derivadas triviais\nPara cada uma das funções abaixo obtenha a sua derivada, implemente uma função chamada dx() que calcula a derivada obtida no ponto \\(x = 1/2\\) e retorna o seu valor. Para usar a correção automática a linha final do seu código deve ser dx(x = 1/2).\n\n\\(f(x) = x^4\\).\n\n\ndx &lt;- function(x) {4*x^3}\ndx(x = 1/2)\n\n[1] 0.5\n\n\n\n\\(f(x) = x^{-3}\\).\n\n\ndx &lt;- function(x) {-3/(x^4)}\ndx(x = 1/2)\n\n[1] -48\n\n\n\n\\(f(x) = \\sqrt[3]{x}\\).\n\n\ndx &lt;- function(x) {(1/3)*(x^(2/3))}\ndx(x = 1/2)\n\n[1] 0.2099868\n\n\n\n\\(f(x) = \\frac{1}{x}\\).\n\n\ndx &lt;- function(x) {-1/(x^2)}\ndx(x = 1/2)\n\n[1] -4\n\n\n\n\\(f(x) = \\sqrt[8]{x^2}\\).\n\n\ndx &lt;- function(x) {1/(4* x^(3/4))}\ndx(x = 1/2)\n\n[1] 0.4204482\n\n\n\n\\(f(x) = 4x^3 + x^2\\).\n\n\ndx &lt;- function(x) {12*x^2 + 2*x}\ndx(x = 1/2)\n\n[1] 4\n\n\n\n\\(f(x) = \\frac{2x + 3}{x^2 + 1}\\).\n\n\ndx &lt;- function(x) {\n  p1 &lt;- 2/(x^2 + 1)\n  p2 &lt;- (2*x*(2*x + 3))/(x^2 + 1)\n  return(p1 - p2)\n}\ndx(x = 1/2)\n\n[1] -1.6\n\n\n\n\\(f(x) = (3x^2 + 1) \\exp(x)\\).\n\n\ndx &lt;- function(x) {\n  out &lt;- (3*x^2 + 1)*exp(x) + 6*x*exp(x)\n  return(out)\n}\ndx(x = 1/2)\n\n[1] 7.831426\n\n\n\n\\(f(x) = 5x^4 + 6x^3 + x^2 + 2\\).\n\n\ndx &lt;- function(x) {\n  out &lt;- 20*x^3 + 18*x^2 + 2*x\n  return(out)\n}\ndx(x = 1/2)\n\n[1] 8\n\n\n\n\\(f(x) = \\log(x) 3x^4\\).\n\n\ndx &lt;- function(x) {\n  out &lt;- 12*x^3 * log(x) + 3*x^3\n  return(out)\n}\ndx(x = 1/2)\n\n[1] -0.6647208\n\n\n\n\n2.2.2 Reta tangente\nPara cada uma das funções abaixo obtenha a reta tangente a \\(f(x)\\) e esboce o gráfico. Para usar a correção aumotmática a última linha do seu código deve retornar o intercepto e a inclinação da reta tangente da seguinte forma resultado = c(intercepto, inclinacao).\n\n\\(f(x) = \\frac{1}{x}\\) em \\(x = 2\\).\n\n\n# Função\nfx &lt;- function(x) {\n  1/x\n}\n# Derivada da função\ndx &lt;- function(x) {\n -1/x^2 \n}\n# Reta tangente\nreta_tangente &lt;- function(a) {\n  intercept = (fx(x = a) - dx(x = a)*a)\n  slope &lt;- dx(x = a)\n  return(c(intercept,slope))\n}\n# Gráfico da função\nx &lt;- seq(1, 3, l = 100) ## Sequencia definindo o eixo x\nplot(fx(x) ~ x, type = \"l\") ## Desenhando a função\n\n## Reta tangente ao ponto a = 2\nreta1 &lt;- reta_tangente(a  = 2)\nintercepto = reta1[1]\ninclinacao &lt;- reta1[2]\nlines(x, c(intercepto + inclinacao*x))\n\n\n\n\n\n\n\nresultado &lt;- c(intercepto, inclinacao)\n\n\n\\(f(x) = x^3\\) em \\(x = 3\\).\n\n\n# Função\nfx &lt;- function(x) {\n  x^3\n}\n# Derivada da função\ndx &lt;- function(x) {\n 3*x^2 \n}\n# Reta tangente\nreta_tangente &lt;- function(a) {\n  intercept = (fx(x = a) - dx(x = a)*a)\n  slope &lt;- dx(x = a)\n  return(c(intercept,slope))\n}\n# Gráfico da função\nx &lt;- seq(1, 5, l = 100) ## Sequencia definindo o eixo x\nplot(fx(x) ~ x, type = \"l\") ## Desenhando a função\n\n## Reta tangente ao ponto a = 2\nreta1 &lt;- reta_tangente(a  = 3)\nintercepto = reta1[1]\ninclinacao &lt;- reta1[2]\nlines(x, c(intercepto + inclinacao*x))\n\n\n\n\n\n\n\nresultado &lt;- c(intercepto, inclinacao)\n\n\n\\(f(x) = \\exp(x)\\) em \\(x = 0\\).\n\n\n# Função\nfx &lt;- function(x) {\n  exp(x)\n}\n# Derivada da função\ndx &lt;- function(x) {\n exp(x) \n}\n# Reta tangente\nreta_tangente &lt;- function(a) {\n  intercept = (fx(x = a) - dx(x = a)*a)\n  slope &lt;- dx(x = a)\n  return(c(intercept,slope))\n}\n# Gráfico da função\nx &lt;- seq(-3, 2, l = 100) ## Sequencia definindo o eixo x\nplot(fx(x) ~ x, type = \"l\") ## Desenhando a função\n\n## Reta tangente ao ponto a = 2\nreta1 &lt;- reta_tangente(a  = 0)\nintercepto = reta1[1]\ninclinacao &lt;- reta1[2]\nlines(x, c(intercepto + inclinacao*x))\n\n\n\n\n\n\n\nresultado &lt;- c(intercepto, inclinacao)\n\n\n\\(f(x) = \\log(x)\\) em \\(x = 2\\).\n\n\n# Função\nfx &lt;- function(x) {\n  log(x)\n}\n# Derivada da função\ndx &lt;- function(x) {\n 1/x \n}\n# Reta tangente\nreta_tangente &lt;- function(a) {\n  intercept = (fx(x = a) - dx(x = a)*a)\n  slope &lt;- dx(x = a)\n  return(c(intercept,slope))\n}\n# Gráfico da função\nx &lt;- seq(0.5, 4, l = 100) ## Sequencia definindo o eixo x\nplot(fx(x) ~ x, type = \"l\") ## Desenhando a função\n\n## Reta tangente ao ponto a = 2\nreta1 &lt;- reta_tangente(a  = 2)\nintercepto = reta1[1]\ninclinacao &lt;- reta1[2]\nlines(x, c(intercepto + inclinacao*x))\n\n\n\n\n\n\n\nresultado &lt;- c(intercepto, inclinacao)\n\n\n\n2.2.3 Regra da cadeia\nPara cada uma das funções abaixo obtenha a sua derivada, implemente uma função chamada dx() que calcula a derivada obtida no ponto \\(x = 2\\) e retorna o seu valor. Para usar a correção automática a linha final do seu código deve ser dx(x = 2).\n\n\\(f(x) = \\exp{3x}\\).\n\n\ndx &lt;- function(x) {3*exp(3*x)}\ndx(x = 2)\n\n[1] 1210.286\n\n\n\n\\(f(x) = \\sin(x^2)\\).\n\n\ndx &lt;- function(x) {2*x*cos(x^2)}\ndx(x = 2)\n\n[1] -2.614574\n\n\n\n\\(f(x) = (3x^2 + 1)^3\\).\n\n\ndx &lt;- function(x) {18*x*(3*x^2 + 1)^2}\ndx(x = 2)\n\n[1] 6084\n\n\n\n\\(f(x) = \\log(x^2 + 3)\\).\n\n\ndx &lt;- function(x) {2*x/(x^2 + 3)}\ndx(x = 2)\n\n[1] 0.5714286\n\n\n\n\\(f(x) = x^2 \\exp(3x)\\).\n\n\ndx &lt;- function(x) {3*(x^2)*exp(3*x) + 2*x*exp(3*x)}\ndx(x = 2)\n\n[1] 6454.861\n\n\n\n\\(f(x) = \\log(x^2 + 3x + 9)\\).\n\n\ndx &lt;- function(x) {(2*x + 3)/(x^2 + 3*x + 9)}\ndx(x = 2)\n\n[1] 0.3684211\n\n\n\n\\(f(x) = \\sqrt{x + \\exp(x)}\\).\n\n\ndx &lt;- function(x) {(exp(x) + 1)/(2*sqrt(exp(x) + x))}\ndx(x = 2)\n\n[1] 1.368901\n\n\n\n\n2.2.4 Aproximação por Série de Taylor\nAproxime as seguintes funções usando a expansão de Taylor de segunda ordem. Esboce o gráfico da função e da aproximação. Note que \\(y_i\\) é constante nos valores informados e que a aproximação deve ser feita em relação a \\(\\mu\\). Pode fixar como ponto de referência para a aproximação \\(\\mu_0\\) a média dos \\(y_i\\)’s. Para usar a correção automática você deve avaliar a aproximação de Taylor em cada valor de \\(y_i\\) fornecido.\n\n\\(f(\\mu; \\boldsymbol{y}) = \\sum_{i=1}^n (y_i - \\mu)^2\\). Fixe \\(y_i = 2.09;-1.32;-0.20;0.05;-0.07\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(2.09, -1.32, -0.20, 0.05, -0.07)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {sum( (y - mu)^2) }\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {-2*sum(y-mu)}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {2*length(y)}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, min(y), max(y), ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(min(y), max(y), l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 25.6994 16.3219  6.5779  6.1154  6.2594\n\n\n\n\\(f(\\mu; \\boldsymbol{y}) = \\sum_{i=1}^n 2 \\left ( y_i \\log \\frac{y_i}{\\mu} + \\mu - y_i \\right )\\). Fixe \\(y_i = 7;4;4;6;5\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(7, 4, 4, 6, 5)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {sum(2*(y*log(y/mu) + mu - y) )}\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {sum(2*(1 - y/mu))}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {sum(2*y/mu^2)}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, min(y), max(y), ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(min(y), max(y), l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 4.404081 2.673311 2.673311 1.904081 1.327158\n\n\n\n\\(f(\\mu; \\boldsymbol{y}) = \\sum_{i=1}^n 2 \\left ( \\frac{y_i}{\\mu} - \\log \\frac{y_i}{\\mu} - 1 \\right )\\). Fixe \\(y_i = 2.35;0.16;0.56;1.05;0.51\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(2.35, 0.16, 0.56, 1.05, 0.51)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {sum(2*((y/mu) - log(y/mu) -1 ))}\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {sum( 2*( (1/mu) - y/(mu^2) ))}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {sum( 2*( (2*y/mu^3) - 1/(mu^2)))}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, min(y), max(y), ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(min(y), max(y), l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 15.420365  7.017681  4.377374  3.685926  4.605369\n\n\n\n\\(f(\\mu; \\boldsymbol{y}) = \\sum_{i=1}^n 2 \\left ( y_i \\log \\frac{y_i}{\\mu} + (1- y_i) \\log \\frac{1-y_i}{1-\\mu} \\right )\\). Fixe \\(y_i = 1;0;0;1;1\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(1,0,0,1,1)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {\n  temp &lt;- c()\n  for(i in 1:length(y)) {\n    if(y[i] == 1) { temp[i] &lt;- y[i]*log(y[i]/mu) }\n    if(y[i] == 0) { temp[i] &lt;- (1-y[i])*log( (1-y[i])/(1-mu) ) }\n  }\n  return(sum(2*temp))\n}\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {sum(2*((1-y)/(1-mu) - y/mu ))}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {sum(2*( (y/mu^2) + (1-y)/(1-mu)^2))}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, 0.1, 0.9, ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(0.1, 0.9, l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 10.06345 14.23012 14.23012 10.06345 10.06345\n\n\n\n$f(; ) = _{i=1}^n 2 ( y_i + (m + y_i) ) $. Fixe \\(m = 10\\) e \\(y_i = 7;4;4;6;5\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(7,4,4,6,5)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {sum (2*( y*log(y/mu) + (10 + y)* log( (10+mu)/(10 + y) ))) }\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {sum(2*( (y+10)/(mu+10) - y/mu ))}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {sum((y/mu^2) - (y + 10)/(mu + 10)^2)}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, 1, 9, ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(1, 9, l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 1.8695894 1.3002574 1.3002574 1.0472210 0.8574436",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cálculo Diferencial e Integral para Cientista de Dados</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#integrais",
    "href": "content/Modulo02/index.html#integrais",
    "title": "2  Cálculo Diferencial e Integral para Cientista de Dados",
    "section": "2.3 Integrais",
    "text": "2.3 Integrais\nOs objetivos deste tutorial são:\n\nObtenção de integrais indefinidas simples.\nCálculo de área abaixo de curvas (integrais definidas)\nUso de funções do Rpara o cálculo de integrais.\n\n\n2.3.1 Integrais indefinidas\nCalcule cada uma das integrais abaixo e implemente uma função chamada integral() que calcula a integral obtida considerando a constante \\(c = 0\\) e retorna o seu valor. Para usar a correção automática a linha final do seu código deve ser integral(x = 2).\n\n\\(\\int x^3 dx\\).\n\n\nintegral &lt;- function(x) { (x^4)/4 }\nintegral(x = 2)\n\n[1] 4\n\n\n\n\\(\\int \\frac{1}{x^2} dx\\).\n\n\nintegral &lt;- function(x) { -1/x }\nintegral(x = 2)\n\n[1] -0.5\n\n\n\n\\(\\int \\frac{1}{x} + \\sqrt{x} dx\\).\n\n\nintegral &lt;- function(x) { log(x) + (2*x^(3/2))/3 }\nintegral(x = 2)\n\n[1] 2.578765\n\n\n\n\\(\\int \\exp^{-x} dx\\).\n\n\nintegral &lt;- function(x) { -exp(-x) }\nintegral(x = 2)\n\n[1] -0.1353353\n\n\n\n\\(\\int x + 3 \\exp^{x} dx\\).\n\n\nintegral &lt;- function(x) {3*exp(x) + (x^2)/2}\nintegral(x = 2)\n\n[1] 24.16717\n\n\n\n\n2.3.2 Integrais definidas\nObtenha as seguintes integrais definidas. Você pode obter a anti-derivada e avaliar a área ou usar a função integrate() do R. Para usar a correção automática a última linha do seu código deve ser area = valor ondelo valor é um valor (numérico).\n\n\\(\\int_{1}^2 x^2 dx\\).\n\n\nfx &lt;- function(x) {x^2}\ntemporario &lt;- integrate(f = fx, lower = 1, upper = 2)\narea &lt;- as.numeric(temporario$value)\n\n\n\\(\\int_{0}^2 (x^3 + 3x -1) dx\\).\n\n\nfx &lt;- function(x) {x^3 + 3*x - 1}\ntemporario &lt;- integrate(f = fx, lower = 0, upper = 2)\narea &lt;- as.numeric(temporario$value)\n\n\n\\(\\int_{-150}^{150} \\exp \\left\\{ -\\frac{(x - 5)^2}{2}   \\right \\} dx\\).\n\n\nfx &lt;- function(x) {exp( - ((x - 5)^2)/2 )}\ntemporario &lt;- integrate(f = fx, lower = -150, upper = 150)\narea &lt;- as.numeric(temporario$value)\n\n\n\\(\\int_{0}^{100} \\exp \\left\\{ -\\frac{|x - 5|}{2}   \\right \\} dx\\).\n\n\nfx &lt;- function(x) {exp(-abs(x - 5)/2 )}\ntemporario &lt;- integrate(f = fx, lower = 0, upper = 150)\narea &lt;- as.numeric(temporario$value)\n\n\n\\(\\int_{1}^{2}  \\left(\\frac{1}{x} + \\frac{1}{x^3}   \\right \\} dx\\).\n\n\nfx &lt;- function(x) {(1/x + 1/x^3)}\ntemporario &lt;- integrate(f = fx, lower = 1, upper = 2)\narea &lt;- as.numeric(temporario$value)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cálculo Diferencial e Integral para Cientista de Dados</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#desafios",
    "href": "content/Modulo02/index.html#desafios",
    "title": "2  Cálculo Diferencial e Integral para Cientista de Dados",
    "section": "2.4 Desafios",
    "text": "2.4 Desafios\nOs próximos dois exercícios são desafios. Não apresento nenhuma solução a ideia é vocês tentarem resolver usando quaisquer meios. Isso inclue procurar soluções na internet, discutir com os colegas, postar em grupos etc. Se você chegar em uma solução que queira compartilhar comigo pode me mandar a solução por e-mail.\n\n2.4.1 Redução de dados usando perda absoluta\n\n2.4.1.1 Sejam \\(y_i\\) valores observados para \\(i = 1, \\ldots, n\\). Considere a função perda absoluta dada por\n\\[f(\\mu; \\mathbf{y}) = \\sum_{i=1}^n |y_i - \\mu|.\\]\n\nSimule um conjunto de valores adequado para \\(y_i\\).\nEsboce o gráfico da função perda para este conjunto de dados e diferentes valores de \\(\\mu\\).\nEncontre o valor de \\(\\mu\\) que minimiza a função perda absoluta.\nDiscuta quando a função perda absoluta pode ser mais conveniente do que a função perda quadrática.\n\n\n\n\n2.4.2 Regressão linear simples usando perda absoluta\nSejam \\(y_i\\) e \\(x_i\\) valores observados para \\(i = 1, \\ldots, n\\). Considere o problema de ajustar um reta relacionando \\(y_i\\) com \\(x_i\\), usando a função perda absoluta\n\\[f(\\beta_0, \\beta_1) = \\sum_{i=1}^n |y_i - (\\beta_0 + \\beta_1 x_i)|.\\]\n\nSimule um conjunto de valores adequado para \\(y_i\\) fixado um vetor de \\(x_i\\).\nEsboce o gráfico da função perda para o conjunto de dados simulado.\nEncontre o valor de \\(\\beta_0\\) e \\(\\beta_1\\) que miniza a função perda absoluta.\nDiscuta quando a função perda absoluta pode ser mais conveniente do que a função perda quadrática para o ajuste deste modelo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cálculo Diferencial e Integral para Cientista de Dados</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html#derivadas",
    "href": "content/Modulo01/index.html#derivadas",
    "title": "1  Cálculo Diferencial e Integral",
    "section": "1.2 Derivadas",
    "text": "1.2 Derivadas\nComo discutido na seção 1.1 o conceito de função é central em diversas técnicas de ciência de dados. Consequentemente, nós precisamos de ferramentas para entender e descrever o comportamento de uma função, bem como, encontrar seus valores de máximo ou mínimo. Tais conceitos serão apresentados nesta seção. A principal ferramenta matemática que nos permitirá analisar o comportamento de uma função é a sua derivada. É interessante notar que apenas com o que foi apresentado sobre funções e o conceito de derivada apresentado nesta seção, seremos capazes de obter um dos modelos mais populares em estatística e aprendizado de máquina: o modelo de regressão linear simples.\n\n1.2.1 Definição\n\n\n\n\n\n\nDefinição 1.13\n\n\n\nDerivada ordinária, derivada primeira, ou simplesmente, derivada de uma função \\(y = f(x)\\) em um ponto \\(x = a\\) no domínio de \\(f\\) é representada por \\(\\frac{dy}{dx}\\), \\(y^{\\prime}\\), \\(\\frac{d f}{fx}\\) ou \\(f^{\\prime}(a)\\) é o valor \\[\n\\frac{dy}{dx} |_{x=a} = f^{\\prime}(a) = \\lim_{h \\to 0} \\frac{f(a + h) - f(a)}{h}.\n\\]\n\n\nA derivada de uma função nada mais é que a taxa de mudança instantânea em \\(y\\) devido a uma mudança em \\(x\\). Chamamos de derivação o processo de obter a derivada de uma função. Uma importante característica da derivada é que no limite quando \\(x \\to a\\) a derivada é a reta tangente ao ponto \\((a, f(a))\\), cuja equação é dada por \\(y - f(a) = f^{\\prime}(a)(x - a)\\).\nVamos fazer um exemplo trivial para ilustrar o conceito de derivada e o processo de derivação.\nExample 1.2 Obtenha a derivada de \\(f(x) = - x^2\\) usando a definição 1.13.\n\\[\n\\begin{align}\nf^{\\prime}(x) & =&  \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h} \\nonumber \\\\\n& =&  \\lim_{h \\to 0} \\frac{- (x + h)^2 - (- x^2)}{h} \\nonumber \\\\\n& =&  \\lim_{h \\to 0} \\frac{-(x^2 + 2xh + h^2) + x^2}{h} \\nonumber \\\\\n& =&  \\lim_{h \\to 0} \\frac{-x^2 - 2xh - h^2 + x^2}{h} = \\frac{-2xh - h^2}{h} \\nonumber \\\\\n& =&  \\lim_{h \\to 0} -2x - h = -2x \\nonumber \\\\\nf^{\\prime}(x) & =&  -2x.\n\\end{align}\n\\]\nApesar da definição 1.13 ser precisa, ela é de pouco uso prático para obter a derivada de uma função qualquer e geralmente leva a um trabalho tedioso. No entanto, o processo de derivação foi sendo aperfeiçoado ao longo do desenvolvimento da disciplina de Cálculo Diferencial e Integral, e atualmente conta-se com uma infinidade de regras de derivação. Uma busca rápida na internet com o termo “tabela de derivadas” vai resultar em inúmeras tabelas resumindo as mais úteis regras de derivação. Importante deixar claro que todas essas regras de derivação são obtidas usando a definição 1.13.\nAlém disso, dispomos de diversos softwares de matemática simbólica que nos auxiliam no processo de derivação de uma função qualquer de interesse. Neste livro, serão apresentadas algumas poucas regras básicas de derivação e ilustrações como obter derivadas simbolicamente utilizando o software R.\n\n\n1.2.2 Regras de derivação\nPara explicar as regras de derivação vamos usar funções auxiliares ou não especificadas \\(f(x)\\) e \\(g(x)\\) e \\(n \\neq 0\\) um natural qualquer. São válidas as seguintes regras de derivação:\n\nSe \\(f(x) = c\\) então \\(f^{\\prime}(x) = 0\\).\nSe \\(f(x) = x^n\\) então \\(f^{\\prime}(x) = n x^{n-1}\\).\nSe \\(f(x) = x^{-n}\\) então \\(f^{\\prime}(x) = -n x^{-n-1}\\).\nSe \\(f(x) = x^{1/n}\\) então \\(f^{\\prime}(x) = \\frac{1}{n} x^{\\frac{1}{n} - 1}\\).\n\nTambém podemos obter a derivada de algumas funções especiais.\n\nSe \\(f(x) = \\exp(x)\\) então \\(f^{\\prime}(x) = \\exp(x)\\).\nSe \\(f(x) = \\ln(x)\\) então \\(f^{\\prime}(x) = \\frac{1}{x}, x &gt; 0\\).\n\nSendo, \\(f(x)\\) e \\(g(x)\\) deriváveis em \\(x\\) e \\(c\\) uma constante. Então, as funções \\(f(x) + g(x)\\), \\(c f(x)\\), \\(f(x) \\times g(x)\\) e \\(\\frac{f(x)}{g(x)}\\) são deriváveis em \\(x\\) e têm-se\n\n\\((f + g)^{\\prime} = f^{\\prime}(x) + g^{\\prime}(x)\\).\n\\((c f)^{\\prime}(x) = c f^{\\prime}(x)\\).\n\\((f \\times g)^{\\prime}(x) = f^{\\prime}(x) g(x) + f(x) g^{\\prime}(x)\\).\n\\((\\frac{f}{g})^{\\prime}(x) = \\frac{f^{\\prime}(x) g(x) - f(x) g^{\\prime}(x)}{[g(x)]^2}.\\)\n\nVamos fazer alguns exemplos ilustrativos.\nExample 1.3 Obtenha a derivada de \\(f(x) = 2 + 3x\\).\nPara obter essa derivada precisamos da derivada de uma constante, neste caso o \\(2\\) que usando a regra 1 é \\(0\\), e da derivada de \\(3x\\). Note que o número \\(3\\) está multiplicando a variável \\(x\\). Assim, pela regra 8 devemos apenas manter a constante e multiplicarmos pela derivada de \\(x\\) que pela regra 2 é \\(x^0\\). Como todo número elevado a zero é \\(1\\), temos que \\(f^{\\prime}(x) = 3.\\) Podemos facilmente obter o mesmo resultado usando a função D() do software R.\n\nD(expression(2 + 3*x), name = \"x\")\n\n[1] 3\n\n\nPara usar a função D() devemos passar explicitamente uma expressão usando a função expression() e indicar em qual variável queremos derivar, no caso x. Vamos fazer mais um exemplo, um pouco mais elaborado.\nExample 1.4 Obtenha a derivada de \\(f(x) = \\frac{5x^3}{4x+3}.\\)\n\nD(expression( (5*x^3)/(4*x + 3) ), name = \"x\")\n\n5 * (3 * x^2)/(4 * x + 3) - (5 * x^3) * 4/(4 * x + 3)^2\n\n\nPrimeiro vamos chamar de \\(f(x) = 5 x^3\\) e \\(g(x) = 4x + 3\\). Agora podemos derivar cada uma destas funções em relação a \\(x\\), ou seja, \\(f^{\\prime}(x) = 3 \\times 5 \\times x^{3-1} = 15 x^2.\\) De forma, similar temos \\(g^{\\prime}(x) = 4.\\) Agora usando a regra 10, temos \\((\\frac{f}{g})^{\\prime}(x) = \\frac{(15x^2)(4x+3) - (5x^3) (4) }{(4x + 3)^2} = \\frac{15x^2}{(4x+3)} - \\frac{20x^3}{(4x + 3)}.\\)\nInteressante notar que os números da expressão resultante da chamada da função D() são também tratados como símbolos, e portanto o R não faz as multiplicações usuais, por exemplo, no numerador o valor \\(5\\) não foi multiplicado pelo \\(3\\) para resultar em \\(15x^2\\), como fizemos manualmente.\nEm diversas situações podemos ter o desafio de calcular a derivada de uma função composta por outra função. Para ilustrar essa ideia, suponha que em um algoritmo computacional, \\(C\\) seja o custo total de realizar \\(s\\) tarefas, então \\(C = f(s).\\) Além disso, suponha que \\(s\\) tarefas sejam realizadas durante os \\(t\\) segundos desde o início da execução do algoritmo, então \\(s = g(t)\\). Se conhecermos a derivada de \\(s\\) em relação a \\(t\\), ou seja, a taxa de variação do número de tarefas realizadas em \\(t\\) segundos, também podemos determinar a derivada de \\(C\\) em relação a \\(t\\), que representa a taxa de variação do custo total do algoritmo em um determinado intervalo de tempo. Note que \\(C\\) é implicitamente determinado por \\(t\\) através de \\(g(t)\\). Para calcular a derivada de \\(C\\) em relação a \\(t\\), usamos uma regra importante chamada de regra da cadeia.\nSejam \\(y = f(x)\\) e \\(x = g(t)\\) duas funções deriváveis, com \\(I \\in D\\). A função composta \\(h(t) = f(g(t))\\) é derivável, sendo\n\\[h^{\\prime}(t) = f^{\\prime}(g(t))g^{\\prime}(t), t \\in D_g.\\]\nExample 1.5 Suponha que para um certo algoritmo computacional \\(C\\) seja o custo (em unidades de processamento) total de realizar \\(s\\) tarefas e que \\(C\\) é determinado por \\(s\\) pela seguinte equação\n\\[C = \\frac{1}{4} s^2 + 2s + 1000.\\]\nAlém disso, se \\(s\\) tarefas são realizadas durante \\(t\\) segundos desde o início da execução, então\n\\[s = 3 t^2 + 50 t.\\]\nDetermine a taxa de variação do custo total de execução do algoritmo em relação ao tempo, \\(2\\) segundos após o início da execução. :::\nPara este exemplo é interessante usarmos uma outra notação de derivada, que deixa explicito quem está sendo derivado em relação a quem. Desejamos, encontrar a derivada de \\(C\\) em relação a \\(t\\), que vamos denotar por \\(\\frac{d C}{d t}\\) quando \\(t = 2\\). Usando a regra da cadeia, tem-se\n\\[\\begin{equation}\n  \\frac{d C}{ dt} = \\frac{d C}{d s} \\times \\frac{d s}{dt}.\n  \\tag{1.1}\n\\end{equation}\n\\] Usando as regras de derivação já apresentadas, tem-se\n\\[\\begin{equation}\n  \\frac{d C}{d s} = \\frac{1}{2}s + 2.\n  \\tag{1.2}\n\\end{equation}\\] De forma similar,\n\\[\\begin{equation}\n  \\frac{d s}{d t} = 6t + 50.\n  \\tag{1.3}\n\\end{equation}\\]\nCombinando as equações (1.2) e (1.3) com (1.1), temos\n\\[\\begin{equation}\n  \\frac{d C}{ dt} = \\left( \\frac{1}{2}s + 2 \\right)(6t + 50).\n  \\tag{1.4}\n\\end{equation}\\]\nPara avaliar no ponto \\(t = 2\\), lembre-se que\n\\[s = 3 t^2 + 50t \\to s = 3\\ctimes(2^2) + 50 \\times 2 = 112.\\]\nSubstituindo, na expressão (1.4), tem-se\n\\[ \\frac{d C}{ dt}|_{t=2} = \\left( \\frac{1}{2}s + 2 \\right)(6t + 50) =  \\left(\\frac{1}{2}(112) + 2\\right)(6\\times 2 + 50) = (58)\\ctimes( 62) = 3596.\\]\nAssim podemos dizer que \\(2\\) segundos após o início da execução do algoritmo o custo computacional está aumentando a uma taxa de \\(3596\\) unidades de processamento.\n\n\n1.2.3 Derivadas de ordem superior\nDada uma função \\(f(x)\\) a derivada \\(f^{\\prime}(x)\\) é também chamada de derivada de primeira ordem e mede a variação da função original ou primitiva. A derivada de segunda ordem denotada por \\(f^{\\prime \\prime}(x)\\) mede a taxa de variação da primeira derivada. De forma análoga, a derivada de terceira ordem \\(f^{\\prime \\prime \\prime}(x)\\) mede a taxa de variação da segunda derivada e assim por diante até a \\(n-\\)ésima derivada. As derivadas de ordem superior são obtidas pela aplicação das regras de diferenciação na derivada de ordem imediatamente inferior. Em termos de notação é comum encontrar \\(\\frac{d^n y}{d x^n}\\) que é interpretada como a \\(n-\\)ésima derivada de \\(y\\) em relação a \\(x\\).\nExample 1.6 Obtenha a derivada de ordem até \\(5\\) da função \\(y = 2x^4 + 5 x^3 + 2 x^2\\).\nUsando as regras de derivação 2 e 7, temos\n\\(\\frac{d y}{d x} = 8 x^3 + 15 x^2 + 4 x\\), \\(\\frac{d^2 y}{d x^2} = 24x^2 + 30x + 4\\), \\(\\frac{d^3 y}{d x^3} = 48 x + 30\\), \\(\\frac{d^4 y}{d x^4} = 48\\) e \\(\\frac{d^5 y}{d x^5} = 0\\).\nNeste caso, todas as derivadas de ordem superior a \\(4\\) são zero.\n\n\n1.2.4 Importância da derivada\nUma das principais aplicações de derivadas é encontrar pontos de máximo/mínimo de uma função. Para entender o que isso significa e porquê é importante encontrar tais pontos precisamos de mais algumas definições.\n\n\n\n\n\n\nDefinição 1.14\n\n\n\nDizemos que um ponto \\(c\\) é um valor máximo relativo de \\(f(x)\\) se existir um intervalo aberto contendo \\(c\\), no qual \\(f(x)\\) esteja definida, tal que \\(f(c) \\geq f(x)\\) para todo \\(x\\) neste intervalo.\n\n\n\n\n\n\n\n\nDefinição 1.15\n\n\n\nDizemos que um ponto \\(c\\) é um valor mínimo relativo de \\(f(x)\\) se existir um intervalo aberto contendo \\(c\\), no qual \\(f(x)\\) esteja definida, tal que \\(f(c) \\leq f(x)\\) para todo \\(x\\) neste intervalo.\n\n\nFigura 1.14 ilustra um esboço de uma parte do gráfico de duas funções tendo um máximo/mínimo relativo em \\(c = 0\\) dentro do intervalo \\((a = -3, b = 3)\\).\n\n\n\n\n\n\n\n\nFigure 1.11: Ilustração de máximo/mínimo relativos.\n\n\n\n\n\nAs Figuras 1.14 (A) e 1.14 (C) ilustram funções com o mínimo relativo em \\(c = 0\\), enquanto que as Figuras 1.14 (B) e 1.14 (D) ilustram funções com o máximo relativo em \\(c = 0\\). Importante notar que multiplicando a função por \\(-1\\) invertemos a sua concavidade, tornando um ponto de mínimo em máximo e vice-versa.\nDe forma geral, quando treinamos ou estimamos algum tipo de modelo, o que realmente estamos fazendo é procurando valores de máximo/mínimo de uma determinada função. Esta ideia ficará mais clara no decorrer desta seção. Neste momento, atenha-se ao fato de que encontrar pontos de máximo ou mínimo de uma função é uma tarefa importante para construir grande parte das técnicas de ciência de dados, e portanto precisamos de uma forma sistemática para realizar esta tarefa.\nConforme mencionado anteriormente, no limite quando \\(x \\to a\\) a derivada é a reta tangente ao ponto \\((a, f(a))\\), cuja equação é dada por \\(y - f(a) = f^{\\prime}(a)(x - a)\\). Este resultado nos permite usar a derivada para encontrar o ponto de máximo ou mínimo relativo de uma função. Para entender o que é a reta tangente a \\(f(x)\\) e como ela nos ajuda a encontrar o ponto de máximo ou mínimo vamos ver um exemplo trivial.\nExample 1.7 Obtenha a derivada de \\(f(x) = - x^2\\) e trace a reta tangente aos pontos \\(a = -2\\) e \\(a = 2\\).\n\\[\\begin{align}\nf^{\\prime}(x) & =&  \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h} \\nonumber \\\\\n& =&  \\lim_{h \\to 0} \\frac{- (x + h)^2 - (- x^2)}{h} \\nonumber \\\\\n& =&  \\lim_{h \\to 0} \\frac{-(x^2 + 2xh + h^2)}{h} \\nonumber \\\\\n& =&  \\lim_{h \\to 0} \\frac{-x^2 - 2xh - h^2  + x^2}{h} = \\frac{-2xh - h^2}{h} \\nonumber \\\\\n& =&  \\lim_{h \\to 0} -2x - h = -2x \\nonumber\nf^{\\prime}(x) & =&  -2x.\n\\end{align}\\]\nNote que no Exemplo 1.2 foram utilizadas diretamente as definições de derivada e limite. Com este resultado e sabendo que a reta tangente a \\(f(x)\\) tem equação dado por \\(y - f(a) = f^{\\prime}(a)(x - a)\\). Nós podemos traçar o gráfico de \\(f(x)\\) e da reta tangente nos pontos \\(a=-2\\) e \\(a=2\\), conforme apresentado na Figura 1.15.\n\n\n\n\n\n\n\n\nFigure 1.12: Ilustração de uma função com a reta tangente a pontos distintos.\n\n\n\n\n\nVamos ver passo-a-passo como chegamos às equações e códigos necessários para desenhar a Figura 1.15.\n\nImplementar a função \\(f(x) = -x^2\\).\n\n\nfx &lt;- function(x) {\n  y &lt;- -x^2\n  return(y)\n}\n\n\nImplementar a derivada de \\(f(x)\\), ou seja, \\(f^{\\prime}(x) = -2x\\).\n\n\nf_prime &lt;- function(x) {\n  y_prime &lt;- -2*x\n  return(y_prime)\n}\n\n\nObter a equação da reta tangente.\n\nNote que não foi demonstrado, mas a equação da reta tangente é dada por \\(y - f(a) = f^{\\prime}(a)(x - a)\\). Substituindo os termos, temos\n\\[\\begin{align}\ny & =&  f(a) + f^{\\prime}(a)(x - a) \\nonumber \\\\\ny & =&  f(a) + f^{\\prime}(a)x - f^{\\prime}(a)a \\nonumber \\\\\ny & =&  [f(a) - f^{\\prime}(a)a] + f^{\\prime}(a)x \\nonumber \\\\\ny & =&  [-(a^2) - (-2a^2)] + (-2ax ) \\nonumber \\\\\ny & =&  a^2 - 2ax.\n\\end{align}\\]\n\nImplementar uma função que retorne o intercepto e a inclinação da reta tangente em um determinado ponto.\n\n\nreta_tangente &lt;- function(a) {\n  intercept = (fx(x = a) - f_prime(x = a)*a)\n  slope &lt;- f_prime(x = a)\n  return(c(intercept,slope))\n}\n\nPor exemplo, no ponto \\(a = 2\\), temos\n\nreta_tangente(a = 2)\n\n[1]  4 -4\n\n\nNeste caso, temos que o intercepto é \\(4\\) e a inclinação é \\(-4\\).\n\nDesenhar o gráfico da função com a reta tangente nos pontos \\(a=-2\\) e \\(a=2\\).\n\n\npar(mar=c(2.6, 2.8, 1.2, 0.5), mgp = c(1.6, 0.6, 0)) ## Define a janela gráfica\nx &lt;- seq(-5, 5, l = 11) ## Sequencia definindo o eixo x\nplot(fx(x) ~ x, type = \"l\", ylim = c(-25, 4)) ## Desenhando a função\n## Reta tangente ao ponto a = 2\nreta1 &lt;- reta_tangente(2)\nintercept1 = reta1[1]\nslope1 &lt;- reta1[2]\ndev_values &lt;- seq(0.5, 5, l = 100)\nlines(dev_values, c(intercept1 + slope1*dev_values))\n\n## Reta tangente ao ponto a = -2\nreta2 &lt;- reta_tangente(-2)\nintercept2 = reta2[1]\nslope2 &lt;- reta2[2]\ndev_values &lt;- seq(-5, -0.5, l = 100)\nlines(dev_values, c(intercept2 + slope2*dev_values))\n\n## Pontos\npoints(-2, -4)\npoints(2, -4)\n\n\n\n\n\n\n\nFigure 1.13: Ilustração de uma função com a reta tangente em pontos distintos.\n\n\n\n\n\nNote que conforme passamos do ponto \\(a1 = 2\\) para \\(a2 = 1\\) a inclinação da reta tangente a \\(f(x)\\) diminuiu e quando chegamos no ponto \\(a3 = 0\\) a inclinação da reta tangente é exatamente zero, indicando que chegamos a um ponto extremo. No entanto, é importante notar que baseado apenas na derivada não sabemos se o ponto encontrado é de máximo ou mínimo relativo. O seguinte Teorema, formaliza a situação até o momento.\n\n\n\n\n\n\nTeorema 1.1\n\n\n\nSe \\(f(x)\\) existe para todos os valores de \\(x\\) no intervalo aberto \\((a,b)\\), e se \\(f(x)\\) tem um extremo relativo em \\(c\\), em que \\(a &lt; c &lt; b\\), então \\(f^{\\prime}(c)\\) existe e \\(f^{\\prime}(c) = 0\\).\n\n\nUm aspecto importante do Teorema 1.1 é que sendo \\(f(x)\\) diferenciável, os pontos extremos de \\(f(x)\\) vão ocorrer quando \\(f^{\\prime}(x) = 0\\). Por outro lado, \\(f^{\\prime}(x)\\) pode ser igual a zero mesmo não sendo um extremo relativo, conforme ilustrado na Figura 1.17.\n\n\n\n\n\n\n\n\nFigure 1.14: Ilustração de uma função onde derivada zero não é ponto extremo.\n\n\n\n\n\nNote que a derivada de \\(f(x)\\) no ponto \\(x = 1\\) é zero, no entanto \\(f(x)\\) não tem um extremo relativo em \\(1\\). Assim, concluímos que apesar da derivada ajudar a encontrar os pontos extremos, apenas \\(f^{\\prime}(x) = 0\\) não é suficiente para concluirmos que a função tem um ponto extremo, seja ele de máximo ou de mínimo.\nPara definir se o ponto extremo encontrado em \\(f^{\\prime}(c) = 0\\) é um ponto de máximo ou mínimo, precisamos lembrar que a derivada mede a taxa de variação instantânea da função no ponto avaliado. Neste sentido, a segunda derivada mede a taxa de variação da derivada primeira. Se a derivada primeira é zero, ou seja, a reta tangente a \\(f(x)\\) está paralela ao eixo \\(x\\), temos um platô na função. O que precisamos saber é se o gráfico de \\(f(x)\\) está abaixo ou acima do ponto extremo, para então concluir se é um ponto de máximo ou mínimo relativo. Note que se a segunda derivada é negativa, significa que a função se move abaixo do platô, e portanto temos um máximo relativo, conforme ilustrado na Figura 1.14 (C). Por outro lado, se a segunda derivada é positiva, significa que a função se move acima do platô, e portanto temos um ponto de mínimo relativo, conforme ilustrado na Figura 1.14 (A). Apenas um adendo na terminologia, um ponto extremo também é chamado de ponto crítico, ou ponto estacionário dependendo da bibliografia consultada.\nPor fim, temos um procedimento simples para encontrar um ponto crítico e decidir se é um ponto de máximo ou mínimo relativo, vamos enunciar na forma de um Teorema.\n\n\n\n\n\n\nTeorema 1.2\n\n\n\nSeja \\(c\\) um ponto extremo de uma função \\(f(x)\\) no qual \\(f^{\\prime}(c) = 0\\), e suponha que \\(f^{\\prime}(x)\\) exista para todos os valores de \\(x\\) em um intervalo aberto contendo \\(c\\). Se \\(f^{\\prime \\prime}(c)\\) existe, então\n\nSe \\(f^{\\prime \\prime}(c) &lt; 0\\), então \\(f(x)\\) tem um máximo relativo em \\(c\\).\nSe \\(f^{\\prime \\prime}(c) &gt; 0\\), então \\(f(x)\\) tem um mínimo relativo em \\(c\\).\n\n\n\nInteressante notar que o Teorema 1.2 não diz nada sobre o caso em \\(f^{\\prime \\prime}(c) = 0\\). Neste caso temos um ponto de inflexão, conforme ilustrado na Figura 1.17. Importante notar que em toda a nossa discussão sobre máximo e mínimo, estamos sempre limitando a nossa atenção a um certo intervalo que contém o valor crítico \\(c\\), por isso particularizamos dizendo máximo/mínimo relativo ao intervalo considerado. No entanto é importante deixar claro que uma função qualquer pode ter vários máximos/mínimos relativos.\nPor fim, um outro aspecto interessante da segunda derivada é que ela nos indica a concavidade do gráfico da função no ponto crítico. Assim, se \\(f^{\\prime \\prime}(c) &gt; 0\\) o gráfico de \\(f(x)\\) é côncavo para cima em \\((c, f(c))\\); se \\(f^{\\prime \\prime}(c) &lt; 0\\) o gráfico de \\(f(x)\\) é côncavo para baixo em \\((c, f(c))\\). Veja por exemplo os gráficos apresentados na Figura 1.14 (A) (côncavo para cima) e 1.14 (B) (côncavo para baixo).\n\n\n1.2.5 Redução de dados\nCom o que aprendemos até este ponto podemos começar a entender a razão pela qual medidas como a média e a mediana são frequentes em praticamente toda e qualquer análise de dados. Se você trabalha com dados, com certeza já se deparou com a tarefa de resumir uma grande quantidade de observações ou registros de uma variável de interesse em apenas uma medida resumo. Muito provavelmente você usou a média, ou a mediana ou ambas. Este processo de resumir os dados observados por meio de alguma medida resumo é o que chamamos de processo de redução de dados.\nAgora, vamos pensar em \\(3\\) questionamentos:\n\nPor qual razão usamos a média ou a mediana como uma medida resumo?\nSerá que existe algum procedimento mais geral que leva à obtenção destas medidas resumo?\nSe sim, como este procedimento está relacionado com o que vimos em relação a funções e seu comportamento?\n\nNo decorrer desta subseção vamos responder a estas perguntas e mostrar como medidas resumo como a média e a mediana surgem naturalmente do processo de minimização de uma função objetivo que busca minizar a informação perdida ao representá-la por meio de apenas um número.\nComo exemplo motivador para esta subseção, considere que o interesse é entender o número de dias que um certo produto leva para ser entregue ao cliente. Neste caso é usual o cientista de dados ter disponível uma base de dados transacional, ou seja, as transações financeiras da empresa onde constam todos os produtos vendidos com a data da venda e possivelmente a data da entrega. Com base nestas informações podemos facilmente calcular o número de dias até a entrega do produto. Como a empresa realiza diversas vendas deste mesmo produto temos um conjunto de observações da variável de interesse e queremos entender qual é o seu comportamento. Por simplicidade, vamos supor que temos apenas as cinco observações apresentadas abaixo.\n\n## [1]  8  9 14 10 10\n\nNeste exemplo, para a primeira venda, o produto demorou 8 dias para ser entregue. Na segunda venda, 9 dias foram necessários e assim por diante. Até que a quinta venda demorou 10 dias. Note que, neste simples exemplo, você não teria nenhum problema em apresentar os cinco valores. Obviamente que no mundo real você terá uma quantidade muito maior de registros e apresentá-los diretamente não é uma opção viável. Para isto precisamos de medidas resumo. O objetivo é de certa forma reduzir a quantidade de valores a serem apresentados. Porém, gostaríamos que os valores apresentados representassem da melhor forma possível todos os registros da variável de interesse.\nNote que temos um certo dilema: apresentar todos os valores seria o ideal porque é toda a informação que temos sobre o que queremos analisar. Por outro lado, olhar para uma planilha com centenas de milhares de números não traz nenhuma informação relevante para entender a variável de interesse. Assim, precisamos pensar como criar formas de reduzir a quantidade de informação a ser analisada e ao mesmo tempo garantir que a medida utilizada represente a informação disponível da melhor forma possível.\nAssim, podemos definir como objetivo resumir o conjunto de observações por meio de apenas um número que chamaremos de \\(\\mu\\). Note que estamos simplificando a realidade, ou seja, temos um modelo extremamente simples que diz que a realidade pode ser resumida por apenas um número. Chamaremos o conjunto de observações da variável de interesse de \\(y_i\\) para \\(i = 1, \\ldots, n\\); em nosso exemplo: \\(n = 5\\). Nosso objetivo é simples, queremos encontrar um valor para \\(\\mu\\) tal que seu valor represente da melhor forma possível os cinco valores observados. Note que precisamos definir o que significa “da melhor forma possível.”\nUm aspecto importante a ser notado é que, independente do valor de \\(\\mu\\), sempre iremos perder informação, uma vez que estamos trocando cinco valores por apenas um. Porém, tal perda deve ser compensada pela facilidade de interpretação. A ideia é usar uma função para medir o quanto estamos perdendo de informação. Isso nos leva ao conceito de função perda. Como o próprio nome sugere, uma função perda deve medir o quanto vamos perder de informação ao representar \\(y_i\\) apenas por meio de \\(\\mu\\). Existem diversas funções perda propostas na literatura, porém a mais popular é a função perda quadrática.\nNa função de perda quadrática a quantidade de informação perdida ao representar \\(y_i\\) por \\(\\mu\\) é dada pela soma das diferenças entre \\(y_i\\) e \\(\\mu\\) ao quadrado, ou seja,\n\\[\\begin{equation}\n  SQ(\\mu) = \\sum_{i=1}^n (y_i - \\mu)^2.\n  \\tag{1.5}\n\\end{equation}\\]\nNote que os \\(y_i\\) são números observados, portanto a única quantidade desconhecida em (1.5) é o valor de \\(\\mu\\). Neste ponto já temos todo o ferramental de cálculo necessário para encontrar o valor de \\(\\mu\\) que minimiza a função perda quadrática. Mas antes de resolver este problema de minimização, vamos fazer uma representação gráfica do que significa este processo.\nVamos começar implementando a função perda quadrática.\nCódigo 1.3 Função perda quadrática.\n\nSQ_mu &lt;- function(mu, y) {\n  out &lt;- sum((y - mu)^2)\n  return(out)\n}\n\nVeja que, na função 1.3, o argumento mu é apenas um número, ao passo que y é um vetor. Podemos avaliar a função em algum ponto de interesse, por exemplo \\(\\mu = 10\\).\n\ny &lt;- c(8,9,14,10,10)\nSQ_mu(mu = 10, y = y)\n\n[1] 21\n\n\nSe usarmos \\(\\mu = 10\\) estamos perdendo \\(21\\) unidades de informação na escala da função de perda quadrática. Este número por si não tem nenhum significado prático, porém ele serve para comparar dois candidados a valor de \\(\\mu\\). Por exemplo, quanto perdemos se usarmos \\(\\mu = 20\\)?\n\nSQ_mu(mu = 20, y = y)\n\n[1] 501\n\n\nA perda neste caso é muito maior do que no caso em que \\(\\mu = 10\\). Para ilustrar essa situação vamos desenhar o gráfico da função em (1.5). Para isso, primeiro precisamos ser capazes de avaliar a função 1.3 para diversos valores do argumento mu, para o mesmo vetor de y. Em R a função Vectorize() nos permite fazer tal operação de forma simples.\n\nSQ_mu &lt;- Vectorize(SQ_mu, \"mu\")\nSQ_mu(mu = c(10, 20), y = y)\n\n[1]  21 501\n\n\nA Figura 1.18 (A) apresenta um diagrama de dispersão dos valores de \\(y_i\\), onde no eixo \\(x\\) é apresentado a ordem ou rótulo das observações e no \\(y\\) o número de dias até a entrega do produto. Além de algumas retas indicando candidatos para valores de \\(\\mu\\). Na Figura 1.18 (B) é apresentado o gráfico da função (1.5) com alguns pontos mostrando o valor da perda para os candidatos a valores de \\(\\mu\\) considerados na Figura 1.18 (A).\n\n\n\n\n\n\n\n\nFigure 1.15: Diagrama de dispersão e função perda quadrática para os dados do exemplo sobre o tempo de entrega de produtos.\n\n\n\n\n\nBaseado no gráfico apresentado na Figura 1.18 (B) fica claro que o melhor valor de \\(\\mu\\), ou seja, aquele que implica na menor perda quadrática, é o ponto de mínimo da função (1.5). Podemos agora usar o que já discutimos sobre funções para encontrar este valor. O procedimento é simples, basta encontrar a primeira derivada da Equação (1.5) e seu ponto crítico. Pelo gráfico já sabemos que é um ponto de mínimo, mas podemos confirmar avaliando o sinal da segunda derivada.\nUm resumo deste processo é apresentado na Figura 1.19.\n\n\n\n\n\n\n\n\nFigure 1.16: Resumo do processo de minimização da função perda quadrática.\n\n\n\n\n\nA Figura 1.19 (A) reforça que no ponto crítico, denotado aqui por \\(\\hat{\\mu}\\) a derivada da soma de quadrados deve ser zero, ou seja, \\(SQ^{\\prime}(\\hat{\\mu}) = 0\\), conforme ilustrado na Figura 1.19 (B). A obtenção de \\(SQ^{\\prime}(\\mu)\\) é facilmente realizada usando a regra da cadeia,\n\\[\n\\begin{eqnarray*}\nSQ^{\\prime}(\\mu) & =&  2 \\sum_{i=1}^n (y_i - \\mu) \\frac{d}{d \\mu}(y_i - \\mu) \\\\\n                 & =&  2 \\sum_{i=1}^n (y_i - \\mu)(-1) = -2 \\sum_{i=1}^n (y_i - \\mu).\n\\end{eqnarray*}\n\\]\nO próximo passo é encontrar o ponto \\(\\hat{\\mu}\\) tal que \\(SQ^{\\prime}(\\mu) = 0\\). Assim,\n\\[\n\\begin{eqnarray*}\nSQ^{\\prime}(\\hat{\\mu}) & =&  0 \\\\\n-2 \\sum_{i=1}^n (y_i - \\hat{\\mu}) & =&  0 \\\\\n-\\sum_{i=1}^n y_i + n \\hat{\\mu} & =&  0 \\\\\nn \\hat{\\mu} & =&  \\sum_{i=1}^n y_i \\\\\n\\hat{\\mu} & =&  \\frac{\\sum_{i=1}^n y_i}{n}. \\\\\n\\end{eqnarray*}\n\\]\nPara concluir se realmente encontramos um ponto de mínimo podemos obter a segunda derivada e avaliar o seu sinal. Neste caso, temos \\(SQ^{\\prime \\prime}(\\mu) = 2n &gt; 0\\) e portanto temos um ponto de mínimo relativo. Desta forma, mostramos que o ponto \\(\\hat{\\mu}\\) que minimiza a função perda quadrática é justamente a média das observações. Esta é apenas uma das justificativas do uso da média como uma medida resumo. Voltemos agora às peguntas do começo desta subseção:\n\nPor qual razão usamos a média ou a mediana como uma medida resumo?\n\nUma possível justificativa é que a média minimiza a função perda quadrática, e portanto, neste sentido, ela é uma medida ótima para resumir a informação contida em um conjunto de observações. Porém, ela não é a única. Como sugestão para o leitor (e também como exercício) sugerimos verificar o que aconteceria caso a função perda absoluta fosse utilizada ao invés da perda quadrática. A função perda absoluta é dada por,\n\\[\n\\begin{equation}\n  SQ(\\mu) = \\sum_{i=1}^n |y_i - \\mu|.\n  \\tag{1.6}\n\\end{equation}\n\\]\nNeste caso a medida resumo é dada pela mediana das observações.\n\nSerá que existe algum procedimento mais geral que leva à obtenção destas medidas resumo?\n\nNós descrevemos todo o procedimento em termos da construção e obtenção da medida resumo. Veremos ao longo deste livro que praticamente todos os modelos populares em ciências de dados seguem o mesmo procedimento utilizado para encontrar a média como uma medida resumo ótima. O procedimento consiste em:\nI. Especificar um modelo, ou seja, uma descrição simplificada da realidade. No exemplo, nós usamos o modelo mais simples possível que admite que as observações podem ser resumidas por meio de apenas um número ou parâmetro. Porém, em termos mais gerais o modelo vai depender de muitos parâmetros.\n\nEspecificar uma função perda. Em nosso exemplo usamos a função perda quadrática, porém como já mencionado outras opções estão disponíveis na literatura e veremos mais sobre isso no decorrer do livro. A função perda nada mais é que uma forma de medir a distância entre o modelo proposto e os dados observados.\nTreinar o modelo ou estimar o valor dos parâmetros do modelo. Este passo consiste em minimizar alguma noção de distância entre os dados observados, ou seja, \\(y_i\\) e o modelo proposto. Para isso, alteramos o valor dos parâmetros do modelo para torná-lo o mais próximo possível dos dados. A distância é medida por meio da função perda.\n\n\nSe sim, como este procedimento está relacionado com o que vimos em relação a funções e seu comportamento?\n\nBasicamente, todo o processo de especificação e treinamento de um modelo consiste no uso de funções matemáticas para representação da realidade de forma simplificada. Por isso é importante entender o conceito de função e seu comportamento. Além disso, para o treinamento, também definimos uma função e estudamos o seu comportamento usando a sua derivada como principal ferramenta para encontrar o seu ponto de mínimo. Neste sentido, a obtenção de uma medida resumo como a média e de vários outros modelos em ciência de dados é uma simples aplicação de funções matemáticas. Uma função é usada para descrever o modelo, outra função para medir o quanto o modelo está longe dos dados (função perda). Por fim, usamos a derivada da função perda para minimizar a função perda e assim encontrar uma medida resumo ótima.\n\n\n1.2.6 Derivadas parciais\nVimos na subseção 1.1.1 que uma função pode ter mais do que uma variável independente, ou seja, \\(y\\) pode por exemplo ser uma função de \\(x1\\) e \\(x2\\): \\(y = f(x_1, x_2)\\). Nesta subseção, vamos discutir como derivar tais funções. O objetivo é medir o efeito da variação de uma particular variável independente sobre a variável dependente. A derivada parcial mede a taxa de variação instantânea da variável dependente \\((y)\\) com relação a variável independente \\(x_1\\), quando a outra variável independente \\(x_2\\) é mantida constante. A ideia se estende naturalmente para funções com mais de duas variáveis independentes. A diferenciação parcial segue as mesmas regras da diferenciação ordinária, mas trata as outras variáveis independentes como constantes.\nEm termos simples, a derivada parcial em relação a \\(x_1\\) é obtida derivando \\(f(x_1, x_2)\\) “fingindo” que \\(x_2\\) é uma constante. Da mesma forma, a derivada parcial de \\(f(x_1, x_2)\\) em relação a \\(x_2\\) é obtida derivando \\(f(x_1, x_2)\\) mantendo \\(x_1\\) constante. Em termos de notação vamos denotar a derivada parcial de \\(f(x_1, x_2)\\) em relação a \\(x_1\\), por \\(\\frac{\\partial f(x_1, x_2)}{\\partial x_1}\\). De forma análoga, vamos denotar a derivada parcial de \\(f(x_1, x_2)\\) em relação a \\(x_2\\) por \\(\\frac{\\partial f(x_1, x_2)}{\\partial x_2}\\).\nExample 1.8 Obtenha as derivadas parciais em relação a \\(x_1\\) e \\(x_2\\) de \\(y = 5 x_1^3 + 3 x_1 x_2 + 4 x_2^2\\).\nVamos diferenciar primeiro em \\(x_1\\), isso significa que \\(x_2\\) deve ser considerado uma constante.\n\\[\\frac{\\partial y}{\\partial x_1} = 15 x_1^2 + 3 x_2.\\]\nDiferenciando agora em \\(x_2\\) consideramos \\(x_1\\) como constante.\n\\[\\frac{\\partial y}{\\partial x_2} = 3x_1 + 8 x_2.\\]\nDerivadas de ordem superior também podem ser estendidas para o caso de funções com múltiplas variáveis independentes. Neste caso, as operações começam a ficar mais complicadas e a notação também. A derivada parcial de segunda ordem denotada por \\(\\frac{\\partial^2 f(x_1,x_2)}{\\partial x_1^2}\\) indica que a função foi diferenciada parcialmente em relação a \\(x_1\\) duas vezes, novamente mantendo todas as outras variáveis independentes constantes.\nA derivada parcial de primeira ordem pode ser diferenciada tanto em relação a \\(x_1\\) quanto em relação a \\(x_2\\). Quando derivamos primeiro em \\(x_1\\) e depois em \\(x_2\\) temos a chamada derivada parcial cruzada (ou mista) denotada por \\(\\frac{\\partial^2 f(x_1,x_2)}{\\partial x_1 \\partial x_2}\\). Importante enfatizar que as derivadas parciais cruzadas de uma função serão sempre iguais, ou seja, \\(\\frac{\\partial^2 f(x_1,x_2)}{\\partial x_1 \\partial x_2} = \\frac{\\partial^2 f(x_1,x_2)}{\\partial x_2 \\partial x_1}\\), se ambas as derivadas parciais forem contínuas.\nExample 1.9 Obtenha as derivadas parciais de até segunda ordem em relação a \\(x_1\\) e \\(x_2\\) de \\(y = 7x_1^3 + 9 x_1 x_2 + 2 x_2^5\\).\n\nDerivadas parciais de primeira ordem\n\n\\[\\frac{\\partial y}{\\partial x_1} = 21 x_1^2 + 9 x_2, \\quad \\quad \\frac{\\partial y}{\\partial x_2} = 9x_1 + 10x_2^4.\\]\n\nDerivadas parciais de segunda ordem (segunda derivadas direta)\n\n\\[\\frac{\\partial^2 y}{\\partial x_1^2} = 42x_1, \\quad \\quad \\frac{\\partial^2 y}{\\partial x_2^2} = 40x_2^3.\\]\n\nDerivadas parciais de segunda ordem (termos cruzados)\n\n\\[\\frac{\\partial^2 y}{\\partial x_1 x_2} = \\frac{\\partial 21 x_1^2 + 9 x_2}{\\partial x_2} = 9, \\quad \\quad \\frac{\\partial^2 y}{\\partial x_2 x_1} = \\frac{\\partial 9x_1 + 10x_2^4}{\\partial x_1} = 9.\\]\nNovamente, o principal interesse no uso de derivadas parciais é a otimização (maximização ou minimização) de funções de múltiplas variáveis independentes. De forma similar ao caso de uma variável independente, temos algumas condições para encontrar os pontos de máximo ou mínimo.\n\nAs derivadas parciais de primeira ordem devem ser iguais a zero simultaneamente, ou seja, \\(\\frac{\\partial y}{\\partial x_1} = 0\\) e \\(\\frac{\\partial y}{\\partial x_2} = 0\\). Essa condição assegura que a função não está crescendo nem decrescendo no ponto. Isso caracteriza o que chamamos de pontos críticos.\nSe as derivadas parciais de segunda ordem no ponto crítico forem ambas positivas então teremos um ponto de mínimo. Por outro lado, se as derivadas parciais de segunda ordem forem negativas teremos um ponto de máximo.\nO produto das derivadas parciais de segunda ordem no ponto crítico deve exceder o valor do quadrado das derivadas parciais cruzadas. Isto assegura que a função está em um ponto ótimo quando avaliada de todas as direções, e não apenas em relação aos eixos principais. Essa condição assegura que a matriz de derivadas de segunda ordem é positiva definida. Para funções com mais de duas variáveis independentes é mais complicado verificar essa condição. No Capítulo 2 discutiremos sobre matrizes positivas definidas o que nos ajudará a verificar essa condição para funções com um número arbitrário de variáveis independentes.\nSe o produto das derivadas parciais de segunda ordem principal (derivada segunda direta) não exceder o quadrado da derivada cruzada a função pode estar em um ponto de inflexão ou em um ponto de sela. Se for ponto de inflexão, a função estará em um ponto de máximo quando observada ao longo de um dos eixos, ao passo que estará em um ponto de mínimo quando observada do eixo restante. No caso do ponto de sela as segundas derivadas diretas assumirão sinais diferentes e o produto destas não excederá o quadrado das derivadas cruzadas. Apesar deste tipo de caso acontecer com frequência em matemática de forma geral, em ciências de dados e, mais especificamente, em modelos estatísticos e de aprendizagem de máquina, as funções que usamos para representar o modelo e a função perda são escolhidas de forma que os pontos críticos representem mínimo/máximo ao menos relativos na maiorias do casos.\n\nExample 1.10 Considere a função \\(y = 6 x_1^2 - 9 x_1 - 3 x_1 x_2 - 7 x_2 + 5 x_2^2\\). Encontre os pontos críticos e determine se são de máximo ou mínimo.\nPara resolver este exemplo, vamos primeiro desenhar o gráfico desta função bidimensional. Assim, precisamos implementá-la em R.\nCódigo 1.4 Exemplo de função bidimensional (entrada escalar).\n\nfx1x2 &lt;- function(x1, x2) {\n  y = 6*x1^2 - 9 *x1 - 3*x1*x2 - 7*x2 + 5*x2^2\n  return(y)\n}\n\nNote que a função em 1.4 tem duas variáveis independentes, da mesma forma que a função em 1.2. Porém, neste caso, estamos passando dois escalares x1 e x2. Na função em 1.2 nós optamos por passar um vetor x com duas posições x[1] e x[2]. De forma geral, para avaliar a função em muitos pontos, é mais simples passar um vetor de entradas. No entanto, neste exemplo passaremos dois escalares para mostrar mais de uma forma de lidar com funções bidimensionais. Com a função implementada podemos avaliá-la em alguns pontos. Por exemplo, vamos avaliar a função nos pontos \\(x_1 = 2\\) e \\(x_2 = 3\\).\n\nfx1x2(x1 = 2, x2 = 3)\n\n[1] 12\n\n\nPara desenhar o gráfico da função precisamos avaliá-la em uma grade de pontos. Definir a grade não é uma tarefa simples, porém um pouco de tentativa e erro tende a fornecer algum entendimento da função, e em geral é suficiente para fazer um gráfico. Neste exemplo, vamos usar uma grade com \\(100^2\\) pontos regularmente espaçados entre \\(-1\\) e \\(3\\) nas direções de \\(x_1\\) e \\(x_2\\). A função expand.grid() auxilia nesta tarefa.\n\nx1 &lt;- seq(-1, 3, l = 100)\nx2 &lt;- seq(-1, 3, l = 100)\ngrade &lt;- expand.grid(x1, x2)\nhead(grade)\n\n        Var1 Var2\n1 -1.0000000   -1\n2 -0.9595960   -1\n3 -0.9191919   -1\n4 -0.8787879   -1\n5 -0.8383838   -1\n6 -0.7979798   -1\n\n\nO próximo passo é avaliar a função nos pontos da grade. Para isso vou utilizar o comando for() que vai percorrer todos os valores da grade avaliando a função no respectivo ponto.\n\ny &lt;- c()\nfor(i in 1:10000) {\n  y[i] &lt;- fx1x2(x1 = grade[i,1], x2 = grade[i,2])\n}\n\nAlguns aspectos importantes do uso do for().\n\nPrimeiro precisamos criar um objeto vazio, neste caso chamado de y para armazenar o resultado da avaliação da função.\nAcessamos os elementos da grade (uma matriz de tamanho \\(10000\\) linhas por \\(2\\) colunas), usando o operador [linha, coluna]: o primeiro número se refere a linha da grade e o segundo se refere a coluna da grade.\n\nPara desenhar o gráfico vamos usar as funções image() e contour() para incluir as curvas de nível.\n\n\n\n\n\n\n\n\nFigure 1.17: Representação bidimensional de uma função com suas curvas de nível.\n\n\n\n\n\nUma outra forma de desenhar o gráfico é usando a função perp().\n\n\n\n\n\n\n\n\nFigure 1.18: Representação bidimensional de uma função usando gráfico de perspectiva.\n\n\n\n\n\nOs gráficos apresentados nas Figuras 1.20 e 1.21 mostram que o ponto crítico é de mínimo, porém não é fácil encontrar o ponto crítico apenas visualmente. Vamos então usar o procedimento já descrito baseado nas derivadas parciais.\n\nCalcular as derivadas parciais de primeira ordem da função \\(y = 6 x_1^2 - 9 x_1 - 3 x_1 x_2 - 7 x_2 + 5 x_2^2.\\)\n\nDerivando em \\(x_1\\), temos\n\\[\\begin{equation}\n  \\frac{\\partial y}{ \\partial x_1} = 12x_1 - 9 - 3x_2.\n  \\tag{1.7}\n\\end{equation}\\]\nDe forma similar derivando em \\(x_2\\), temos\n\\[\\begin{equation}\n  \\frac{\\partial y}{ \\partial x_2} = -3x_1 - 7 + 10 x_2.\n  \\tag{1.8}\n\\end{equation}\\]\n\nResolver o sistema de equações\n\n\\[\\begin{align}\n\\begin{matrix}\n12x_1 - 9 - 3x_2 = 0\\\\\n-3x_1 - 7 + 10 x_2 = 0.\n\\end{matrix}\n\\end{align}\\]\nPara resolver o sistema, primeiro note que da Equação (1.7) é possível obter \\(x_2\\) como uma função de \\(x_1\\),\n\\[\\begin{align}\n12x_1 - 2x_2 & =&  9 \\\\\n-3x_2 & =&  9 - 12x_1 \\\\\nx_2 & =&  4x_1 - 3.\n\\end{align}\\]\nAgora substituímos \\(x_2 = 4x_1 - 3\\) na Equação (1.8) e obtemos\n\\[\\begin{align}\n-3x_1 + 10x_2 & = &  7 \\\\\n-3x_1 + 10(4x_1 - 3) & = &  7 \\\\\n-3x_1 + 40x_1 -30 & = &  7 \\\\\n37x_1 & = &  37 \\\\\nx_1 = 1.\n\\end{align}\\]\nPor fim, sabemos que \\(x_2 = 4x_1 - 3\\), e portanto \\(x_2 = 4 - 3 = 1\\). Assim, chegamos que \\(x_1 = 1\\) e \\(x_2 = 1\\).\n\nVerificar se o ponto encontrado é de mínimo, calculando a segunda derivada parcial e avaliando o seu sinal.\n\n\\[\\begin{equation*}\n\\frac{\\partial^2 y}{\\partial x_1^2} = \\frac{\\partial}{\\partial x_1} (12x_1 - 9 - 3x_2) = 12, \\quad \\\\\n\\frac{\\partial^2 y}{\\partial x_2^2} = \\frac{\\partial}{\\partial x_2}(3x_1 - 7 + 10x_2) = 10.\n\\end{equation*}\\]\nComo ambas derivadas de segunda ordem são positivas, o ponto \\(x_1 = 1\\) e \\(x_2 = 1\\) é um ponto de mínimo em relação aos eixos principais.\n\nCalcular as derivadas cruzadas e verificar se o produto das derivadas principais é maior que o produto das cruzadas.\n\n\\[\\begin{equation*}\n\\frac{\\partial^2 y}{\\partial x_1 x_2} = \\frac{\\partial 12x_1 - 9 - 3x_2}{\\partial x_2} = -3, \\quad \\quad\n\\frac{\\partial^2 y}{\\partial x_2 x_1} = \\frac{\\partial -3x_1 - 7 + 10x_2}{\\partial x_2} = -3.\n\\end{equation*}\\]\nAssim, temos que\n\\[\\begin{align}\n\\frac{\\partial^2 y}{\\partial x_1^2} \\frac{\\partial^2 y}{\\partial x_2^2} & &gt;&  \\left( \\frac{\\partial^2 y}{\\partial x_1 x_2} \\right)^2 \\\\\n12 \\times 10 & &gt;&  (-3)^2 \\\\\n120 &gt; 9.\n\\end{align}\\]\nAssim, concluímos que a função está em um ponto de mínimo quando examinada de todas as direções, e não apenas em relação aos eixos principais.\n\n\n1.2.7 Gradiente e Hessiano\nAs derivadas de primeira e segunda ordem de uma função de múltiplas variáveis independentes aparecem com muita frequência em matemática e por isso receberam nomes especiais.\n\n\n\n\n\n\nDefinição 1.16\n\n\n\nO vetor gradiente de uma função \\(f(x_1,x_2)\\) é o vetor composto pelas derivadas primeiras de \\(f(x_1,x_2)\\) em relação a \\(x_1\\) e \\(x_2\\), \\[\n\\nabla f(x_1,x_2) = \\left ( \\frac{\\partial f(x_1,x_2)}{\\partial x_1}, \\frac{\\partial f(x_1,x_2)}{\\partial x_2} \\right )^{\\top}.\n\\]\n\n\nA definição 1.16 se estende naturalmente para funções com mais do que duas variáveis independentes. Neste caso a função é denotada por \\(f(\\boldsymbol{x})\\) onde \\(\\boldsymbol{x}\\) é um vetor \\(p \\times 1\\) de variáveis independentes o vetor gradiente de \\(f(\\boldsymbol{x})\\) é dado por\n\\[\n\\nabla f(\\boldsymbol{x}) = \\left ( \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_1}, \\ldots, \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_p} \\right )^{\\top}.\n\\]\nDe forma similar as derivadas de segunda ordem de \\(f(x_1, x_2)\\) podem ser convenientemente arranjadas em uma matriz de duas linhas e duas colunas.\n\n\n\n\n\n\nDefinição 1.17\n\n\n\nA matriz hessiana** de uma função \\(f(x_1,x_2)\\) é a matriz composta pelas derivadas de segunda ordem de \\(f(x_1,x_2)\\), na seguinte estrutura\n\\[\\begin{equation*}\n\\mathbf{H} = \\begin{pmatrix}\n\\frac{\\partial^2 f(x_1,x_2)}{\\partial x_1^2} &  \\frac{\\partial f(x_1,x_2)}{\\partial x_1 \\partial x_2} \\\\\n\\frac{\\partial f(x_1,x_2)}{\\partial x_2 \\partial x_1} &  \\frac{\\partial^2 f(x_1,x_2)}{\\partial x_2^2}\n\\end{pmatrix}.\n\\end{equation*}\\]\n\n\nA definição 1.17 se estende naturalmente para uma função com um número arbitrário \\(p\\) de variáveis independentes. Neste caso a matriz hessiana tem dimensão \\(p \\times p\\) com as seguintes entradas\n\\[\\begin{equation*}\n\\mathbf{H} = \\begin{pmatrix}\n\\frac{\\partial^2 f(\\boldsymbol{x})}{\\partial x_1^2} &  \\cdots &  \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_1 \\partial x_p} \\\\\n\\vdots &  \\ddots  &  \\vdots \\\\\n\\frac{\\partial f(\\boldsymbol{x})}{\\partial x_p \\partial x_1} &  \\cdots &  \\frac{\\partial^2 f(\\boldsymbol{x})}{\\partial x_p^2}\n\\end{pmatrix}.\n\\end{equation*}\\]\n\n\n1.2.8 Séries de Taylor\nEm diversas situações em ciência de dados é comum nos depararmos com funções difíceis de lidar, seja matematica ou computacionalmente. Em tais situações é natural pensar em fazer algum tipo de aproximação da função de interesse por uma mais simples de lidar.\nO núcleo das técnicas de ciência de dados dizem respeito às ferramentas de inferência estatística e métodos numéricos. Nestes campos geralmente vamos lidar com funções bastante complicadas, mas que podem ser aproximadas por funções mais simples, em geral funções quadráticas (polinômios de segunda ordem).\nÉ neste contexto que aparece o que chamamos de expansões em Séries de Taylor. Isso nada mais é do que aproximar uma função \\(f(x)\\) por uma função mais simples: um polinômio de grau a ser definido pela ordem da aproximação. Suponha que uma função \\(f(x)\\) é derivável \\((n+1)\\) vezes em um intervalo contendo um ponto \\(x=x_0\\). A expansão em Série de Taylor de \\(f(x)\\) em torno do ponto \\(x=x_0\\) consiste em reescrever \\(f(x)\\) da seguinte forma:\n\\[\n\\begin{align}\nf(x) = f(x_0) + (x - x_0) \\frac{d f(x)}{dx} |_{x=x_0} + \\frac{(x-x_0)^2}{2!} \\frac{d^2 f(x)}{dx^2}|_{x=x0} + \\\\\n\\frac{(x-x_0)^3}{3!} \\frac{d^3 f(x)}{dx^3}|_{x=x_0} + \\ldots + \\frac{(x-x_0)^n}{n!} \\frac{d^n f(x)}{dx^n}|_{x=x_0} + R_n(x)\n\\tag{1.9}  \n\\end{align}\n\\]\nonde o termo \\(R_n(x)\\) é chamado de resíduo ou erro, e dado por\n\\[\nR_n(x) = \\frac{(x-x_0)^{n+1}}{(n+1)!} \\frac{d^{n+1} f(x)}{d x^{n+1}}|_{x= \\epsilon}\n\\]\nsendo \\(\\epsilon\\) um valor entre \\(x\\) e \\(x_0\\). Em geral o valor do resíduo \\(R_n(x)\\) não pode ser calculado na prática, uma vez que \\(\\epsilon\\) não é conhecido.\nPara obter a aproximação da função ao redor de um ponto \\(x_0\\) é comum usar dois ou mais termos da série. A precisão da aproximação depende de quantos termos da Série de Taylor são usados e também da forma da função original. A ideia é que a aproximação melhore conforme se aumenta o número de termos na aproximação, porém a complexidade da aproximação também cresce. Em inferência estatística o mais comum é usar aproximação de segunda ordem. O que implica que a função original será aproximada por um polinômio quadrático. É importante enfatizar que a aproximação é feita ao redor de um ponto \\(x_0\\) e em geral vai ser útil apenas ao redor deste ponto e não em todo o domínio da função.\nExample 1.11 Seja \\(f(x) = \\exp(x)\\). Determine a expansão de Taylor de ordens \\(1\\) e \\(2\\), de \\(f(x)\\) ao redor de \\(x_0 = 0\\). Desenhe os gráficos de \\(f(x)\\) e dos polinômios de Taylor.\nVamos chamar de \\(P_1(x)\\) e \\(P_2(x)\\) os polinômios de Taylor de primeira e segunda ordem, respectivamente. Usando as regras de derivação para a função exponencial sabemos que \\(f^{\\prime}(x) = f^{\\prime \\prime}(x) = \\exp(x)\\). Usando a Equação (1.9) apenas com o primeiro termo, temos\n\\[\\begin{eqnarray*}\nP_1(x) & =&  f(x = 0) + f^{\\prime}(x = 0)(x - 0) \\\\\n       & =&  \\exp(0) + \\exp(0)(x - 0) \\quad \\text{lembre-se que exponencial de 0 é 1} \\\\\n       & =&  1 + x.\n\\end{eqnarray*}\\]\nDe forma similar, usando os dois primeiros termos, temos\n\\[\\begin{eqnarray*}\nP_2(x) & =&  f(x = 0) + f^{\\prime}(x = 0)(x - 0) + \\frac{f^{\\prime \\prime}(x = 0)}{2}(x - 0)^2 \\\\\n       & =&  \\exp(0) + \\exp(0)(x - 0) + \\frac{\\exp(0)}{2} (x - 0)^2 \\\\\n       & =&  1 + x + \\frac{1}{2}x^2.\n\\end{eqnarray*}\\]\nPara traçar o gráfico da função e da aproximação, vamos implementar funções em R.\n\nfx &lt;- function(x)exp(x)\np1 &lt;- function(x)1+x\np2 &lt;- function(x)1+x+0.5*x^2\n\nVamos traçar o gráfico em duas situações. A primeira, apresentada na Figura 1.22 (A), mostra o gráfico da função e dos polinômios de Taylor apenas próximo do ponto \\(x = 0\\). Por outro lado, a Figura 1.22 (B) mostra o gráfico da função e dos polinômios de Taylor em uma maior porção do domínio de \\(f(x)\\).\n\nx &lt;- seq(-1, 1, l = 1000)\npar(mfrow = c(1,2), mar=c(2.6, 2.8, 1.2, 0.5), mgp = c(1.6, 0.6, 0))\nplot(fx(x) ~ x, type = \"l\", ylab = expression(f(x)), \n     xlab = \"x\", ylim = c(0, 2.8), main = \"(A)\")\nlines(x, p1(x), col = \"black\", lty = 2)\nlines(x, p2(x), col = \"black\", lty = 3)\n\nx &lt;- seq(-3, 3, l = 1000)\nplot(fx(x) ~ x, type = \"l\", ylab = expression(f(x)), \n     xlab = \"x\", main = \"(B)\", ylim = c(-5,20))\nlines(x, p1(x), col = \"black\", lty = 2)\nlines(x, p2(x), col = \"black\", lty = 3)\n\n\n\n\nIlustração da aproximação em Séries de Taylor de primeira e segunda ordem da função exponencial ao redor de zero.\n\n\n\n\nNote que ao redor do ponto \\(x_0\\) a aproximação é razoável. No entanto, conforme nos afastamos de \\(x_0\\) a aproximação vai piorando rapidamente. Em alguns casos é possível obter um limite superior para o erro de aproximação \\(R_n(x)\\). Porém, a obtenção de tais fórmulas está além do objetivo deste livro. Para mais sobre o assunto, o leitor pode consultar o liro ‘Um Curso de Cálculo: Volume I.’ Outra importante extensão da aproximação via Séries de Taylor é aproximar funções com duas ou mais variáveis independentes. Porém, tal extensão também está além dos objetivos deste livro.\n\n\n1.2.9 Regressão linear simples\nO modelo de regressão linear é uma das técnicas mais populares em ciência de dados. É muito comum em livros de modelagem estatística e aprendizado de máquina começar apresentando este modelo para então motivar modelos mais complexos. Nesta subseção nós vamos construir o modelo de regressão linear simples usando argumentos baseados apenas nos conceitos de funções que vimos nas seções anteriores. Chamaremos essa construção de puramente matemática. No entanto, uma formulação completamente estatística leva exatamente ao mesmo modelo com algumas vantagens em termos de inferência para os parâmetros do modelo. Porém, uma discussão estatística do modelo está fora do escopo deste livro.\nO objetivo de um modelo de regressão linear simples é descrever o comportamento de uma variável dependente, digamos \\(y\\) por meio do conhecimento de uma variável independente \\(x\\). Descrever o comportamento de \\(y\\) pode ser útil para predizer valores de futuras observações de \\(y\\) ou quantificar o efeito de \\(x\\) em \\(y\\). Apenas baseado nesta informação já é possível notar a semelhança do objetivo deste modelo com a construção de uma função. Na literatura especializada a variável dependente é também chamada de variável resposta, variável de saída, target, entre outros. Enquanto que a variável independente é também chamada de covariável, variável explanatória, variável explicativa ou ainda variável de entrada entre outros.\nPara ilustrar a construção do modelo de regressão linear simples considere que o objetivo é verificar como o tamanho (em metros quadrados) de um apartamento em uma região homogênea de uma cidade está associado ao valor (em reais) deste apartamento. Suponha que um conjunto de \\(20\\) apartamentos foi visitado, medido e avaliado por um profissional da área imobiliária. O conjunto de dados está disponível como material suplementar na página do livro. Abaixo são apresentadas apenas as seis primeiras observações, enquanto que na Figura 1.23 é apresentado um diagrama de dispersão do tamanho em metros quadrados (eixo \\(x\\)) e o valor em reais do apartamento (eixo \\(y\\)).\n\n##        y  x\n## 1 207318 55\n## 2 250846 69\n## 3 165755 46\n## 4 219817 61\n## 5 268582 73\n## 6 229060 63\n\n\n\n\n\n\n\n\n\nFigure 1.19: Diagrama de dispersão relacionando preço do apartamento como função do tamanho do apartamento em metros quadrados.\n\n\n\n\n\nA Figura 1.23 sugere que o preço do apartamento deve ser alguma função do seu tamanho. Para formalizar essa situação em termos matemáticos, vamos denotar \\(y_i\\) para \\(i = 1,\\ldots,n\\) o preço do apartamento \\(i\\) e neste caso \\(n = 20\\). De forma similar, denotamos por \\(x_i\\) o tamanho do apartamento \\(i\\) em metros quadrados. Assim, dizer que o preço é uma função do tamanho pode ser denotado da seguinte forma\n\\[\\begin{equation*}\n  y_i = f^*(x_i).\n  \\tag{1.10}\n\\end{equation*}\\]\nObviamente o primeiro desafio que surge é qual é a função \\(f^*(x_i)\\) que descreve o preço do apartamento por meio do seu tamanho. Em geral em termos práticos não conhecemos e nunca vamos conhecer tal função. o objetivo é de alguma forma aproximar a função \\(f^*(x_i)\\) por uma outra função \\(f(x_i)\\) que seja conhecida. Uma forma de fazer isso é escolher entre as inúmeras funções disponíveis na literatura e tentar de alguma forma descobrir qual é a que melhor descreve a relação em \\(y_i\\) e \\(x_i\\). Baseado no diagrama de dispersão apresentado na Figura 1.23 é possível ver que uma reta pode fornecer uma descrição razoável da relação entre preço e tamanho do apartamento.\nUma outra forma de pensar é usar a aproximação em séries de Taylor para aproximar a função desconhecida \\(f^{*}(x_i)\\). Usando a aproximação de Taylor de primeira ordem (veja Equação (1.9)) em torno de um ponto \\(x_0\\) desconhecido, temos\n\\[\\begin{equation*}\nf^*(x) = f^*(x_0) + (x-x_0)f^{*\\prime}(x_0) + R_n(x).\n\\end{equation*}\\]\nAgora ignorando o termo residual \\(R_n(x)\\), temos a seguinte aproximação para \\(f^*(x)\\).\n\\[\\begin{equation*}\n  f^{*}(x) \\approx f^*(x_0) + (x-x_0)f^{*\\prime}(x_0).\n  \\tag{1.11}\n\\end{equation*}\\]\nPodemos rearranjar os termos da Equação (1.11) para obter\n\\[\\begin{align}\nf^{*}(x) & \\approx&  \\underset{\\beta_0}{\\underbrace{\\left \\{f^*(x_0) - f^{*\\prime}(x_0)x_0 \\right \\}}} + \\underset{\\beta_1}{\\underbrace{f^{*\\prime}(x_0)}}x \\\\\nf^{*}(x) & \\approx&  \\beta_0 + \\beta_1 x.\n  \\tag{1.12}\n\\end{align}\\]\nAssim, concluímos que a função desconhecida \\(f^*(x)\\) pode ser aproximada usando uma expansão de Taylor de primeira ordem. Essa aproximação resulta em uma função linear (reta) parametrizada pelos parâmetros desconhecidos \\(\\beta_0\\) e \\(\\beta_1\\). Substituindo a aproximação em (1.12) no modelo original em (1.10) temos\n\\[\\begin{equation}\n  y_i = \\beta_0 + \\beta_1 x_i + R_n(x_i),\n\\end{equation}\\]\nem que o termo \\(R_n(x_i)\\) é o erro cometido em aproximar \\(y_i\\) por \\(\\beta_0 + \\beta_1 x_i\\). É comum na literatura de modelos de regressão denotar o termo \\(R_n(x_i)\\) por \\(\\epsilon_i\\) para simplificar a notação. Assim, o objetivo é encontrar \\(\\beta_0\\) e \\(\\beta_1\\) que tornem o nosso modelo, neste caso uma reta, o mais próximo possível de \\(y_i\\). Em outras palavras queremos minimizar o erro \\(\\epsilon_i = y_i - (\\beta_0 + \\beta_1 x_i).\\)\nPor outro lado, note que o erro é também uma função, mas agora dos parâmetros desconhecidos \\(\\epsilon(\\beta_0, \\beta_1)_i\\). Para medir o quanto a nossa aproximação está próxima das observações podemos usar a função perda quadrática de forma análoga a subseção 1.2.5. Portanto, nosso objetivo passa a ser minimizar a soma de quadrados dos erros ou resíduos,\n\\[\\begin{align}\nSQ(\\beta_0, \\beta_1) & =&  \\sum_{i=1}^n \\epsilon^2(\\beta_0, \\beta_1)_i \\\\\nSQ(\\beta_0, \\beta_1) & =&  \\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1 x_i))^2.\n  \\tag{1.13}\n\\end{align}\\]\nNote que temos uma função com duas variáveis independentes \\(\\beta_0\\) e \\(\\beta_1\\). Importante ainda enfatizar que tanto \\(y_i\\) como \\(x_i\\) são números (constantes) dentro da soma de quadrados dos resíduos. Para encontrar, digamos, \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\) que minimizam (1.13) podemos usar o método baseado em derivadas parciais apresentado na subseção 1.2.6. O procedimento consiste dos seguintes passos:\n\nObter o vetor gradiente\n\n\\[\\nabla SQ(\\beta_0,\\beta_1) = \\left ( \\frac{\\partial SQ(\\beta_0,\\beta_1)}{\\partial \\beta_0}, \\frac{\\partial SQ(\\beta_0, \\beta_1)}{\\partial \\beta_1} \\right ).\\]\n\nEncontrar \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) tal que\n\n\\[\\nabla SQ(\\hat{\\beta}_0,\\hat{\\beta}_1) = \\mathbf{0}.\\]\n\nVerificar se o ponto critico encontrado é de mínimo avaliando o sinal das segundas derivadas parciais diretas e cruzadas.\n\nPara obter o vetor gradiente vamos usar a regra da cadeia, veja o passo-a-passo.\n\nChame \\(y_i - (\\beta_0 + \\beta_1 x_i) = \\epsilon_i\\).\nChame \\(\\beta_0 + \\beta_1 x_i = \\mu_i\\).\nAssim,\n\n\\[\\nabla SQ(\\beta_0,\\beta_1) = \\left ( \\frac{\\partial SQ(\\beta_0,\\beta_1)}{\\partial \\epsilon_i} \\frac{\\partial \\epsilon_i}{\\mu_i} \\frac{\\partial \\mu_i}{\\partial \\beta_0}, \\frac{\\partial SQ(\\beta_0,\\beta_1)}{\\partial \\epsilon_i} \\frac{\\partial \\epsilon_i}{\\mu_i} \\frac{\\partial \\mu_i}{\\partial \\beta_1} \\right ),\\]\nem que\n\\[\\frac{\\partial SQ(\\beta_0,\\beta_1)}{\\partial \\epsilon_i} = \\frac{\\partial}{\\partial \\epsilon_i}\\sum_{i=1}^n \\epsilon_i^2 = 2\\sum_{i=1}^2 \\epsilon_i.\\]\n\\[ \\frac{\\partial \\epsilon_i}{\\partial \\mu_i} = \\frac{\\partial}{\\partial \\mu_i} (y_i - \\mu_i) = -1.\\] \\[ \\frac{\\partial \\mu_i}{\\partial \\beta_0} = \\frac{\\partial}{\\partial \\beta_0} \\beta_0 + \\beta_1 x_i = 1.\\] \\[ \\frac{\\partial \\mu_i}{\\partial \\beta_1} = \\frac{\\partial}{\\partial \\beta_1} \\beta_0 + \\beta_1 x_i = x_i.\\]\nPortanto,\n\\[\\begin{eqnarray*}\n\\nabla SQ(\\beta_0,\\beta_1) & =&  \\left ( -2\\sum_{i=1}^n \\epsilon_i (1); -2\\sum_{i=1}^n \\epsilon_i x_i \\right ) \\\\\n& =&  \\left ( -2\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i); -2\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i) x_i \\right ).\n\\end{eqnarray*}\\]\nPrecisamos agora resolver o seguinte conjunto de equações simultâneas\n\\[\\begin{align}\n-2\\sum_{i=1}^n (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) & =&  0 \\tag{1.14}\\\\\n-2\\sum_{i=1}^n (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) x_i & =&  0. \\tag{1.15}\n\\end{align}\\]\nPara resolver o sistema de equações, primeiro note que da Equação (1.14) podemos obter \\(\\hat{\\beta_0}\\) como uma função de \\(\\hat{\\beta_1}\\),\n\\[\\begin{equation}\n\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}.\n\\tag{1.16}\n\\end{equation}\\]\nAgora, substituindo Equação (1.16) na Equação (1.15) e resolvendo em \\(\\hat{\\beta}_1\\), temos\n\\[\\begin{equation}\n  \\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n y_i x_i - \\bar{y}\\sum_{i=1}^n x_i}{\\sum_{i=1}^n x^2_i - \\bar{x}\\sum_{i=1}^n x_i}.\n  \\tag{1.17}\n\\end{equation}\\]\nPor fim, podemos obter as entradas da matriz Hessiana. As segundas derivadas principais são dadas por\n\\[\\begin{equation}\n\\frac{\\partial^2 SQ(\\beta_0, \\beta_1)}{\\partial \\beta^2_0} = \\frac{\\partial}{\\partial \\beta_0} -2 \\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1 x_i) = 2 n \\quad \\text{e} \\quad\n\\end{equation}\\]\n\\[\\begin{equation}\n\\frac{\\partial^2 SQ(\\beta_0, \\beta_1)}{\\partial \\beta^2_1} = \\frac{\\partial}{\\partial \\beta_1} -2 \\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1 x_i) x_i = 2 \\sum_{i=1}^n x_i^2.\n\\end{equation}\\]\nA segunda derivada cruzada é dada por\n\\[\\begin{equation}\n\\frac{\\partial^2 SQ(\\beta_0, \\beta_1)}{\\partial \\beta_0 \\beta_1} = \\frac{\\partial}{\\partial \\beta_1} -2 \\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1 x_i) = 2 \\sum_{i=1}^n x_i.\n\\end{equation}\\]\nAssim, a matriz Hessiana é dada por\n\\[\\begin{equation*}\n\\mathbf{H} = \\begin{pmatrix}\n2n                &   2\\sum_{i=1}^n x_i \\\\\n2\\sum_{i=1}^n x_i &  2\\sum_{i=1}^n x^2_i\n\\end{pmatrix}.\n\\end{equation*}\\]\nTemos que as derivadas parciais principais são sempre positivas o que indica que o ponto crítico é de mínimo. Além disso, temos que o produto das segundas derivadas principais é \\(n 4\\sum_{i=1}^n x_i^2\\), e portanto é sempre maior que o quadrado da segunda derivada cruzada \\(4\\sum_{i=1}^n x^2_i\\). Assim, o ponto é de mínimo quando a função é avaliada de todas as direções.\nCom estes resultados, podemos obter a reta ótima e visualizar o ajuste do modelo em comparação com os dados. Para isso, vamos ler a base de dados em R e obter os valores de \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\), conforme as Equações (1.16) e (1.17).\n## Carregando a base de dados\ndados &lt;- read.table(\"data/reglinear.csv\", header = TRUE)\n\n## Obtendo beta1\nbeta1 &lt;- (sum(dados$y*dados$x) - mean(dados$y)*sum(dados$x))/\n  (sum(dados$x^2) - mean(dados$x)*sum(dados$x))\n\n# Obtendo beta0\nbeta0 &lt;- mean(dados$y) - beta1*mean(dados$x)\nc(beta0, beta1)\nCom o intercepto e a inclinação da reta ajustada, podemos sobrepor o modelo aos dados.\n\n\n\n\n\n\n\n\nFigure 1.20: Diagrama de dispersão relacionando preço do apartamento como função do tamanho do apartamento em metros quadrados e reta de regressão ajustada.\n\n\n\n\n\nPor fim, podemos conferir o nosso resultado usando a função lm() do R que implementa o ajuste de modelos lineares.\nfit &lt;- lm(y ~ x, data = dados)\ncoef(fit)\nDada a simplicidade do modelo é também fácil interpretar os parâmetros estimados. O intercepto representa o preço de um apartamento de tamanho zero. O que óbviamente não tem sentido prático. No entanto, a inclinação (\\(\\beta_1\\)) representa o quanto é acrescido no preço do apartamento quando o seu tamanho aumenta em um metro quadrado.\nTambém podemos usar o modelo para predizer o preço aproximado de um imóvel. Por exemplo, em nossa base de dados não temos nenhum apartamento com \\(80\\) metros quadrados. Um potencial interesse pode ser em predizer o valor aproximado de um apartamento desse tamanho. Assim, podemos facilmente usar o nosso modelo que diz que o preço aproximado \\(\\hat{y}\\) de um apartamento é dado por \\(\\hat{y} = 2623 + 3608 \\times x\\). Substituindo \\(x = 80\\) temos que o preço aproximado é de R\\(\\$ 291.263\\).\nÉ claro que o modelo não irá predizer o valor exato do apartamento. Isso acontece porque temos apenas uma aproximação de primeira ordem da verdadeira função \\(f^*(x)\\) que relaciona o tamanho com o preço. Uma opção é incluir mais termos na aproximação para obter uma forma de relacionamento mais flexível. Acontece que em termos práticos, tal abordagem não é muito útil por pelo menos dois motivos:\n\nO erro cometido pode ser pelo fato de existir outras características importantes para determinar o preço do apartamento que não foram levadas em consideração em nosso modelo. Neste caso, o efeito de tais características será absorvido pelo termo de erro. E mesmo aumentando a ordem de aproximação o erro do modelo não apresentará um grande decréscimo.\n\n2.Podem existir erros de mensuração pelo profissional da imobiliária que também serão absorvidos pelo termo de erro. Neste caso, se aumentarmos a ordem da aproximação estaremos capturando os erros de mensuração, o que claramente não é nosso objetivo. Lembre-se o objetivo de um modelo é representar a realidade de forma simplificada e não reproduzir os dados observados (potencialmente com erros).\nO modelo de regressão linear simples é facilmente estendido para o modelo de regressão linear múltipla. Neste modelo o valor da variável independente \\(y\\) será uma função não de apenas uma variável explicativa, mas de várias. Neste modelo os cálculos necessários para obter as estimativas para os parâmetros \\(\\beta\\)’s cresce rapidamente em complexidade e usar a estratégia de resolver um sistema de linear de equações torna-se muito trabalhoso. Consequentemente precisamos de ferramentas mais gerais que nos permitam lidar com vetores e matrizes. Tais ferramentas serão apresentadas no Capítulo 2. Mas antes disso vamos apresentar o último tópico do Capítulo de Cálculo Diferencial e Integral: Integrais.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cálculo Diferencial e Integral</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html#teorema-101",
    "href": "content/Modulo01/index.html#teorema-101",
    "title": "1  Cálculo Diferencial e Integral",
    "section": "1.3 Teorema 1.1",
    "text": "1.3 Teorema 1.1\nSe \\(f(x)\\) existe para todos os valores de \\(x\\) no intervalo aberto \\((a,b)\\), e se \\(f(x)\\) tem um extremo relativo em \\(c\\), em que \\(a &lt; c &lt; b\\), então \\(f^{\\prime}(c)\\) existe e \\(f^{\\prime}(c) = 0\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cálculo Diferencial e Integral</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html#teorema-102",
    "href": "content/Modulo01/index.html#teorema-102",
    "title": "1  Cálculo Diferencial e Integral",
    "section": "1.4 Teorema 1.2",
    "text": "1.4 Teorema 1.2\nSeja \\(c\\) um ponto extremo de uma função \\(f(x)\\) no qual \\(f^{\\prime}(c) = 0\\), e suponha que \\(f^{\\prime}(x)\\) exista para todos os valores de \\(x\\) em um intervalo aberto contendo \\(c\\). Se \\(f^{\\prime \\prime}(c)\\) existe, então\n\nSe \\(f^{\\prime \\prime}(c) &lt; 0\\), então \\(f(x)\\) tem um máximo relativo em \\(c\\).\nSe \\(f^{\\prime \\prime}(c) &gt; 0\\), então \\(f(x)\\) tem um mínimo relativo em \\(c\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cálculo Diferencial e Integral</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html#integrais",
    "href": "content/Modulo01/index.html#integrais",
    "title": "1  Cálculo Diferencial e Integral",
    "section": "1.3 Integrais",
    "text": "1.3 Integrais\nSendo \\(f(x)\\) uma função de uma variável independente, existem dois tipos de integrais: a integral indefinida e a integral definida. Nesta seção, vamos apresentar algumas regras básicas de integração e sua ideia fundamental como ferramenta matemática para calcular a área abaixo de curvas.\n\n1.3.1 Integral indefinida\nChamamos de integral indefinida o oposto ou o inverso da derivada, também chamada de antiderivada.\n\n\n\n\n\n\nDefinição 1.18\n\n\n\nA integral indefinida da função \\(f(x)\\) é expressa por \\[\\int f(x) dx = F(x) + c.\\]\n\n\nEsta notação é lida como sendo “a integral de \\(f\\) de \\(x\\) em relação a \\(x\\).” O símbolo \\(\\int\\) é o sinal de integral, \\(f(x)\\) é chamado de integrando e \\(c\\) é uma constante de integração. \\(F(x) + c\\) é chamada de integral indefinida porque \\(x\\) não é especificado e portanto pode assumir vários valores.\nPara calcular uma integral indefinida tente pensar em qual função você deveria derivar para encontrar \\(f(x)\\). Por exemplo,\n\\[ \\int x dx = \\frac{x^2}{2} + c,\\] uma vez que se derivarmos \\(\\frac{x^2}{2}\\) encontramos \\(x\\).\nDa mesma forma que no caso de derivadas, contamos com uma extensa lista de regras de integração. Tais regras são obtidas pela inversão das regras correspondentes de diferenciação. Sendo \\(k\\) uma constante qualquer, temos\n\nIntegral de uma constante \\(k\\) \\[\\int k dx = kx + c.\\]\nIntegral de \\(1\\) \\[\\int 1 dx = x + c.\\]\nIntegral da função potência \\(x^n\\), onde \\(n \\neq -1\\) \\[ \\int x^n dx = \\frac{1}{n+1} x^{n+1} + c \\quad n \\neq 1.\\]\nIntegral de \\(x^{-1}\\) \\[\\int \\frac{1}{x} dx = \\ln |x| + c \\quad \\text{se} \\quad x \\neq 0.\\]\nIntegral da função exponencial \\[\\int a^{kx} dx = \\frac{a^{kx}}{k \\ln a} + c.\\]\nIntegral da função exponencial natural \\[\\int \\exp^{kx}dx = \\frac{\\exp^{kx}}{k} + c.\\]\nA integral de uma constante multiplicado por uma função é igual à constante multiplicada pela integral da função. \\[\\int k f(x) dx = k \\int f(x) dx.\\]\nA integral da soma é igual a soma das integrais. \\[\\int \\left[ f(x) + g(x)\\right]dx = \\int f(x)dx + \\int g(x) dx.\\]\n\nO leitor atento deve estar se perguntando: o que é a constante de integração \\(c\\)? E por que ela aparece em todas as regras de integração? O que explica a necessidade da constante de integração \\(c\\) é o fato de que funções que diferem apenas por uma constante têm a mesma derivada. Por exemplo, a função \\(F(x) = 2x + k\\) tem a mesma derivada, \\(f(x) = 2\\), para um número infinito de valores possíveis para \\(k\\). Se o processo é invertido, fica claro que \\(\\int 2 dx\\) tem que ser a antiderivada para um número infinito de funções que diferem umas das outras apenas por uma constante. Portanto, a constante de integração \\(c\\) serve para representar o valor de qualquer constante que fazia parte da função primitiva que foi excluída da derivada pelas regras de diferenciação.\nExistem diversas outras técnicas ou regras de integração como: integral por partes, integração por substituição, e diversas outras que não serão tratadas neste material. O uso de integrais em ciência de dados é mais restrito do que o de derivadas. Integrais serão úteis no estudo da teoria das probabilidades e aparecem em técnicas avançadas de modelagem estatística como nos modelos hierárquicos ou, de forma mais geral, na classe dos modelos com variáveis latentes. Novamente, tais técnicas estão fora do escopo deste livro.\n\n\n1.3.2 Integral definida\nSuponha que \\(f(x)\\) defina uma curva entre os pontos \\(a\\) e \\(b\\) conforme ilustrado na Figura 1.25 (A). O interesse é calcular a área sob a curva \\(f(x)\\) entre os pontos \\(a=0\\) e \\(b=1\\). Não há fórmula geométrica para obter tal área. O desafio que surge é como calcular a área abaixo desta curva. Para resolver este desafio é que usamos a integral definida.\nDe forma geral, a ideia é bastante intuitiva e consiste em dividir o intervalo \\([a,b]\\) em \\(n\\) subintervalos, digamos \\([a_1,b_1], \\ldots, [a_n, b_n]\\). Para cada um destes subintervalos podemos construir retângulos de tal modo que a altura seja igual ao menor valor da função no subintervalo, conforme ilustrado na Figura 1.25 (B). A soma das áreas dos retângulos \\(\\sum_{i=1}^n f(x_i) \\Delta x_i\\) será aproximadamente a área sob a curva. Nesta notação, \\(\\Delta x_i = x_{i+1} - x_i\\), é o comprimento da base do retângulo. Quanto menor for o subintervalo, mais retângulos serão criados e melhor será a aproximação.\n\n\n\n\n\n\n\n\nFigure 1.21: Ilustração de função para o cálculo de área abaixo de uma curva.\n\n\n\n\n\nBaseado nesta intuição e com o uso de limites, podemos tornar o número de retângulos tão grande quanto necessário. Assim, a área abaixo da curva \\(f(x)\\) pode ser matematicamente expressa por\n\\[\\begin{equation}\n  \\lim_{n \\to \\infty} \\sum_{i=1}^n f(x_i) \\delta x_i = \\int_{a}^b f(x) dx.\n  \\tag{1.18}\n\\end{equation}\\]\nA ideia é simples: vamos diminuindo a amplitude de cada intervalo até que cada intervalo se torne infinitesimal. De forma equivalente, podemos pensar que estamos incluindo cada vez mais retângulos, o que vai fazer com que a soma de Riemann (Equação (1.18)) fique cada vez mais próxima da área abaixo de \\(f(x)\\). Essa ideia é ilustrada na Figura 1.26 para um número crescente de retângulos.\n\n\n\n\n\n\n\n\nFigure 1.22: Ilustração da soma de Riemann.\n\n\n\n\n\nNa Figura 1.26 (A) foram utilizados \\(9\\) retângulos, ao passo que em 1.26 (B) e 1.26 (C) foram utilizados \\(24\\) e \\(49\\) retângulos, respectivamente. Claramente conforme o número de retângulos cresce a área abaixo de \\(f(x)\\) é melhor aproximada.\nA integral definida de uma função contínua \\(f(x)\\) sobre o intervalo \\(a\\) e \\(b\\), sendo \\(a &lt; b\\) é denotada por\n\\[\\int_{a}^b f(x) dx.\\]\nEssa notação é lida como “a integral de \\(a\\) até \\(b\\) de \\(f\\) de \\(x\\) \\(dx\\).” \\(a\\) é chamado limite inferior de integração e \\(b\\) é chamado limite superior de integração.\nPara o cálculo da integral definida usamos o Teorema fundamental do cálculo que diz que o valor numérico da integral definida de uma função contínua \\(f(x)\\) no intervalo de \\(a\\) até \\(b\\) é dada pela integral indefinida \\(F(x) + c\\) calculada no limite superior de integração \\(b\\), menos a mesma integral indefinida calculada no limite inferior de integração \\(a\\). Assim, como \\(c\\) é comum aos dois, a constante de integração é eliminada por subtração.\n\n\n\n\n\n\nTeorema 1.3\n\n\n\nSe uma função \\(f(x)\\) é contínua ao longo do intervalo \\([a,b]\\) e \\(F(x)\\) é a antiderivada de \\(f(x)\\) ao longo desse mesmo intervalo, então\n\\[ \\int_{a}^b f(x) dx = F(b) - F(a).\\]\n\n\nExample 1.12 Calcule \\[ \\int_{1}^{2} x^2 dx.\\]\nA solução é bastante simples usando a antiderivada e o Teorema 1.3.\n\\[F(2) - F(1) = \\frac{x^3}{3}|_{x=2} - \\frac{x^3}{3}|_{x=1} = \\frac{8}{3} - \\frac{1}{3} = \\frac{7}{3} = 2.33\\ldots.\\]\nUma outra forma de obter apenas o valor da integral é usar diretamente a soma de Riemann. Computacionalmente, a soma de Riemann pode ser facilmente implementada em R conforme ilustrado no Código 1.5.\nCódigo 1.5 Soma de Riemann.\n\nsoma_riemann &lt;- function(n, a, b, fx, ...) {\n  intervalos &lt;- seq(a, b, length = n)\n  ci &lt;- c()\n  soma &lt;- c()\n  for(i in 1:c(n-1)) {\n    Deltai &lt;- (intervalos[i+1] - intervalos[i]) # Tamanho do intervalo\n    ci[i] &lt;- (intervalos[i+1] + intervalos[i])/2 # Ponto central do intervalo\n    soma[i] &lt;- fx(ci[i])*Deltai # Cada elemento da soma\n  }\n  return(sum(soma))\n}\nsoma_riemann &lt;- Vectorize(soma_riemann, \"n\")\n\nAgora vamos avaliar o valor da integral para um número crescente de retângulos dentro do intervalo \\([1,2]\\). A Figura 1.27 (A) apresenta o gráfico da função \\(f(x) = x^2\\) no intervalo \\([1,2]\\). A Figura 1.27 (B) apresenta no eixo \\(y\\) o valor aproximado da integral como uma função do número de intervalos (eixo \\(x\\)).\n\n\n\n\n\n\n\n\nFigure 1.23: Ilustração da soma de Riemann.\n\n\n\n\n\nClaramente, conforme aumentamos o número de intervalos o valor aproximado da integral se estabiliza em torno do valor \\(\\frac{7}{3}\\). O mesmo valor que obtemos usando a antiderivada e o Teorema 1.3.\nNo caso de integrais definidas pode acontecer que um ou ambos limites de integração sejam infinito ou menos infinito, neste caso dizemos que temos uma integral imprópria.\nExample 1.13 São exemplos de integrais impróprias\n\\[\\int_{a}^{\\infty} f(x) dx, \\quad \\int_{-\\infty}^{b} f(x) dx \\quad \\text{e} \\quad \\int_{-\\infty}^{\\infty} f(x) dx.\\]\nNeste caso infinito não é um número e não pode ser substituído por \\(x\\) em \\(F(x)\\). Assim, precisamos novamente recorrer a limites para obter o valor de tais integrais.\n\\[\\int_{a}^{\\infty} f(x)dx = \\lim_{b \\to \\infty} \\int_{a}^b f(x) dx.\\]\nSe o limite existir dizemos que a integral imprópria converge e a integral terá um valor. Caso contrário, a integral imprópria diverge e não terá significado prático.\nEm termos computacionais o R não dispõe de uma função semelhante a função D() para a obtenção de integrais de forma simbólica. Porém, é possível usar outros softwares de matemática simbólica como o Wolfram alpha e o wxMaxima. Em R a função integrate() pode ser utilizada para o cálculo de integrais de uma variável, porém usando algoritmos numéricos. A ideia é similar a soma de Riemann. Vamos obter o valor da integral do Exemplo 1.12 usando a função integrate().\n\nfx &lt;- function(x) x^2\nintegrate(fx, lower = 1, upper = 2)\n\n2.333333 with absolute error &lt; 2.6e-14\n\n\nApenas como comparação, o valor da integral usando a soma de Riemann com \\(n = 100\\).\n\nsoma_riemann(n = 100, a = 1, b = 2, fx = fx)\n\n[1] 2.333325\n\n\nAmbas abordagens retornam o mesmo valor para a integral.\nPor fim, é importante mencionar que o cálculo de integrais pode ser estendido para funções com mais de uma variável independente de forma análoga ao que foi feito para derivadas, ou seja, integramos uma variável independente assumindo que todas as outras são constantes. Porém, uma discussão mais completa sobre integrais multidimensionais está fora do escopo deste material.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cálculo Diferencial e Integral</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html#teorema-103",
    "href": "content/Modulo01/index.html#teorema-103",
    "title": "1  Cálculo Diferencial e Integral",
    "section": "1.6 Teorema 1.3",
    "text": "1.6 Teorema 1.3\nSe uma função \\(f(x)\\) é contínua ao longo do intervalo \\([a,b]\\) e \\(F(x)\\) é a antiderivada de \\(f(x)\\) ao longo desse mesmo intervalo, então\n\\[ \\int_{a}^b f(x) dx = F(b) - F(a).\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cálculo Diferencial e Integral</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html#referências-bibliográficas",
    "href": "content/Modulo01/index.html#referências-bibliográficas",
    "title": "1  Cálculo Diferencial e Integral",
    "section": "1.4 Referências bibliográficas",
    "text": "1.4 Referências bibliográficas\nPara escolher o conteúdo deste capítulo nós pensamos quais eram os principais conteúdos da disciplina de cálculo diferencial e integral essenciais para que o leitor pudesse acompanhar livros como Goodfellow, Bengio, and Courville (2016) e Deisenroth, Faisal, and Ong (2020). Como inspiração para estruturar o capítulo foram usados livros básicos de cálculo aplicado à economia e administração tais como Dowling (1984) e Leithold (1988). Além dos capítulos iniciais de Gilat and Subramaniam (2009). Por fim, para uma base mais sólida do cálculo diferencial e integral foi consultado Guidorizzi (2013).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cálculo Diferencial e Integral</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/index.html#exercícios",
    "href": "content/Modulo01/index.html#exercícios",
    "title": "1  Cálculo Diferencial e Integral",
    "section": "1.5 Exercícios",
    "text": "1.5 Exercícios\nOs exercícios deste livro são na forma de tutoriais interativos.\nAcesse Exercícios Cálculo Diferencial Integral.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Cálculo Diferencial e Integral</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/Exercicios/index.html",
    "href": "content/Modulo01/Exercicios/index.html",
    "title": "5  Cálculo Diferencial e Integral para Cientista de Dados",
    "section": "",
    "text": "5.1 Funções, limites e continuidade\nOs objetivos deste tutorial são:",
    "crumbs": [
      "Exercicios",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cálculo Diferencial e Integral para Cientista de Dados</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/Exercicios/index.html#funções-limites-e-continuidade",
    "href": "content/Modulo01/Exercicios/index.html#funções-limites-e-continuidade",
    "title": "5  Cálculo Diferencial e Integral para Cientista de Dados",
    "section": "",
    "text": "Ganhar experiência com a interpretação de equações matemáticas.\nPraticar a implementação computacional de funções matemáticas.\nDesenhar e interpretar o gráfico de funções uni e bidimensionais.\nRevisar e ilustrar computacionalmente propriedades de funções do tipo potência, exponencial e logarítmos.\n\n\n5.1.1 Implementação de funções e seus gráficos\nPara os exercícios abaixo use a função plot() com a opção type = \"l\" para desenhar o gráfico das funções. Lembre-se que computacionalmente você vai avaliar a função em um conjunto de pontos. Para criar esse conjunto de pontos use a função seq(a, b, l = tamanho) onde a e b são os limites inferior e superior do intervalo e l determina o número de pontos dentro do intervalo. Recomendo que para esses exercícios você use l = 100. Você pode consultar a minha solução clicando no botão Solution. Note que a minha solução é apenas uma sugestão. O importante é você desenvolver a habilidade de traduzir uma equação matemática para o computador e desenhar o gráfico associado.\n\nImplemente a função \\(f(x) = \\sqrt{x}\\) e desenhe seu gráfico no intervalo \\((0,3)\\).\n\n\nx &lt;- seq(0, 3, l = 100)\nfx &lt;- function(x) {\n  sqrt(x)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(f(x) = \\log(x)\\) e desenhe seu gráfico no intervalo \\((-5,5)\\).\n\n\nx &lt;- seq(-5, 5, l = 100)\nfx &lt;- function(x) {\n  log(x)\n}\ny &lt;- fx(x = x)\n\nWarning in log(x): NaNs produzidos\n\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint:\n\n\n\nNote que o domínio da função \\(\\log\\) é apenas os reais positivos. Assim, a parte negativa não faz sentido para este gráfico.\n\n\n\nImplemente a função \\(\\log_{10}(x)\\) e desenhe seu gráfico no intervalo \\((0,5)\\).\n\n\nx &lt;- seq(0, 5, l = 100)\nfx &lt;- function(x) {\n  log10(x)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(\\exp(x)\\) e desenhe seu gráfico no intervalo \\((0,1)\\).\n\n\nx &lt;- seq(0, 1, l = 100)\nfx &lt;- function(x) {\n  exp(x)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(\\Gamma(x)\\) e desenhe seu gráfico no intervalo \\((0.5, 3)\\).\n\n\nx &lt;- seq(0.5, 3, l = 100)\nfx &lt;- function(x) {\n  gamma(x)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(f(x) = \\frac{1}{x}\\) e desenhe seu gráfico no intervalo \\((-1, 1)\\).\n\n\nx1 &lt;- seq(-1, 0, l = 50)\nx2 &lt;- seq(0, 1, l = 50)\nfx &lt;- function(x) {\n  1/x\n}\ny1 &lt;- fx(x = x1)\ny2 &lt;- fx(x = x2)\nplot(c(y1, y2) ~ c(x1, x2), type = \"l\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint:\n\n\n\nNote que neste exercício o ideal é dividir o domínio de \\(f(x)\\) em duas partes, uma vez que a função é descontinua em \\(x = 0\\). Avalie a função no ponto \\(x = 0\\) para ver o que o R retorna.\n\n\n\nImplemente a função \\(f(x) = |x - 1| + 2\\) e desenhe seu gráfico no intervalo \\((-5, 5)\\).\n\n\nx &lt;- seq(-5, 5, l = 100)\nfx &lt;- function(x) {\n  abs(x - 1) + 2\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(f(x) = \\mathrm{beta}(x, 0.5)\\) e desenhe seu gráfico no intervalo \\((0, 1)\\).\n\n\nx &lt;- seq(0, 1, l = 100)\nfx &lt;- function(x) {\n  beta(a = x, b = 0.5)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint:\n\n\n\nVeja a documentão da função beta ?beta.\n\n\n\nImplemente a função \\(f(x) = (x-1)^3\\) e desenhe seu gráfico no intervalo \\((-3, 5)\\).\n\n\nx &lt;- seq(-3, 5, l = 100)\nfx &lt;- function(x) {\n  (x - 1)^3\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nImplemente a função \\(f(x) = \\frac{(x+1)}{x}\\) e desenhe seu gráfico no intervalo \\((-3, 3)\\).\n\n\nx1 &lt;- seq(-3, 0, l = 100)\nx2 &lt;- seq(0, 3, l = 100)\nfx &lt;- function(x) {\n  (x+1)/x\n}\ny1 &lt;- fx(x = x1)\ny2 &lt;- fx(x = x2)\nplot(c(y1, y2) ~ c(x1, x2), type = \"l\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint:\n\n\n\nNote novamente a descontinuidade de \\(f(x)\\) no ponto \\(x = 0\\).\n\n\n\n\n5.1.2 Funções parametrizadas\nPara os exercícios abaixo você deve fazer o gráfico como uma função de \\(x\\) com o parâmetro \\(\\theta\\) fixado. Tenha cuidado tanto com o domínio de \\(f(x)\\) quanto com o espaço paramétrico de \\(\\theta\\), ou seja, o conjunto de valores que \\(\\theta\\) pode assumir. Para entender como o parâmetro controla a curva você deve desenhar o gráfico usando diversos valores para \\(\\theta\\).\n\n5.1.2.1 Considere a função \\(f(x; \\theta) = \\left( x \\log \\frac{x}{\\theta} - x + \\theta\\right)\\).\n\nImplemente a função e desenhe seu gráfico com \\(\\theta = 10\\).\n\n\nx &lt;- seq(0, 20,  l = 100)\nfx &lt;- function(x, theta) {\n  out &lt;- x*log(x/theta) - x + theta\n  return(out)\n}\ny &lt;- fx(x = x, theta = 10)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nQual é o domínio de \\(f(x)\\)?\n\n\nReais\nIntervalo (0,1)\nReais estritamente positivos\nNaturais\n\n\nQual é o espaço paramétrico de \\(\\theta\\)?\n\n\nReais\nIntervalo (0,1)\nReais estritamente positivos\nInteiros positivos\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para baixo.\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para baixo.\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para cima.\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para cima.\n\n\n\n5.1.2.2 Considere a função \\(f(x; \\theta) = \\binom{100}{x} \\exp \\left\\{x \\log \\frac{\\theta}{1-\\theta} +100 \\log(1 - \\theta) \\right\\}\\).\n\nImplemente a função e desenhe seu gráfico considerando \\(\\theta = 0.40\\).\n\n\nx &lt;- 0:100\nfx &lt;- function(x, theta) {\n  out &lt;- choose(n = 100, k = x) * exp(x * log(theta/(1-theta)) + 100*log(1- theta))\n  return(out)\n}\ny &lt;- fx(x = x, theta = 0.4)\nbarplot(y ~ x)\n\n\n\n\n\n\n\n\n\nQual é o domínio de \\(f(x)\\)?\n\n\nReais\nIntervalo (0,1)\nInteiros (0, 100)\nInteiros de [0, 100]\n\n\nQual é o espaço paramétrico de \\(\\theta\\)?\n\n\nReais ✗\nIntervalo (0,1) ✓\nReais estritamente positivos ✗\nReais estritamente negativo ✗\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para baixo. ✗\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para baixo. ✓\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para cima. ✗\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para cima. ✗\n\n\n\n5.1.2.3 Considere a função \\(f(x; \\theta) = \\sum_{i=1}^n \\left( \\frac{x_i}{\\theta} -\\log \\left\\{ \\frac{x_i}{\\theta} \\right \\} -1 \\right )\\).\n\nImplemente a função e desenhe seu gráfico considerando \\(\\theta = 10\\).\n\n\nfx &lt;- function(x, theta) {\n  out &lt;- (x/theta) - log(x/theta) - 1\n  return(out)\n}\nx &lt;- seq(5, 15, l = 100)\ny &lt;- fx(x = x, theta = 10)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nQual é o domínio de \\(f(x)\\)?\n\n\nReais ✗\nIntervalo (0,1) ✗\nReais estritamente positivos ✓\nIntervalo (0,2π] ✗\n\n\nQual é o espaço paramétrico de \\(\\theta\\)?\n\n\nReais ✗\nIntervalo (0,1) ✗\nReais estritamente positivos ✓\nIntervalo (0,2π] ✗\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para baixo.\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para baixo.\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para cima.\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para cima.\n\n\n\n5.1.2.4 Considere a função \\(f(x; \\theta) = (1 - \\cos(x - \\theta))\\).\n\nImplemente a função e desenhe seu gráfico considerando \\(\\theta = 2\\).\n\n\nfx &lt;- function(x, theta) {\n  out &lt;- (1 - cos(x - theta))\n  return(out)\n}\nx &lt;- seq(0, 2*pi, l = 100)\ny &lt;- fx(x = x, theta = 2)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nEntre as opções abaixo para o domínio de \\(f(x)\\) qual garante que \\(f(x)\\) tenha apenas um mínimo relativo?\n\n\nReais ✗\nInteiros ✗\nReais estritamente positivos ✗\nIntervalo (0,2π] ✓\n\n\nConsiderando b) qual é o espaço paramétrico de \\(\\theta\\)?\n\n\nReais ✗\nIntervalo (0,1) ✗\nReais estritamente positivos ✗\nIntervalo (0,2π] ✓\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para baixo. ✗\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para baixo. ✗\nO parâmetro indica o ponto de minimo relativo e a curva é côncava para cima. ✓\nO parâmetro indica o ponto de máximo relativo e a curva é côncava para cima. ✗\n\n\n\n5.1.2.5 Considere a função \\(f(x; \\theta, p) = 2\\left \\{ \\frac{x^{(2-p)}}{(1-p)(2-p)} - \\frac{x \\theta^{(1-p)}}{1-p} + \\frac{\\theta^{(2-p)}}{2-p} \\right \\}\\).\n\nImplemente a função e desenhe seu gráfico considerando \\(\\theta = 5\\) e \\(p = 1.5\\).\n\n\nfx &lt;- function(x, theta, p) {\n  term1 &lt;- ( x^(2-p) )/( (1-p)*(2-p) )\n  term2 &lt;- (x*(theta^(1-p)))/(1-p)\n  term3 &lt;- (theta^(2-p))/(2-p)\n  out &lt;- 2*(term1 - term2 + term3)\n  return(out)\n}\nx &lt;- seq(0, 20, l = 100)\ny &lt;- fx(x = x, theta = 5, p = 1.5)\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n\n\nQual é o domínio de \\(f(x)\\)?\n\n\nReais ✗\nInteiros ✗\nReais estritamente positivos ✓\nIntervalo (0,2π]. ✗\n\n\nQual o espaço paramétrico de \\(\\theta\\) e \\(p\\)?\n\n\n\\(\\theta\\) é real e \\(p\\) é estritamente positivo. ✗\nIntervalo (0,1) para ambos ✗\n\\(\\theta\\) é real e \\(p \\in (1,2)\\). ✗\n\\(\\theta\\) é real estritamente positivo e \\(p \\in (1,2)\\) ✓\n\n\nSobre o comportamento do gráfico de \\(f(x)\\) marque a alternativa correta.\n\n\nO parâmetro \\(\\theta\\) indica o ponto de minimo relativo e a curva é côncava para baixo. ✗\nO parâmetro \\(\\theta\\) indica o ponto de máximo relativo e a curva é côncava para baixo. ✗\nO parâmetro \\(\\theta\\) indica o ponto de minimo relativo e a curva é côncava para cima. ✓\nO parâmetro \\(\\theta\\) indica o ponto de máximo relativo e a curva é côncava para cima. ✗\n\n\n\n\n5.1.3 Limites\n\n5.1.3.1 Considere a seguinte função \\(f(x) = \\sqrt{x} + x\\).\n\nEsboce o gráfico e marque o ponto \\(x = 0\\).\n\n\nx &lt;- seq(0, 2,  l = 100)\nfx &lt;- function(x) {\n  out &lt;- sqrt(x) + x\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = 0, y = fx(x = 0), pch = 18)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to 0 } ( \\sqrt{x} + x)\\).\n\n\n-2 ✗\n4 ✗\n0 ✓\n6/5 ✗\n1 ✗\n\n\n\n5.1.3.2 Considere a seguinte função \\(f(x) = \\frac{x^2 + x}{ x + 3}\\).\n\nEsboce o gráfico e marque o ponto \\(x = 2\\).\n\n\nx &lt;- seq(0, 4,  l = 100)\nfx &lt;- function(x) {\n  out &lt;- (x^2 + x)/(x + 3)\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = 2, y = fx(x = 2), pch = 18)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to 2 } \\frac{x^2 + x}{ x + 3}\\).\n\n\n6/5 ✓\n4 ✗\n-2 ✗\n1 ✗\n6 ✗\n\n\n\n5.1.3.3 Considere a seguinte função \\(f(x) = \\frac{x^2 - 4}{x-2}\\).\n\nEsboce o gráfico e marque o ponto \\(x = 2\\).\n\n\nx &lt;- c(seq(1, 2, l = 50), 2, seq(2, 3, l = 50))\nfx &lt;- function(x) {\n  out &lt;- (x^2 - 4)/(x - 2)\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = 2, y = 4, pch = 1)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to 2 } \\frac{x^2 - 4}{x - 2}\\).\n\n\n-2 ✗\n4 ✓\n0 ✗\n6/5 ✗\n1 ✗\n\n\n\n5.1.3.4 Considere a seguinte função \\(f(x) = \\frac{x^2 - 1}{x + 1}\\).\n\nEsboce o gráfico e marque o ponto \\(x = -1\\).\n\n\nx &lt;- seq(-3, 0,  l = 100)\nfx &lt;- function(x) {\n  out &lt;- (x^2 - 1)/(x + 1)\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = -1, y = -2, pch = 1)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to -1 } \\frac{x^2 - 1}{x + 1}\\).\n\n\n-2 ✗\n4 ✓\n0 ✗\n6/5 ✗\n1 ✗\n\n\n\n5.1.3.5 Considere a seguinte função \\(f(x) = \\sin(x)\\).\n\nEsboce o gráfico e marque o ponto \\(x = 0\\).\n\n\nx &lt;- seq(-3, 3,  l = 100)\nfx &lt;- function(x) {\n  out &lt;- sin(x)\n  return(out)\n}\ny &lt;- fx(x = x)\nplot(y ~ x, type = \"l\")\npoints(x = 0, y = fx(x = 0), pch = 18)\n\n\n\n\n\n\n\n\n\nCalcule \\(\\lim_{x \\to 0 } \\sin(x)\\).\n\n\n-2 ✗\n4 ✗\n0 ✓\n6/5 ✗\n1 ✗\n\n\n\n\n5.1.4 Continuidade\nConsidere as seguintes funções:\n\n\\(f(x) = \\sqrt{x}\\) em \\(x = 0\\).\n\\(f(x) = \\frac{x^2 - 4}{x-2}\\) em \\(x = 2\\).\n\\(f(x) = \\left\\{\\begin{matrix} x \\quad \\text{se} \\quad x &lt; 1 \\\\ \\frac{1}{x} \\quad \\text{se} \\quad x &gt; 1 \\quad \\text{em} \\quad x = 1 \\end{matrix}\\right.\\)\n\\(f(x) = \\Gamma(x)\\) em \\(x = 2\\).\n\\(f(x) = \\frac{|x-2|}{x-2}\\) em \\(x = 2\\).\n\nUsando a definição intuitiva de limite marque a alternativa correta\n\na), b) e d) são contínuas. ✗\ne), b) e a) são contínuas. ✗\nb), c) e e) são não contínuas ✓\nb), c) e d) são não contínuas ✗\nApenas d) é não contínua. ✗\n\n\n\n5.1.5 Funções especiais\nIlustre computacionalmente cada uma das seguintes propriedades das funções do tipo potência.\n\n\\(x^a (x^c) = x^{a+c}\\);\n\\((x^a)^c = x^{ac}\\);\n\\((xz)^a = x^a (z^a)\\);\n\\(\\left ( \\frac{x}{z} \\right )^c = \\frac{x^c}{z^c}\\);\n\\(\\frac{1}{x^a} = x^{-a}\\);\n\\(\\frac{x^a}{x^c} = x^{a-c}\\);\n\\(\\sqrt{x} = x^{1/2}\\);\n\n\nx &lt;- 5\nz &lt;- 3\na &lt;- 2\nc &lt;- 4\nall.equal((x^a)*(x^c),x^(a+c))\n\n[1] TRUE\n\nall.equal((x^a)^c, x^(a*c))\n\n[1] TRUE\n\nall.equal((x*z)^a, (x^a) * (z^a))\n\n[1] TRUE\n\nall.equal(((x/z)^c), ((x^c)/(z^c)))\n\n[1] TRUE\n\nall.equal(1/(x^a) , x^(-a))\n\n[1] TRUE\n\nall.equal((x^a)/(x^c), x^(a-c))\n\n[1] TRUE\n\nall.equal(sqrt(x), x^0.5)\n\n[1] TRUE",
    "crumbs": [
      "Exercicios",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cálculo Diferencial e Integral para Cientista de Dados</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/Exercicios/index.html#derivadas",
    "href": "content/Modulo01/Exercicios/index.html#derivadas",
    "title": "5  Cálculo Diferencial e Integral para Cientista de Dados",
    "section": "5.2 Derivadas",
    "text": "5.2 Derivadas\nOs objetivos deste tutorial são:\n\nDerivar funções triviais.\nObter a equação da reta tangente a uma função.\nCálculo de derivadas usando a regra da cadeia.\nAproximar funções usando a expansão em séries de Taylor.\n\n\n5.2.1 Derivadas triviais\nPara cada uma das funções abaixo obtenha a sua derivada, implemente uma função chamada dx() que calcula a derivada obtida no ponto \\(x = 1/2\\) e retorna o seu valor. Para usar a correção automática a linha final do seu código deve ser dx(x = 1/2).\n\n\\(f(x) = x^4\\).\n\n\ndx &lt;- function(x) {4*x^3}\ndx(x = 1/2)\n\n[1] 0.5\n\n\n\n\\(f(x) = x^{-3}\\).\n\n\ndx &lt;- function(x) {-3/(x^4)}\ndx(x = 1/2)\n\n[1] -48\n\n\n\n\\(f(x) = \\sqrt[3]{x}\\).\n\n\ndx &lt;- function(x) {(1/3)*(x^(2/3))}\ndx(x = 1/2)\n\n[1] 0.2099868\n\n\n\n\\(f(x) = \\frac{1}{x}\\).\n\n\ndx &lt;- function(x) {-1/(x^2)}\ndx(x = 1/2)\n\n[1] -4\n\n\n\n\\(f(x) = \\sqrt[8]{x^2}\\).\n\n\ndx &lt;- function(x) {1/(4* x^(3/4))}\ndx(x = 1/2)\n\n[1] 0.4204482\n\n\n\n\\(f(x) = 4x^3 + x^2\\).\n\n\ndx &lt;- function(x) {12*x^2 + 2*x}\ndx(x = 1/2)\n\n[1] 4\n\n\n\n\\(f(x) = \\frac{2x + 3}{x^2 + 1}\\).\n\n\ndx &lt;- function(x) {\n  p1 &lt;- 2/(x^2 + 1)\n  p2 &lt;- (2*x*(2*x + 3))/(x^2 + 1)\n  return(p1 - p2)\n}\ndx(x = 1/2)\n\n[1] -1.6\n\n\n\n\\(f(x) = (3x^2 + 1) \\exp(x)\\).\n\n\ndx &lt;- function(x) {\n  out &lt;- (3*x^2 + 1)*exp(x) + 6*x*exp(x)\n  return(out)\n}\ndx(x = 1/2)\n\n[1] 7.831426\n\n\n\n\\(f(x) = 5x^4 + 6x^3 + x^2 + 2\\).\n\n\ndx &lt;- function(x) {\n  out &lt;- 20*x^3 + 18*x^2 + 2*x\n  return(out)\n}\ndx(x = 1/2)\n\n[1] 8\n\n\n\n\\(f(x) = \\log(x) 3x^4\\).\n\n\ndx &lt;- function(x) {\n  out &lt;- 12*x^3 * log(x) + 3*x^3\n  return(out)\n}\ndx(x = 1/2)\n\n[1] -0.6647208\n\n\n\n\n5.2.2 Reta tangente\nPara cada uma das funções abaixo obtenha a reta tangente a \\(f(x)\\) e esboce o gráfico. Para usar a correção aumotmática a última linha do seu código deve retornar o intercepto e a inclinação da reta tangente da seguinte forma resultado = c(intercepto, inclinacao).\n\n\\(f(x) = \\frac{1}{x}\\) em \\(x = 2\\).\n\n\n# Função\nfx &lt;- function(x) {\n  1/x\n}\n# Derivada da função\ndx &lt;- function(x) {\n -1/x^2 \n}\n# Reta tangente\nreta_tangente &lt;- function(a) {\n  intercept = (fx(x = a) - dx(x = a)*a)\n  slope &lt;- dx(x = a)\n  return(c(intercept,slope))\n}\n# Gráfico da função\nx &lt;- seq(1, 3, l = 100) ## Sequencia definindo o eixo x\nplot(fx(x) ~ x, type = \"l\") ## Desenhando a função\n\n## Reta tangente ao ponto a = 2\nreta1 &lt;- reta_tangente(a  = 2)\nintercepto = reta1[1]\ninclinacao &lt;- reta1[2]\nlines(x, c(intercepto + inclinacao*x))\n\n\n\n\n\n\n\nresultado &lt;- c(intercepto, inclinacao)\n\n\n\\(f(x) = x^3\\) em \\(x = 3\\).\n\n\n# Função\nfx &lt;- function(x) {\n  x^3\n}\n# Derivada da função\ndx &lt;- function(x) {\n 3*x^2 \n}\n# Reta tangente\nreta_tangente &lt;- function(a) {\n  intercept = (fx(x = a) - dx(x = a)*a)\n  slope &lt;- dx(x = a)\n  return(c(intercept,slope))\n}\n# Gráfico da função\nx &lt;- seq(1, 5, l = 100) ## Sequencia definindo o eixo x\nplot(fx(x) ~ x, type = \"l\") ## Desenhando a função\n\n## Reta tangente ao ponto a = 2\nreta1 &lt;- reta_tangente(a  = 3)\nintercepto = reta1[1]\ninclinacao &lt;- reta1[2]\nlines(x, c(intercepto + inclinacao*x))\n\n\n\n\n\n\n\nresultado &lt;- c(intercepto, inclinacao)\n\n\n\\(f(x) = \\exp(x)\\) em \\(x = 0\\).\n\n\n# Função\nfx &lt;- function(x) {\n  exp(x)\n}\n# Derivada da função\ndx &lt;- function(x) {\n exp(x) \n}\n# Reta tangente\nreta_tangente &lt;- function(a) {\n  intercept = (fx(x = a) - dx(x = a)*a)\n  slope &lt;- dx(x = a)\n  return(c(intercept,slope))\n}\n# Gráfico da função\nx &lt;- seq(-3, 2, l = 100) ## Sequencia definindo o eixo x\nplot(fx(x) ~ x, type = \"l\") ## Desenhando a função\n\n## Reta tangente ao ponto a = 2\nreta1 &lt;- reta_tangente(a  = 0)\nintercepto = reta1[1]\ninclinacao &lt;- reta1[2]\nlines(x, c(intercepto + inclinacao*x))\n\n\n\n\n\n\n\nresultado &lt;- c(intercepto, inclinacao)\n\n\n\\(f(x) = \\log(x)\\) em \\(x = 2\\).\n\n\n# Função\nfx &lt;- function(x) {\n  log(x)\n}\n# Derivada da função\ndx &lt;- function(x) {\n 1/x \n}\n# Reta tangente\nreta_tangente &lt;- function(a) {\n  intercept = (fx(x = a) - dx(x = a)*a)\n  slope &lt;- dx(x = a)\n  return(c(intercept,slope))\n}\n# Gráfico da função\nx &lt;- seq(0.5, 4, l = 100) ## Sequencia definindo o eixo x\nplot(fx(x) ~ x, type = \"l\") ## Desenhando a função\n\n## Reta tangente ao ponto a = 2\nreta1 &lt;- reta_tangente(a  = 2)\nintercepto = reta1[1]\ninclinacao &lt;- reta1[2]\nlines(x, c(intercepto + inclinacao*x))\n\n\n\n\n\n\n\nresultado &lt;- c(intercepto, inclinacao)\n\n\n\n5.2.3 Regra da cadeia\nPara cada uma das funções abaixo obtenha a sua derivada, implemente uma função chamada dx() que calcula a derivada obtida no ponto \\(x = 2\\) e retorna o seu valor. Para usar a correção automática a linha final do seu código deve ser dx(x = 2).\n\n\\(f(x) = \\exp{3x}\\).\n\n\ndx &lt;- function(x) {3*exp(3*x)}\ndx(x = 2)\n\n[1] 1210.286\n\n\n\n\\(f(x) = \\sin(x^2)\\).\n\n\ndx &lt;- function(x) {2*x*cos(x^2)}\ndx(x = 2)\n\n[1] -2.614574\n\n\n\n\\(f(x) = (3x^2 + 1)^3\\).\n\n\ndx &lt;- function(x) {18*x*(3*x^2 + 1)^2}\ndx(x = 2)\n\n[1] 6084\n\n\n\n\\(f(x) = \\log(x^2 + 3)\\).\n\n\ndx &lt;- function(x) {2*x/(x^2 + 3)}\ndx(x = 2)\n\n[1] 0.5714286\n\n\n\n\\(f(x) = x^2 \\exp(3x)\\).\n\n\ndx &lt;- function(x) {3*(x^2)*exp(3*x) + 2*x*exp(3*x)}\ndx(x = 2)\n\n[1] 6454.861\n\n\n\n\\(f(x) = \\log(x^2 + 3x + 9)\\).\n\n\ndx &lt;- function(x) {(2*x + 3)/(x^2 + 3*x + 9)}\ndx(x = 2)\n\n[1] 0.3684211\n\n\n\n\\(f(x) = \\sqrt{x + \\exp(x)}\\).\n\n\ndx &lt;- function(x) {(exp(x) + 1)/(2*sqrt(exp(x) + x))}\ndx(x = 2)\n\n[1] 1.368901\n\n\n\n\n5.2.4 Aproximação por Série de Taylor\nAproxime as seguintes funções usando a expansão de Taylor de segunda ordem. Esboce o gráfico da função e da aproximação. Note que \\(y_i\\) é constante nos valores informados e que a aproximação deve ser feita em relação a \\(\\mu\\). Pode fixar como ponto de referência para a aproximação \\(\\mu_0\\) a média dos \\(y_i\\)’s. Para usar a correção automática você deve avaliar a aproximação de Taylor em cada valor de \\(y_i\\) fornecido.\n\n\\(f(\\mu; \\boldsymbol{y}) = \\sum_{i=1}^n (y_i - \\mu)^2\\). Fixe \\(y_i = 2.09;-1.32;-0.20;0.05;-0.07\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(2.09, -1.32, -0.20, 0.05, -0.07)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {sum( (y - mu)^2) }\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {-2*sum(y-mu)}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {2*length(y)}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, min(y), max(y), ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(min(y), max(y), l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 25.6994 16.3219  6.5779  6.1154  6.2594\n\n\n\n\\(f(\\mu; \\boldsymbol{y}) = \\sum_{i=1}^n 2 \\left ( y_i \\log \\frac{y_i}{\\mu} + \\mu - y_i \\right )\\). Fixe \\(y_i = 7;4;4;6;5\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(7, 4, 4, 6, 5)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {sum(2*(y*log(y/mu) + mu - y) )}\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {sum(2*(1 - y/mu))}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {sum(2*y/mu^2)}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, min(y), max(y), ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(min(y), max(y), l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 4.404081 2.673311 2.673311 1.904081 1.327158\n\n\n\n\\(f(\\mu; \\boldsymbol{y}) = \\sum_{i=1}^n 2 \\left ( \\frac{y_i}{\\mu} - \\log \\frac{y_i}{\\mu} - 1 \\right )\\). Fixe \\(y_i = 2.35;0.16;0.56;1.05;0.51\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(2.35, 0.16, 0.56, 1.05, 0.51)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {sum(2*((y/mu) - log(y/mu) -1 ))}\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {sum( 2*( (1/mu) - y/(mu^2) ))}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {sum( 2*( (2*y/mu^3) - 1/(mu^2)))}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, min(y), max(y), ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(min(y), max(y), l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 15.420365  7.017681  4.377374  3.685926  4.605369\n\n\n\n\\(f(\\mu; \\boldsymbol{y}) = \\sum_{i=1}^n 2 \\left ( y_i \\log \\frac{y_i}{\\mu} + (1- y_i) \\log \\frac{1-y_i}{1-\\mu} \\right )\\). Fixe \\(y_i = 1;0;0;1;1\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(1,0,0,1,1)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {\n  temp &lt;- c()\n  for(i in 1:length(y)) {\n    if(y[i] == 1) { temp[i] &lt;- y[i]*log(y[i]/mu) }\n    if(y[i] == 0) { temp[i] &lt;- (1-y[i])*log( (1-y[i])/(1-mu) ) }\n  }\n  return(sum(2*temp))\n}\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {sum(2*((1-y)/(1-mu) - y/mu ))}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {sum(2*( (y/mu^2) + (1-y)/(1-mu)^2))}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, 0.1, 0.9, ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(0.1, 0.9, l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 10.06345 14.23012 14.23012 10.06345 10.06345\n\n\n\n$f(; ) = _{i=1}^n 2 ( y_i + (m + y_i) ) $. Fixe \\(m = 10\\) e \\(y_i = 7;4;4;6;5\\).\n\n\n# Função genérica\ntaylor_ap &lt;- function(mu, mu0, f, f_prime, f_dprime) {\n  app &lt;- f(mu = mu0) + (mu - mu0)*f_prime(mu = mu0) + \n    (((mu - mu0)^2)/(2))*f_dprime(mu = mu0)\n  return(app)\n}\n\n# Dados do exercício\ny &lt;- c(7,4,4,6,5)\n\n# Ponto referencia da aproximação\nmu0 &lt;- mean(y)\n\n# Função a ser aproximada\nf &lt;- function(mu) {sum (2*( y*log(y/mu) + (10 + y)* log( (10+mu)/(10 + y) ))) }\nf &lt;- Vectorize(FUN = f, vectorize.args = \"mu\")\n# Primeira derivada da função a ser aproximada\nf_prime &lt;- function(mu) {sum(2*( (y+10)/(mu+10) - y/mu ))}\nf_prime &lt;- Vectorize(FUN = f_prime, vectorize.args = \"mu\")\n# Segunda derivada da função a ser aproximada\nf_dprime &lt;- function(mu) {sum((y/mu^2) - (y + 10)/(mu + 10)^2)}\nf_dprime &lt;- Vectorize(FUN = f_dprime, vectorize.args = \"mu\")\n# Grafico da aproximação\nplot(f, 1, 9, ylab = expression(f(mu)), xlab = expression(mu))\nxx &lt;- seq(1, 9, l = 100)\nlines(xx, taylor_ap(mu = xx, mu0 = mu0, f = f, f_prime = f_prime, \n                      f_dprime = f_dprime), col = \"red\", lty = 2, lwd = 2)\nlegend(\"topleft\", legend = c(\"True\",\"Taylor Aprx.\"), lty = c(1,2), lwd = c(1, 2), col = c(1,2))\n\n\n\n\n\n\n\ntaylor_ap(mu = y, mu0 = mean(y), f = f, f_prime = f_prime, f_dprime = f_dprime)\n\n[1] 1.8695894 1.3002574 1.3002574 1.0472210 0.8574436",
    "crumbs": [
      "Exercicios",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cálculo Diferencial e Integral para Cientista de Dados</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/Exercicios/index.html#integrais",
    "href": "content/Modulo01/Exercicios/index.html#integrais",
    "title": "5  Cálculo Diferencial e Integral para Cientista de Dados",
    "section": "5.3 Integrais",
    "text": "5.3 Integrais\nOs objetivos deste tutorial são:\n\nObtenção de integrais indefinidas simples.\nCálculo de área abaixo de curvas (integrais definidas)\nUso de funções do Rpara o cálculo de integrais.\n\n\n5.3.1 Integrais indefinidas\nCalcule cada uma das integrais abaixo e implemente uma função chamada integral() que calcula a integral obtida considerando a constante \\(c = 0\\) e retorna o seu valor. Para usar a correção automática a linha final do seu código deve ser integral(x = 2).\n\n\\(\\int x^3 dx\\).\n\n\nintegral &lt;- function(x) { (x^4)/4 }\nintegral(x = 2)\n\n[1] 4\n\n\n\n\\(\\int \\frac{1}{x^2} dx\\).\n\n\nintegral &lt;- function(x) { -1/x }\nintegral(x = 2)\n\n[1] -0.5\n\n\n\n\\(\\int \\frac{1}{x} + \\sqrt{x} dx\\).\n\n\nintegral &lt;- function(x) { log(x) + (2*x^(3/2))/3 }\nintegral(x = 2)\n\n[1] 2.578765\n\n\n\n\\(\\int \\exp^{-x} dx\\).\n\n\nintegral &lt;- function(x) { -exp(-x) }\nintegral(x = 2)\n\n[1] -0.1353353\n\n\n\n\\(\\int x + 3 \\exp^{x} dx\\).\n\n\nintegral &lt;- function(x) {3*exp(x) + (x^2)/2}\nintegral(x = 2)\n\n[1] 24.16717\n\n\n\n\n5.3.2 Integrais definidas\nObtenha as seguintes integrais definidas. Você pode obter a anti-derivada e avaliar a área ou usar a função integrate() do R. Para usar a correção automática a última linha do seu código deve ser area = valor ondelo valor é um valor (numérico).\n\n\\(\\int_{1}^2 x^2 dx\\).\n\n\nfx &lt;- function(x) {x^2}\ntemporario &lt;- integrate(f = fx, lower = 1, upper = 2)\narea &lt;- as.numeric(temporario$value)\n\n\n\\(\\int_{0}^2 (x^3 + 3x -1) dx\\).\n\n\nfx &lt;- function(x) {x^3 + 3*x - 1}\ntemporario &lt;- integrate(f = fx, lower = 0, upper = 2)\narea &lt;- as.numeric(temporario$value)\n\n\n\\(\\int_{-150}^{150} \\exp \\left\\{ -\\frac{(x - 5)^2}{2}   \\right \\} dx\\).\n\n\nfx &lt;- function(x) {exp( - ((x - 5)^2)/2 )}\ntemporario &lt;- integrate(f = fx, lower = -150, upper = 150)\narea &lt;- as.numeric(temporario$value)\n\n\n\\(\\int_{0}^{100} \\exp \\left\\{ -\\frac{|x - 5|}{2}   \\right \\} dx\\).\n\n\nfx &lt;- function(x) {exp(-abs(x - 5)/2 )}\ntemporario &lt;- integrate(f = fx, lower = 0, upper = 150)\narea &lt;- as.numeric(temporario$value)\n\n\n\\(\\int_{1}^{2}  \\left(\\frac{1}{x} + \\frac{1}{x^3}   \\right \\} dx\\).\n\n\nfx &lt;- function(x) {(1/x + 1/x^3)}\ntemporario &lt;- integrate(f = fx, lower = 1, upper = 2)\narea &lt;- as.numeric(temporario$value)",
    "crumbs": [
      "Exercicios",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cálculo Diferencial e Integral para Cientista de Dados</span>"
    ]
  },
  {
    "objectID": "content/Modulo01/Exercicios/index.html#desafios",
    "href": "content/Modulo01/Exercicios/index.html#desafios",
    "title": "5  Cálculo Diferencial e Integral para Cientista de Dados",
    "section": "5.4 Desafios",
    "text": "5.4 Desafios\nOs próximos dois exercícios são desafios. Não apresento nenhuma solução a ideia é vocês tentarem resolver usando quaisquer meios. Isso inclue procurar soluções na internet, discutir com os colegas, postar em grupos etc. Se você chegar em uma solução que queira compartilhar comigo pode me mandar a solução por e-mail.\n\n5.4.1 Redução de dados usando perda absoluta\n\n5.4.1.1 Sejam \\(y_i\\) valores observados para \\(i = 1, \\ldots, n\\). Considere a função perda absoluta dada por\n\\[f(\\mu; \\mathbf{y}) = \\sum_{i=1}^n |y_i - \\mu|.\\]\n\nSimule um conjunto de valores adequado para \\(y_i\\).\nEsboce o gráfico da função perda para este conjunto de dados e diferentes valores de \\(\\mu\\).\nEncontre o valor de \\(\\mu\\) que minimiza a função perda absoluta.\nDiscuta quando a função perda absoluta pode ser mais conveniente do que a função perda quadrática.\n\n\n\n\n5.4.2 Regressão linear simples usando perda absoluta\nSejam \\(y_i\\) e \\(x_i\\) valores observados para \\(i = 1, \\ldots, n\\). Considere o problema de ajustar um reta relacionando \\(y_i\\) com \\(x_i\\), usando a função perda absoluta\n\\[f(\\beta_0, \\beta_1) = \\sum_{i=1}^n |y_i - (\\beta_0 + \\beta_1 x_i)|.\\]\n\nSimule um conjunto de valores adequado para \\(y_i\\) fixado um vetor de \\(x_i\\).\nEsboce o gráfico da função perda para o conjunto de dados simulado.\nEncontre o valor de \\(\\beta_0\\) e \\(\\beta_1\\) que miniza a função perda absoluta.\nDiscuta quando a função perda absoluta pode ser mais conveniente do que a função perda quadrática para o ajuste deste modelo.",
    "crumbs": [
      "Exercicios",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Cálculo Diferencial e Integral para Cientista de Dados</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#vetores-e-escalares",
    "href": "content/Modulo02/index.html#vetores-e-escalares",
    "title": "2  Álgebra Matricial",
    "section": "",
    "text": "Definição 2.1\n\n\n\nUm vetor é uma lista de \\(n\\) números (elementos ou componentes) escritos em linha ou coluna.\n\n\n\n\n\n\n\n\n\n\n\n2.1.1 Operações com vetores\nDa mesma forma que podemos fazer operações soma, subtração, multiplicação e divisão com números (no contexto de Álgebra Linear são chamados de escalares) também podemos fazer operações com vetores. No entanto, nem todas as operações usuais de escalares são válidas para vetores. De forma geral, vetores podem ser somados, subtraídos e multiplicados de forma especial. Porém, vetores não podem ser divididos e existem algumas operações especiais com vetores como o produto interno. Dois vetores podem ser somados ou subtraídos apenas se forem do mesmo tipo (linha ou coluna) e do mesmo tamanho. Para definirmos as operações com vetores, considere dois vetores \\(\\mathbf{a}\\) e \\(\\mathbf{b}\\) adequados, ou seja, mesmo tipo e tamanho, e \\(\\alpha\\) um escalar, as seguintes operações são bem definidas:\n\nSoma: \\(\\mathbf{a} + \\mathbf{b} = (a_i + b_i) = (a_1 + b_1, \\ldots, a_n + b_n).\\)\nSubtração: \\(\\mathbf{a} - \\mathbf{b} = (a_i - b_i) = (a_1 - b_1, \\ldots, a_n - b_n).\\)\nMultiplicação por escalar: \\(\\alpha \\mathbf{a} = (\\alpha a_1, \\ldots, \\alpha a_n)\\).\nTransposta de um vetor: a operação transposta transforma um vetor coluna em um vetor linha e vice-versa. Por exemplo,\n\n\\[\n\\mathbf{a} = \\begin{pmatrix}\na_1 & \\ldots & a_n\n\\end{pmatrix} \\quad  \\quad \\mathbf{a}^{\\top} = \\begin{pmatrix}\na_1 \\\\\n\\vdots \\\\\na_n\n\\end{pmatrix}.\n\\]\n\nProduto interno ou escalar entre dois vetores resulta em um escalar:\n\n\\[\n\\mathbf{a} \\cdot \\mathbf{b} = (a_1 b_1 + a_2 b_2 + \\ldots + a_n b_n).\n\\]\nO co-seno do ângulo \\(\\theta\\) entre os vetores \\(\\mathbf{a}\\) e \\(\\mathbf{b}\\) é dado por:\n\\[\n\\begin{equation}    \n\\cos(\\theta)=\\frac{\\mathbf{a}^{\\top}\\mathbf{b}}{\\sqrt{\\mathbf{a}^{\\top}\\mathbf{a}}\\sqrt{\\mathbf{b}^{\\top}\\mathbf{b}}}.\n\\end{equation}\n\\]\nDizemos que dois vetores são ortogonais entre si se o ângulo \\(\\theta\\) entre eles é 90º o que implica que \\(\\cos(\\theta)=0\\) e que \\(\\mathbf{a}^{\\top} \\mathbf{b}=0\\). Todas as operações descritas para vetores são trivialmente definidas em R. Vamos ver alguns exemplos. Para declarar um vetor em R usamos a função c().\n\na &lt;- c(4,5,6)\nb &lt;- c(1,2,3)\n\nSendo os vetores compatíveis podemos facilmente somá-los, subtraí-los, multiplicar por um escalar ou obter o produto interno, conforme ilustrado no Código 2.1. Porém, cabe enfatizar que a divisão entre vetores não é definida.\nCódigo 2.1 Operações com vetores.\n\n## Soma\n\na + b\n\n[1] 5 7 9\n\n\n\n## Subtração\n\na - b\n\n[1] 3 3 3\n\n\n\n## Multiplicação por escalar\n\nalpha = 10\nalpha * a\n\n[1] 40 50 60\n\n\n\n## Produto interno\n\na %*% b\n\n     [,1]\n[1,]   32\n\n\nNeste ponto é importante falar sobre a lei da reciclagem em R e dos cuidados que devemos ter ao fazer operações com vetores.\nVamos definir dois vetores, \\(a\\) e \\(b\\), porém de tamanhos diferentes.\n\na &lt;- c(4,5,6,5,6,7)\nb &lt;- c(1,2,3)\n\na + b\n\n[1]  5  7  9  6  8 10\n\n\nNote que apesar dos vetores não serem compatíveis para a soma, o R realizou alguma operação. É neste ponto que aparece a lei da reciclagem. Veja que os três primeiros elementos do vetor resultante da soma de a + b são \\(4 + 1 = 5; 5 + 2 = 7\\) e \\(6 + 3 = 9\\). Porém, o R ainda reporta mais três números que são o resultado de \\(5 + 1 = 6; 6 + 2 = 8\\) e \\(7 + 3 = 10\\), ou seja, o R reciclou os elementos do vetor b para completar a tarefa de somar a + b. Portanto, é muito importante tomar cuidado ao fazer operações com vetores em R.\nUm outro ponto importante é a forma de fazer a multiplicação entre vetores. Veja o uso do operador especial %*% para a multiplicação entre vetores. O símbolo usual de multiplicação * não realiza a multiplicação vetorial, mas sim uma multiplicação elemento por elemento, também chamada de produto de Hadamard.\n\na &lt;- c(4,5,6)\nb &lt;- c(1,2,3)\n\n\n## Multiplicação elemento a elemento (Hadamard)\n\na*b\n\n[1]  4 10 18\n\n\n\n## Multiplicação entre vetores\n\na%*%b\n\n     [,1]\n[1,]   32\n\n\nUsando as operações com vetores podemos facilmente calcular o co-seno do ângulo \\(\\theta\\) entre dois vetores compatíveis.\n\ncos_theta &lt;- t(a)%*%b/(sqrt(t(a)%*%a)*sqrt(t(b)%*%b))\ncos_theta\n\n          [,1]\n[1,] 0.9746318",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Álgebra Matricial</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/index.html#matrizes",
    "href": "content/Modulo02/index.html#matrizes",
    "title": "2  Álgebra Matricial",
    "section": "2.2 Matrizes",
    "text": "2.2 Matrizes\n\n\n\n\n\n\nDefinição 2.2\n\n\n\nUma matriz é um arranjo retangular ou quadrado de números ou variáveis. Uma matriz \\((n \\times m)\\) tem \\(n\\) linhas e \\(m\\) colunas:\n\\[\n\\mathbf{A} = \\begin{pmatrix}\na_{11} & a_{12} & \\ldots & a_{1m} \\\\\na_{21} & a_{22} & \\ddots & a_{2m} \\\\\n\\vdots & \\vdots & \\ddots &  \\vdots \\\\\na_{n1} & \\ldots & \\ldots & a_{nm}\n\\end{pmatrix}.\n\\]\n\n\nEm termos de notação, nós vamos usar letras maiúsculas em negrito para representar uma matriz, por exemplo: \\(\\mathbf{A}\\). Neste livro os elementos de uma matriz serão números reais ou variáveis representando números reais. Por exemplo, a matriz \\(\\mathbf{A}\\) representa as notas e o número de faltas de três alunos do curso de estatística básica. Cada linha representa um aluno, a primeira coluna a nota e a segunda o número de faltas.\n\\[\n\\mathbf{A} = \\begin{pmatrix}\n80 & 0 \\\\\n95 & 1 \\\\\n70 & 5\n\\end{pmatrix}.\n\\]\nPara representar os elementos da matriz como variáveis ou incógnitas, usamos letras minúsculas, por exemplo,\n\\[\n\\mathbf{A} = \\begin{pmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22} \\\\\na_{31} & a_{32}\n\\end{pmatrix}.\n\\]\nVamos adotar que o primeiro subscrito representa linha e o segundo a coluna do elemento, ou seja, \\(a_{\\text{linha}\\;\\text{coluna}}\\). Assim, podemos representar a matriz também por meio dos seus elementos, \\(\\mathbf{A} = a_{ij}\\) para \\(i=1, \\ldots, n\\) e \\(j=1, \\ldots, m\\) onde \\(n\\) e \\(m\\) são o número de linhas e colunas da matriz, respectivamente. Para o exemplo dos alunos, temos \\(n = 3\\) e \\(m = 2\\). É comum referenciar uma matriz pela sua dimensão ou tamanho, ou seja, o número de linhas e colunas. Dizemos, então que \\(\\mathbf{A}\\) tem dimensão \\(n \\times m\\), leia-se “A matriz \\(\\mathbf{A}\\) tem dimensão \\(n\\) por \\(m\\).” Particularizando para o nosso exemplo \\(\\mathbf{A}\\) é \\(3 \\times 2\\). Note que um vetor é simplesmente uma matriz com apenas uma linha ou uma coluna. De forma similar, podemos pensar que um escalar é apenas uma matriz de dimensão \\(1 \\times 1\\). No entanto, um escalar é tecnicamente diferente de uma matriz \\(1 \\times 1\\) em termos de aplicações e propriedades em Álgebra Linear. Tais diferenças ficarão claras no decorrer do Capítulo. Dizemos que duas matrizes são iguais se tem a mesma dimensão e se os elementos das correspondentes posições são iguais. A operação de transpor também é definida para matrizes de forma similar ao realizado para vetores. Assim, a operação de transposição rearranja uma matriz de forma que suas linhas são transformadas em colunas e vice-versa. Considere o exemplo,\n\\[\n\\begin{pmatrix}\n1 & 2\\\\\n3 & 4\\\\\n5 & 6\n\\end{pmatrix}^{\\top} =\n\\begin{pmatrix}\n1 & 3 & 5\\\\\n2 & 4 & 6\n\\end{pmatrix}.\n\\]\nAlém disso, é claro que \\((\\mathbf{A}^{\\top})^{\\top} = \\mathbf{A}\\), ou seja, a transposta da transposta de uma matriz é a matriz original. Para definir uma matriz em R usamos o comando matrix() que permite rearranjar um vetor em uma matriz. O Código 2.2 define uma matriz \\(3 \\times 2\\) em R.\nCódigo 2.2 Inicialização de uma matriz.\n\na &lt;- c(1,2,3,4,5,6)\nA &lt;- matrix(a, nrow = 3, ncol = 2)\n\nA\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n\nPor default  o R vai preencher a matriz por coluna. Assim, os primeiros três valores do vetor formam a primeira coluna, enquanto que os três últimos formam a segunda coluna. Os argumentos nrow e ncol definem o número de linhas e colunas da matriz resultante. É possível também preencher a matriz por linhas, caso seja de interesse. Neste caso usamos o argumento byrow = TRUE.\n\nA &lt;- matrix(a, nrow = 3, ncol = 2, byrow = TRUE)\nA\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\n\nA transposição de uma matriz ou vetor é realizada pela função t(), conforme ilustrado no Código 2.3.\nCódigo 2.3 Transposta de uma matriz.\n\n## Transposta de uma matriz\n\nt(A)\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n\n\n2.2.1 Operações com matrizes\nAlgumas operações entre matrizes e vetores também são definidas. Qualquer escalar pode ser multiplicado por qualquer matriz da seguinte forma:\n\\[\n\\alpha \\mathbf{A} = \\begin{pmatrix}\n\\alpha a_{11} & \\alpha a_{12} & \\ldots & \\alpha a_{1m} \\\\\n\\alpha a_{21} & \\alpha a_{22} & \\ddots & \\alpha a_{2m} \\\\\n\\vdots & \\vdots & \\ddots &  \\vdots \\\\\n\\alpha a_{n1} & \\ldots & \\ldots & \\alpha a_{nm}\n\\end{pmatrix}.\n\\]\nEm palavras, multiplicar um escalar por uma matriz é simplesmente multiplicar cada entrada da matriz pelo escalar de interesse. O resultado é uma matriz de mesma dimensão da matriz original. Note ainda que \\(\\alpha \\mathbf{A} = \\mathbf{A} \\alpha\\). O código 2.4 ilustra tal operação em R.\nCódigo 2.4 Multiplicação de escalar por matriz.\n\nA &lt;- matrix(c(1,2,3,4,5,6), nrow = 3, ncol = 2)\nalpha &lt;- 10\nalpha*A\n\n     [,1] [,2]\n[1,]   10   40\n[2,]   20   50\n[3,]   30   60\n\n\nDuas matrizes podem ser somadas ou subtraídas somente se tiverem o mesmo tamanho. O resultado da soma ou subtração de duas matrizes \\(\\mathbf{A}\\) e \\(\\mathbf{B}\\) ambas \\((n \\times m)\\) é uma matriz \\(\\mathbf{C}\\) de mesmo tamanho cujos elementos são dados por:\n\nSoma \\(c_{ij} = a_{ij} + b_{ij}.\\)\nSubtração \\(c_{ij} = a_{ij} - b_{ij}.\\)\n\nPor exemplo,\n\\[\n\\begin{pmatrix}\n1 & 2\\\\\n3 & 4\\\\\n5 & 6\n\\end{pmatrix} + \\begin{pmatrix}\n10 & 20\\\\\n30 & 40 \\\\\n50 & 60\n\\end{pmatrix} =\n\\begin{pmatrix}\n11 & 22\\\\\n33 & 44\\\\\n55 & 66\n\\end{pmatrix}.\n\\]\nO Código 2.5 ilustra a soma de matrizes em R.\nCódigo 2.5 Soma de matrizes.\n\nA &lt;- matrix(c(1,2,3,4,5,6), nrow = 3, ncol = 2)\nB &lt;- matrix(c(10,20,30,40,50,60), nrow = 3, ncol = 2)\nC = A + B\n\nC\n\n     [,1] [,2]\n[1,]   11   44\n[2,]   22   55\n[3,]   33   66\n\n\nA multiplicação \\(\\mathbf{C} = \\mathbf{A} \\mathbf{B}\\) é definida apenas quando o número de colunas de \\(\\mathbf{A}\\) é igual ao número de linhas de \\(\\mathbf{B}\\). \\(\\underset{m \\times n}{\\mathbf{C}} = \\underset{m \\times q}{\\mathbf{A}} \\underset{q \\times n}{\\mathbf{B}}\\). Cada elemento \\(c_{ij} = \\sum_{k = 1}^q a_{ik} b_{kj}.\\)\nPor exemplo,\n\\[\n\\begin{pmatrix}\n2 & -1\\\\\n8 & 3\\\\\n6 & 7\n\\end{pmatrix} \\begin{pmatrix}\n4 & 9 & 1 & -3\\\\\n-5 & 2 & 4 & 6\n\\end{pmatrix} =\n\\]\n\\[\n\\begin{pmatrix}\n(2 \\cdot 4 + -1 \\cdot-5) & (2\\cdot 9 + -1 \\cdot 2) & (2\\cdot1 + -1 \\cdot 4) & (2 \\cdot -3 + -1 \\cdot 6) \\\\\n(8\\cdot 4 + 3 \\cdot -5) & (8\\cdot 9 + 3 \\cdot 2)  & (8 \\cdot 1 + 3 \\cdot 4) & (8 \\cdot -3 + 3 \\cdot 6) \\\\\n(6\\cdot4 + 7\\cdot -5) & (6 \\cdot 9 + 7 \\cdot 2)  & (6 \\cdot 1 + 7 \\cdot 4) & (6 \\cdot - 3 + 7 \\cdot 6)\n\\end{pmatrix} =\n\\]\n\\[\n\\begin{pmatrix}\n13 & 16 & -2 & -12\\\\\n17 & 78 & 20 & -6\\\\\n-11 & 68 & 34 & 24\n\\end{pmatrix}.\n\\]\nO Código 2.6 ilustra a multiplicação de matrizes em R. Novamente note o uso do operador especial %*% ao invés do símbolo usual de multiplicação *.\nCódigo 2.6 Multiplicação de matrizes.\n\nA &lt;- matrix(c(2,8,6,-1,3,7), nrow = 3, ncol = 2)\nB &lt;- matrix(c(4,-5,9,2,1,4,-3,6), nrow = 2, ncol = 4)\nC = A%*%B\n\nC\n\n     [,1] [,2] [,3] [,4]\n[1,]   13   16   -2  -12\n[2,]   17   78   20   -6\n[3,]  -11   68   34   24\n\n\nEm geral \\(\\mathbf{A} \\mathbf{B} \\neq \\mathbf{B} \\mathbf{A}\\). Veja que no caso das matrizes do exemplo anterior \\(\\mathbf{B}\\) tem dimensão \\(2\\times 4\\), enquanto \\(\\mathbf{A}\\) tem dimensão \\(3 \\times 2\\), e portanto o produto não pode ser feito. Apenas como ilustração o Código 2.7 tenta realizar a multiplicação entre duas matrizes não compatíveis.\nCódigo 2.7 Multiplicação de matrizes não compatíveis.\n\nB %*% A\n\nError in B %*% A: argumentos não compatíveis\n\n\nNeste caso o R retorna uma mensagem de erro indicando que as matrizes não são compatíveis para multiplicação. Algumas propriedades da multiplicação de matrizes são apresentadas a seguir. Sendo \\(\\mathbf{A}, \\mathbf{B}, \\mathbf{C}\\) e \\(\\mathbf{D}\\) compatíveis temos,\n\n\\(\\mathbf{A} + \\mathbf{B} = \\mathbf{B} + \\mathbf{A}\\).\n\\((\\mathbf{A} + \\mathbf{B}) + \\mathbf{C} = \\mathbf{A} + (\\mathbf{B} + \\mathbf{C}).\\)\n\\(\\alpha (\\mathbf{A} + \\mathbf{B}) = \\alpha \\mathbf{A} + \\alpha \\mathbf{B}.\\)\n\\((\\alpha + \\beta) \\mathbf{A} = \\alpha \\mathbf{A} + \\beta \\mathbf{A}.\\)\n\\(\\alpha(\\mathbf{A}\\mathbf{B}) = (\\alpha \\mathbf{A})\\mathbf{B} = \\mathbf{A}(\\alpha \\mathbf{B}).\\)\n\\(\\mathbf{A}(\\mathbf{B} \\pm \\mathbf{C}) = \\mathbf{A}\\mathbf{B} \\pm \\mathbf{A}\\mathbf{C}.\\)\n\\((\\mathbf{A} \\pm \\mathbf{B})\\mathbf{C} = \\mathbf{A}\\mathbf{C} \\pm \\mathbf{B}\\mathbf{C}.\\)\n\\((\\mathbf{A} - \\mathbf{B})(\\mathbf{C} - \\mathbf{D}) = \\mathbf{A}\\mathbf{C} - \\mathbf{B}\\mathbf{C} - \\mathbf{A}\\mathbf{D} + \\mathbf{B}\\mathbf{D}.\\)\n\nDuas propriedades interessantes envolvendo transposta e multiplicação de matrizes são:\n\nSe \\(\\mathbf{A}\\) é \\(n \\times m\\) e \\(\\mathbf{B}\\) é \\(m \\times n\\), então\n\n\\[\n(\\mathbf{A} \\mathbf{B})^{\\top} = \\mathbf{B}^{\\top} \\mathbf{A}^{\\top}.\n\\]\n\nDe maneira similar, se \\(\\mathbf{A}, \\mathbf{B}\\) e \\(\\mathbf{C}\\) são compatíveis\n\n\\[\n(\\mathbf{A} \\mathbf{B} \\mathbf{C} )^{\\top} = \\mathbf{C}^{\\top} \\mathbf{B}^{\\top} \\mathbf{A}^{\\top}.\n\\]\nNeste momento estamos aptos a fazer a distinção entre escalar e uma matriz \\(1 \\times 1\\). Considere que \\(\\mathbf{a}\\) é uma matriz \\(1 \\times 1\\). O produto de um escalar (\\(\\alpha\\)) por uma matriz está definido para qualquer matriz. Entretanto, uma matriz \\(1 \\times 1\\) só pode ser multiplicada por um vetor \\(\\mathbf{b}\\) (\\(1 \\times n\\), vetor linha) pela direita, ou seja, \\(\\mathbf{a} \\mathbf{b}\\) ou pela esquerda por um vetor \\(\\mathbf{b}\\) (\\(n \\times 1\\), vetor coluna) pela esquerda \\(\\mathbf{b} \\mathbf{a}\\). O Código 2.8 ilustra esta situação.\nCódigo 2.8 Ilustração da diferença entre escalar e matriz \\(1 \\times 1\\).\n\nalpha &lt;- 10\na &lt;- matrix(10, nrow = 1, ncol = 1)\nb &lt;- matrix(c(1,2,3,4), nrow = 1, ncol = 4)\n\ndim(a) # Dimensão de a\n\n[1] 1 1\n\n\n\ndim(b) ## Dimensão de b\n\n[1] 1 4\n\n\n\na%*%b # Compatível\n\n     [,1] [,2] [,3] [,4]\n[1,]   10   20   30   40\n\n\n\nb%*%a ## Não compatível\n\nError in b %*% a: argumentos não compatíveis\n\n\n\nt(b)%*%a ## Compatível\n\n     [,1]\n[1,]   10\n[2,]   20\n[3,]   30\n[4,]   40\n\n\n\nalpha*b # Escalar com matriz\n\n     [,1] [,2] [,3] [,4]\n[1,]   10   20   30   40\n\n\n\nb*alpha # Escalar com matriz\n\n     [,1] [,2] [,3] [,4]\n[1,]   10   20   30   40\n\n\nUm outro tipo de produto entre vetores ou matrizes é o chamado produto de Hadamard. Sendo duas matrizes ou dois vetores de mesmo tamanho o produto de Hadamard é simplesmente o resultado da multiplicação direta dos elementos correspondentes:\n\\[\n\\mathbf{A} \\odot  \\mathbf{B} = \\begin{pmatrix}\na_{11} b_{11} & a_{12} b_{12} & \\cdots & a_{1m}b_{1m} \\\\\na_{21} b_{21} & a_{22} b_{22} & \\cdots & a_{2m} b_{2m} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots\\\\\na_{n1} b_{n1} & a_{n2} b_{n2} & \\cdots & a_{nm} b_{nm}\n\\end{pmatrix}.\n\\]\nEstamos usando a notação \\(\\odot\\) para diferenciar o produto de Hadamard do produto matricial usual. Em R este produto é obtido usando o operador * usual, conforme ilustrado no Código 2.9.\nCódigo 2.9 Produto de Hadamard.\n\nA &lt;- matrix(c(1,2,3,4), nrow = 2, ncol = 2)\nB &lt;- matrix(c(10,20,30,40), nrow = 2, ncol = 2)\n\nA*B\n\n     [,1] [,2]\n[1,]   10   90\n[2,]   40  160\n\n\n\n\n2.2.2 Matrizes de formas especiais\nNesta subseção veremos algumas matrizes com formas especiais.\nDizemos que uma matriz é quadrada quando tem o mesmo número de linhas e colunas. Por exemplo,\n\\[\n\\mathbf{A} = \\begin{pmatrix}\na_{11} & a_{12} & a_{13} & a_{14} \\\\\na_{21} & a_{22} & a_{23} & a_{24} \\\\\na_{31} & a_{32} & a_{33} & a_{34} \\\\\na_{41} & a_{42} & a_{43} & a_{44}\n\\end{pmatrix}.\n\\]\nChamamos os elementos \\(a_{ii}\\) de elementos diagonais ou da diagonal. Já os elementos \\(a_{ij}\\) para \\(i \\neq j\\) são chamados de elementos fora da diagonal. Os elementos \\(a_{ij}\\) para \\(j &gt; i\\) são os elementos acima da diagonal e os elementos \\(a_{ij}\\) para \\(i &gt; j\\) são os elementos abaixo da diagonal.\nUma matriz é diagonal se apenas os elementos diagonais são diferentes de zero. Por exemplo,\n\\[\n\\mathbf{D} = \\begin{pmatrix}\na_{11} & 0 & 0 & 0 \\\\\n0 & a_{22} & 0 & 0 \\\\\n0 & 0 & a_{33} & 0 \\\\\n0 & 0 & 0 & a_{44}\n\\end{pmatrix}.\n\\]\nUma matriz é triangular superior se os elementos abaixo da diagonal são todos iguais a zero. É comum denotar uma matriz triangular superior por \\(\\mathbf{U}\\) do Inglês upper .\n\\[\n\\mathbf{U} = \\begin{pmatrix}\na_{11} & a_{12} & a_{13} & a_{14} \\\\\n0 & a_{22} & a_{23} & a_{24} \\\\\n0 & 0 & a_{33} & a_{34} \\\\\n0 & 0 & 0 & a_{44}\n\\end{pmatrix}.\n\\]\nPor outro lado, uma matriz é triangular inferior se os elementos acima da diagonal são todos iguais a zero. Neste caso a notação usual é \\(\\mathbf{L}\\) do Inglês lower .\n\\[\n\\mathbf{L} = \\begin{pmatrix}\na_{11} & 0 & 0 & 0 \\\\\na_{21} & a_{22} & 0 & 0 \\\\\na_{31} & a_{32} & a_{33} & 0 \\\\\na_{41} & a_{42} & a_{43} & a_{44}\n\\end{pmatrix}.\n\\]\nA matriz identidade é uma matriz diagonal onde os elementos diagonais são todos iguais a \\(1\\). A notação usual é \\(\\mathbf{I}\\) do Inglês identity .\n\\[\n\\mathbf{I} = \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}.\n\\]\nA matriz zero ou nula é aquela cuja todas as entradas são iguais a zero, ou seja,\n\\[\n\\mathbf{0} = \\begin{pmatrix}\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0\n\\end{pmatrix}.\n\\]\nUma matriz quadrado é dita ser simétrica se \\(a_{ij} = a_{ji}\\). De forma equivalente, se \\(\\mathbf{A}^{\\top} = \\mathbf{A}\\), então \\(\\mathbf{A}\\) é simétrica. Por exemplo,\n\\[\n\\mathbf{A} = \\begin{pmatrix}\n1 & 0.8 & 0.6 & 0.4 \\\\\n0.8 & 1 & 0.2 & 0.4 \\\\\n0.6 & 0.2 & 1 & 0.1 \\\\\n0.4 & 0.4 & 0.1 & 1\n\\end{pmatrix}.\n\\]\n\n\n2.2.3 Rank  e inversa de uma matriz\nNa seção 2.2.1 vimos diversas operações com matrizes. Muitas destas operações são extensões das operações de soma, subtração e multiplicação de escalares. No entanto, a divisão entre matrizes não foi definida. De forma geral duas matrizes não podem ser divididas, porém existe um tipo especial de matriz que tenta de certa forma estender a operação de divisão entre escalares para matrizes. Essa matriz especial é chamada de matriz inversa. Porém, a sua obtenção está limitada a um certo conjunto de matrizes que são chamadas não singulares. Nesta seção nós vamos entender o que é uma matriz não singular e como avaliar se uma matriz qualquer é ou não singular por meio da avaliação do seu rank , também chamado de posto.\nPara definir o que é o rank  de uma matriz precisamos da noção de dependência e independência linear. Um conjunto de vetores \\(\\mathbf{a}_1, \\mathbf{a}_2, \\ldots, \\mathbf{a}_n\\) é dito ser linearmente dependente se escalares \\(c_1, c_2, \\ldots, c_n\\) não todos iguais a zero puderem ser encontrados de tal forma que\n\\[\n\\begin{equation}\nc_1 \\mathbf{a}_1 + c_2 \\mathbf{a}_2 + \\ldots + c_n \\mathbf{a}_n = 0.\n\\tag{2.1}\n\\end{equation}\n\\]\nNo caso em que os coeficientes \\(c_1, c_2, \\ldots, c_n\\) não puderem ser encontrados satisfazendo (2.1) o conjunto de vetores \\(\\mathbf{a}_1, \\mathbf{a}_2, \\ldots, \\mathbf{a}_n\\) é dito ser linearmente independente. Note que a Equação (2.1) pode ser reescrita em formato matricial, onde os vetores \\(\\mathbf{a}_1, \\mathbf{a}_2, \\ldots, \\mathbf{a}_n\\) formam as colunas de uma matriz \\(\\mathbf{A}\\) e os escalares são empilhados em um vetor \\(\\mathbf{c}\\). Assim,\n\\[\n\\mathbf{A} \\mathbf{c} = \\mathbf{0}.\n\\]\nNeste caso as colunas de \\(\\mathbf{A}\\) são linearmente independentes se \\(\\mathbf{A} \\mathbf{c} = \\mathbf{0}\\) implicar que \\(\\mathbf{c} = 0\\). Intuitivamente um conjunto de vetores linearmente dependentes é de alguma forma redundante, no sentido de que um dos vetores pode ser escrito como uma combinação linear dos outros.\nConsidere um exemplo trivial com os vetores \\(\\mathbf{a}_1 = (1,0)\\) e \\(\\mathbf{a}_2 = (0,1)\\). Veja que qualquer outro vetor de tamanho dois pode ser escrito como uma combinação linear dos vetores \\(\\mathbf{a}_1\\) e \\(\\mathbf{a}_2\\). Assim, qualquer outro vetor de tamanho dois concatenado com \\(\\mathbf{a}_1\\) e \\(\\mathbf{a}_2\\) em uma matriz \\(\\mathbf{A}\\) tornará as colunas de \\(\\mathbf{A}\\) linearmente dependentes. Porém, uma matriz \\(\\mathbf{A}\\) formada apenas por \\(\\mathbf{a}_1\\) e \\(\\mathbf{a}_2\\) tem colunas linearmente independentes.\n\n\n\n\n\n\nDefinição 2.3\n\n\n\nO rank  ou posto de qualquer matriz quadrada ou retangular \\(\\mathbf{A}\\) é definido como\n\\[\n\\mathrm{rank}(\\mathbf{A}) = \\text{número de colunas ou linhas linearmente independentes em } \\mathbf{A}.\n\\]\n\n\nPode ser provado que o número de linhas e colunas linearmente independentes em uma matriz qualquer é sempre o mesmo. Se uma matriz \\(\\mathbf{A}\\) tem apenas um elemento diferente de zero, então \\(\\mathrm{rank}(\\mathbf{A}) = 1\\). O \\(\\mathrm{rank}\\) da matriz nula é \\(0\\).\nSendo \\(\\mathbf{A}\\) uma matriz retangular \\(n \\times m\\) o maior rank  possível para \\(\\mathbf{A}\\) é o \\(\\min(n,m)\\). Quando o rank  da matriz é o \\(\\min(n,m)\\) dizemos que a matriz tem rank  completo ou é de posto completo. Importante salientar que qualquer matriz retangular terá colunas linearmente dependentes. Com os conceitos apresentados até aqui podemos finalmente definir o que entendemos por uma matriz não singular e matriz inversa.\n\n\n\n\n\n\nDefinição 2.4\n\n\n\nUma matriz quadrada de posto completo é chamada de não singular.\n\n\n\n\n\n\n\n\nDefinição 2.5\n\n\n\nDada uma matriz quadrada \\(\\mathbf{A}\\) de posto completo a matriz inversa de \\(\\mathbf{A}\\) denotada por \\(\\mathbf{A}^{-1}\\) é única tal que\n\\[\n\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{I}.\n\\]\n\n\nSe a matriz \\(\\mathbf{A}\\) não for quadrada e de posto completo, então \\(\\mathbf{A}\\) não terá inversa e é dita ser singular. Baseado na Definição 2.5 é fácil ver que \\((\\mathbf{A}^{-1})^{-1} = \\mathbf{A}.\\)\nEm aplicações reais obter a inversa de uma matriz é uma tarefa complexa e requer o uso de algoritmos numéricos. Nós vamos ver algumas opções na Seção 2.3 quando discutiremos algoritmos para a solução de sistemas de equações lineares.\nA intuição da matriz inversa é poder fazer operações similares a que realizamos com escalares quando estamos resolvendo sistemas de equações lineares. Lembre-se do sistema de equações lineares representado nas Equações (1.14) e (1.15) no modelo de regressão linear simples.\nNo decorrer deste livro seremos frequentemente confrontados com sistemas lineares do tipo \\(\\mathbf{A} \\mathbf{x} = \\mathbf{c}\\) em que precisamos encontrar o vetor de incógnitas \\(\\mathbf{x}\\). No caso em que \\(\\mathbf{A}\\) é não singular, o sistema de equações \\(\\mathbf{A} \\mathbf{x} = \\mathbf{c}\\) terá uma única solução dada por \\(\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{c}\\). Veja como a inversa imita o que costumamos fazer com escalares quando resolvendo uma simples equação linear. É o equivalente ao que falamos grosseiramente de “passa pro outro lado.” O que realmente está sendo feito é que multiplicamos o sistema em ambos os lados por \\(\\mathbf{A}^{-1}\\) para obter a solução, ou seja,\n\\[\n\\begin{eqnarray}\n\\mathbf{A}^{-1} \\mathbf{A} \\mathbf{x} &=& \\mathbf{A}^{-1} \\mathbf{c} \\\\\n\\mathbf{I}\\mathbf{x} &=& \\mathbf{A}^{-1} \\mathbf{c}.\n\\end{eqnarray}\n\\]\nEm R podemos facilmente obter a inversa de uma matriz usando a função solve(). No entanto, como ficará claro quando discutirmos métodos para a solução de sistemas lineares, tal solução é cara computacionalmente e raramente necessária explicitamente. O Código 2.10 ilustra a obtenção da inversa.\nCódigo 2.10 Inversa de uma matriz.\n\nA &lt;- matrix(c(4, 2, 7, 6), 2, 2)\nA_inv &lt;- solve(A)\n\n## Conferindo: deve resultar na matriz identidade\nA%*%A_inv\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n\n\nDuas propriedades importantes envolvendo multiplicação e inversão de matrizes são:\n\nSe \\(\\mathbf{A}\\) é não singular, então \\(\\mathbf{A}^{\\top}\\) é não singular e sua inversa é dada por \\[\n(\\mathbf{A}^{\\top})^{-1} = (\\mathbf{A}^{-1})^{\\top}.\n\\]\nSe \\(\\mathbf{A}\\) e \\(\\mathbf{B}\\) são matrizes não singulares de mesmo tamanho, então o produto \\(\\mathbf{A} \\mathbf{B}\\) é não singular e \\[\n(\\mathbf{A} \\mathbf{B})^{-1} =  \\mathbf{B}^{-1} \\mathbf{A}^{-1}.\n\\]\n\nNo caso em que uma matriz é retangular não podemos obter a inversa. Nestes casos podemos recorrer a matriz inversa generalizada.\n\n\n\n\n\n\nDefinição 2.6\n\n\n\nA inversa generalizada de uma matriz \\(\\mathbf{A}\\) \\(n \\times p\\) é qualquer matriz \\(\\mathbf{A}^{-}\\) que satisfaça\n\\[\n\\mathbf{A}\\mathbf{A}^{-}\\mathbf{A} = \\mathbf{A}.\n\\]\n\n\nA inversa generalizada não é única exceto quando \\(\\mathbf{A}\\) é não-singular, e neste caso coincide com a inversa. Toda matriz, seja quadrada ou retangular tem uma inversa generalizada, isto inclui vetores. Como um exemplo ilustrativo, considere o vetor\n\\[\n\\mathbf{a} = \\begin{pmatrix}\n1\\\\\n2\\\\\n3\\\\\n4\n\\end{pmatrix}.\n\\]\nNeste caso o vetor \\(\\mathbf{a}^{-} = (1, 0, 0, 0)\\) é a inversa generalizada de \\(\\mathbf{a}\\). Para verificar basta fazer a multiplicação matricial.\n\na &lt;- matrix(c(1, 2, 3, 4), 4, 1)\na_invg &lt;- matrix(c(1,0,0,0), 1, 4)\na%*%a_invg%*%a\n\n     [,1]\n[1,]    1\n[2,]    2\n[3,]    3\n[4,]    4\n\n\nImportante notar que se \\(\\mathbf{A}\\) é \\(n \\times p\\), então qualquer inversa generalizada de \\(\\mathbf{A}\\) terá dimensão \\(p \\times n\\).\nComo dito, a inversa generalizada não é única. Em particular a inversa generalizada chamada de Moore-Penrose (Moore-Penrose Genereralized Inverse ) está implementada em R por meio do pacote MASS. O Código 2.11 ilustra a obtenção da inversa generalizada de Moore-Penrose para uma matriz quadrada, porém singular.\nCódigo 2.11 Inversa generalizada de Moore-Penrose.\n\n## Matriz singular (a terceira coluna é a soma da primeira com a segunda)\nA &lt;- matrix(c(2, 1, 3, 2, 0, 2, 3, 1, 4), 3, 3)\n\n## Carregando o pacote MASS\nlibrary(MASS)\nA_ginv &lt;- ginv(A)\n\n## Conferindo\nA%*%A_ginv%*%A\n\n     [,1]         [,2] [,3]\n[1,]    2 2.000000e+00    3\n[2,]    1 2.220446e-16    1\n[3,]    3 2.000000e+00    4\n\n\n\n\n2.2.4 Matrizes positivas definidas\nNo decorrer deste livro vamos encontrar frequentemente as chamadas somas de quadrados. Nós já discutimos sobre soma de quadrados nas seções 1.2.5 e 1.2.9 quando encontramos a média e os coeficientes de regressão do modelo de regressão linear simples. De forma matricial, a soma de quadrados pode ser reescritas usando formas quadráticas.\nConsidere uma matriz \\(\\mathbf{A}\\) simétrica e \\(\\mathbf{y}\\) um vetor, o produto\n\\[\n\\mathbf{y}^{\\top} \\mathbf{A} \\mathbf{y} = \\sum_{i} a_{ij} y_i^2 + \\sum_{i \\neq j} a_{ij} y_i y_j,\n\\]\né chamado de forma quadrática.\nPara uma matriz \\(\\mathbf{y}\\) de dimensão \\(n \\times 1\\), ou seja, um vetor coluna o produto matricial \\(\\mathbf{y}^{\\top}\\mathbf{I} \\mathbf{y} = y_1^2 + y_2^2 + \\ldots, y_n^2\\). Assim, \\(\\mathbf{y}^{\\top} \\mathbf{y}\\) é a soma de quadrados dos elementos do vetor \\(\\mathbf{y}\\). A raiz quadrado da soma de quadrados é a distância do ponto \\(\\mathbf{y}\\) até a origem, também chamada de comprimento de \\(\\mathbf{y}\\). As somas de quadrados permanecem positivas, ou ao menos não negativas para todos os valores de \\(\\mathbf{y}\\) exceto no caso em que \\(\\mathbf{y} = 0\\).\n\n\n\n\n\n\nDefinição 2.7\n\n\n\nSendo \\(\\mathbf{A}\\) uma matriz simétrica com a propriedade \\(\\mathbf{y}^{\\top} \\mathbf{A} \\mathbf{y} &gt; 0\\) para todos os possíveis \\(\\mathbf{y}\\) exceto para quando \\(\\mathbf{y} = 0\\), então a forma quadrática \\(\\mathbf{y}^{\\top} \\mathbf{A} \\mathbf{y}\\) é chamada positiva definida, e \\(\\mathbf{A}\\) é dita ser uma matriz positiva definida. No caso de \\(\\mathbf{y}^{\\top} \\mathbf{A} \\mathbf{y} \\geq 0\\) e existir ao menos um \\(\\mathbf{y} \\neq 0\\) tal que \\(\\mathbf{y}^{\\top} \\mathbf{A} \\mathbf{y} = 0\\), então \\(\\mathbf{y}^{\\top} \\mathbf{A} \\mathbf{y}\\) é dita ser positiva semi-definida e \\(\\mathbf{A}\\) é uma matriz positiva semi-definida.\n\n\nPara ilustração considere a seguinte matriz\n\\[\n\\mathbf{A} = \\begin{pmatrix}\n2 & -1\\\\\n-1 & 3\n\\end{pmatrix}.\n\\]\nA forma quadrática associada é dada por\n\\[\n\\mathbf{y}^{\\top} \\mathbf{A} \\mathbf{y} = \\begin{pmatrix}\ny_1 & y_2\n\\end{pmatrix}\n\\begin{pmatrix}\n2 & -1\\\\\n-1 & 3\n\\end{pmatrix}\n\\begin{pmatrix}\ny_1 \\\\\ny_2\n\\end{pmatrix} = 2 y_1^2 - 2 y_1 y_2 + 3 y_2^2,\n\\]\nque é claramente positiva, desde que \\(y_1\\) e \\(y_2\\) sejam diferentes de zero. Algumas propriedades interessantes sobre matrizes positivas definidas ou semi-definidas são:\n\n\\(\\mathbf{A}\\) é positiva definida, então todos os valores da diagonal de \\(\\mathbf{A}\\) são positivos.\nSe \\(\\mathbf{A}\\) é positiva semi-definida, então os elementos da diagonal de \\(\\mathbf{A}\\) são maiores ou iguais a zero.\nSendo \\(\\mathbf{P}\\) uma matriz não-singular e \\(\\mathbf{A}\\) uma matriz positiva definida, o produto \\(\\mathbf{P}^{\\top} \\mathbf{A} \\mathbf{P}\\) é uma matriz positiva definida.\nSendo \\(\\mathbf{P}\\) uma matriz não-singular e \\(\\mathbf{A}\\) uma matriz positiva semi-definida, o produto \\(\\mathbf{P}^{\\top} \\mathbf{A} \\mathbf{P}\\) é uma matriz positiva semi-definida.\nUma matriz positiva definida é não-singular.\n\nMatrizes positivas definidas são fundamentais em estatística pois representam a matriz de variância e covariância de vetores aleatórios.\n\n\n2.2.5 Determinante e traço de uma matriz\n\n\n\n\n\n\nDefinição 2.8\n\n\n\nO determinante de uma matriz \\(\\mathbf{A}\\) é o escalar\n\\[\n|\\mathbf{A}| = \\sum_j (-1)^k a_{1 j_1} a_{2 j_2}, \\ldots, a_{n j_n},\n\\]\nonde a soma é realizada para todas as \\(n!\\) permutações de grau \\(n\\), e \\(k\\) é o número de mudanças necessárias para que os segundos subscritos sejam colocados na ordem \\(1,2, \\ldots, n.\\)\n\n\nEm termos de notação vamos usar \\(|\\mathbf{A}|\\) ou \\(\\det{(A)}\\). A Definição 2.8 é difícil de entender e pouco útil para avaliar determinantes de matrizes de grande dimensão. Entretanto, nestes casos temos sempre que recorrer a métodos computacionais. Para matrizes pequenas é fácil obter o determinante. Vamos fazer um exemplo simples com uma matriz \\(2 \\times 2\\) apenas como ilustração.\nConsidere a matriz\n\\[\n\\mathbf{A} = \\begin{pmatrix}\n3 & -2\\\\\n-2 & 4\n\\end{pmatrix}.\n\\]\nUsando a definição precisamos encontrar todas as \\(n!\\) combinações de produtos contendo um elemento de cada linha e coluna. Neste caso \\(n = 2\\) e \\(n! = 2 \\cdot 1 = 2\\). Teremos apenas duas combinações. Na primeira combinação vamos pegar o elemento \\(a_{11} = 3\\) e multiplicar pelo elemento \\(a_{22} = 4\\). Neste caso os índices de coluna já estão na ordem crescente, então o número de trocas foi \\(0\\). O segundo termo será o elemento \\(a_{12} = -2\\) multiplicado pelo elemento \\(a_{21} = -2\\). Neste caso, para que os índices de coluna fiquem em ordem crescente, precisamos fazer uma mudança, então \\(k = 1\\).\n\\[\n|\\mathbf{A}| = (-1)^0 a_{11} a_{22} + (-1)^1 a_{12} a_{21} = 1 \\cdot (3 \\cdot 4) - (-2 \\cdot -2) =  12 - 4 = 8.\n\\]\nEm R o determinante de uma matriz pode ser obtido por meio da função determinant(), conforme ilustrado no Código 2.12.\nCódigo 2.12 Determinante de uma matriz.\n\nA &lt;- matrix(c(3,-2,-2,4),2,2)\ndeterminant(A, logarithm = FALSE)\n\n$modulus\n[1] 8\nattr(,\"logarithm\")\n[1] FALSE\n\n$sign\n[1] 1\n\nattr(,\"class\")\n[1] \"det\"\n\n\nÉ muito comum precisarmos do logaritmo do determinante, assim a função determinant() traz essa opção como default . Por isso, para obter o determinante de \\(\\mathbf{A}\\) precisamos incluir o argumento logarithm = FALSE. Caso contrário o determinante seria obtido em escala logarítmica.\n\ndeterminant(A, logarithm = TRUE)\n\n$modulus\n[1] 2.079442\nattr(,\"logarithm\")\n[1] TRUE\n\n$sign\n[1] 1\n\nattr(,\"class\")\n[1] \"det\"\n\n\nAlguns aspectos interessantes sobre determinantes são:\n\nSe \\(\\mathbf{A}\\) é singular, \\(|\\mathbf{A}| = 0\\).\nSe \\(\\mathbf{A}\\) é não singular, \\(|\\mathbf{A}| \\neq 0\\).\nSe \\(\\mathbf{A}\\) é positiva definida, \\(|\\mathbf{A}| &gt; 0\\).\n\\(|\\mathbf{A}^{\\top}| = |\\mathbf{A}|\\).\nSe \\(\\mathbf{A}\\) é não singular, \\(|\\mathbf{A}^{-1}| = \\frac{1}{|\\mathbf{A}|}\\).\n\n\n\n\n\n\n\nDefinição 2.9\n\n\n\nO traço de uma matriz \\(\\mathbf{A}\\) \\(n \\times n\\) é um escalar definido como a soma dos elementos da diagonal, \\(\\mathrm{tr}(\\mathbf{A}) = \\sum_{i=1}^n a_{ii}\\).\n\n\nAlgumas propriedades do traço:\n\nSe \\(\\mathbf{A}\\) e \\(\\mathbf{B}\\) são \\(n \\times n\\), então\n\n\\[\n\\mathrm{tr}(\\mathbf{A} + \\mathbf{B}) = \\mathrm{tr}(\\mathbf{A}) + \\mathrm{tr}(\\mathbf{B}).\n\\]\n\nSe \\(\\mathbf{A}\\) é \\(n \\times p\\) e \\(\\mathbf{B}\\) e \\(p \\times n\\), então\n\n\\[\n\\mathrm{tr}(\\mathbf{AB}) = \\mathrm{tr}(\\mathbf{BA}).\n\\]\nEm R não temos uma função explícita para a obtenção do traço devido a sua simplicidade. Assim, podemos obter o traço simplesmente acessando os elementos da diagonal da matriz com a função diag() e somar com a função sum(), conforme ilustrado no Código 2.13.\nCódigo 2.13 Traço de uma matriz.\n\nA &lt;- matrix(c(3,-2,-2,4),2,2)\nsum(diag(A))\n\n[1] 7\n\n\n\n\n2.2.6 Cálculo vetorial e matricial\nNo Capítulo \\(1\\) vimos como obter a derivada de funções com até duas variáveis independentes. Usando as ferramentas de Cálculo vetorial e matricial podemos obter derivadas de funções com um número arbitrário de variáveis independentes. Seja \\(y = f(\\mathbf{x})\\) uma função das variáveis \\(x_1, x_2, \\ldots, x_p\\) e \\(\\frac{\\partial y}{\\partial x_1}, \\frac{\\partial y}{\\partial x_2}, \\ldots, \\frac{\\partial y}{\\partial x_p}\\) as respectivas derivadas parciais. Assim,\n\\[\n\\frac{\\partial y}{\\partial \\mathbf{x}} = \\begin{pmatrix}\n\\frac{\\partial y}{\\partial x_1}\\\\\n\\frac{\\partial y}{\\partial x_2}\\\\\n\\vdots\\\\\n\\frac{\\partial y}{\\partial x_p}\n\\end{pmatrix}.\n\\]\nBasicamente, a ideia é derivar em cada uma das variáveis independentes e arranjar as derivadas parciais em um vetor de tamanho adequado. Usando esta ideia simples é possível calcular a derivada de funções mais complicadas. Vejamos algumas derivadas vetoriais e matriciais úteis em ciência de dados.\nSendo \\(\\mathbf{a}^{\\top} = (a_1, a_2, \\ldots, a_p)\\) um vetor de constantes e \\(\\mathbf{A}\\) uma matriz simétrica de constantes.\n\nSeja \\(y = \\mathbf{a}^{\\top} \\mathbf{x} = \\mathbf{x}^{\\top} \\mathbf{a}\\). Então,\n\n\\[\n\\frac{\\partial y}{\\partial \\mathbf{x}} = \\frac{\\partial (\\mathbf{x}^{\\top} \\mathbf{a})}{\\partial \\mathbf{x}} = \\mathbf{a}.\n\\]\n\nSeja \\(y = \\mathbf{x}^{\\top} \\mathbf{A} \\mathbf{x}\\). Então,\n\n\\[\n\\frac{\\partial y}{\\partial \\mathbf{x}} = \\frac{\\partial (\\mathbf{x}^{\\top} \\mathbf{A} \\mathbf{x}) }{\\partial \\mathbf{x}} = 2 \\mathbf{A} \\mathbf{x}.\n\\]\nDe forma similar, se \\(y = f(\\mathbf{X})\\) onde \\(\\mathbf{X}\\) é uma matriz \\(p \\times p\\). As derivadas parciais de \\(y\\) em relação a cada \\(x_{ij}\\) são organizadas em uma matriz.\n\\[\n\\frac{\\partial y}{\\partial \\mathbf{X}} = \\begin{pmatrix}\n\\frac{\\partial y}{\\partial x_{11}} & \\ldots & \\frac{\\partial y}{\\partial x_{1p}}\\\\\n\\vdots & \\ddots  & \\vdots\\\\\n\\frac{\\partial y}{\\partial x_{p1}} & \\ldots & \\frac{\\partial y}{\\partial x_{pp}}\n\\end{pmatrix}.\n\\]\nAlgumas derivadas importantes envolvendo matrizes são apresentadas abaixo.\n\nSeja \\(y = \\mathrm{tr}(\\mathbf{X}\\mathbf{A})\\) sendo \\(\\mathbf{X}\\) \\(p \\times p\\) e definida positiva e \\(\\mathbf{A}\\) \\(p \\times p\\) constantes. Então,\n\n\\[\n\\frac{\\partial y}{\\partial \\mathbf{X}} = \\frac{\\partial \\mathrm{tr}(\\mathbf{X}\\mathbf{A})}{\\partial \\mathbf{X}} =  \\mathbf{A} + \\mathbf{A}^{\\top} - \\mathrm{diag}(\\mathbf{A}).\n\\]\n\nSendo \\(\\mathbf{A}\\) não singular com derivadas \\(\\frac{\\partial \\mathbf{A}}{\\partial x}\\). Então,\n\n\\[\n\\frac{\\partial \\mathbf{A}^{-1}}{\\partial x} = - \\mathbf{A}^{-1} \\frac{\\partial \\mathbf{A}}{\\partial x} \\mathbf{A}^{-1}.\n\\]\n\nSendo \\(\\mathbf{A}\\) \\(n \\times n\\) positiva definida. Então,\n\n\\[\n\\frac{\\partial \\log |\\mathbf{A}|}{\\partial x} = \\mathrm{tr} \\left( \\mathbf{A}^{-1} \\frac{\\partial \\mathbf{A}}{\\partial x} \\right).\n\\]\n\n\n2.2.7 Regressão linear múltipla\nNa seção 1.2.9 construímos o modelo de regressão linear simples, onde apenas uma covariável \\(x\\) descreve o comportamento da variável dependente \\(y\\), por meio de uma reta, ou seja,\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i.\n\\]\nNo modelo de regressão linear múltipla estendemos este modelo para levar em consideração um número arbitrário \\(p\\) de covariáveis \\(x_{ip}\\). Nesta notação \\(x_{ip}\\) é o valor da \\(p-\\)ésima covariável associada a observação \\(i\\) para \\(i = 1, \\ldots, n\\), sendo \\(n\\) o número de observações. Note que a primeira covariável é assumida como \\(1\\) para representar o intercepto.\nO modelo de regressão linear múltipla é então escrito como\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\ldots + \\beta_p x_{ip} + \\epsilon_i.\n\\]\nPodemos escrever o modelo para cada uma das \\(n\\) observações, como segue\n\\[\n\\begin{matrix}\ny_1 = \\beta_0 + \\beta_1 x_{11} + \\beta_2 x_{12} + \\ldots \\beta_{p} x_{1p} + \\epsilon_1 \\\\\ny_2 = \\beta_0 + \\beta_1 x_{21} + \\beta_2 x_{22} + \\ldots \\beta_{p} x_{2p} + \\epsilon_2\\\\\n\\vdots \\\\\ny_n = \\beta_0 + \\beta_1 x_{n1} + \\beta_2 x_{n2} + \\ldots \\beta_{p} x_{np} + \\epsilon_p.\\\\\n\\end{matrix}\n\\]\nAgora organizamos os termos em formato matricial\n\\[\n\\underset{n\\times 1}{\\begin{bmatrix}\ny_1\\\\\ny_2\\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}} =\n\\underset{n\\times p}{\\begin{bmatrix}\n1 & x_{11} & \\ldots & x_{p1} \\\\\n1 & x_{12} & \\ldots & x_{p1} \\\\\n\\vdots & \\vdots  & \\ddots & \\vdots \\\\\n1& x_{1n} & \\ldots & x_{pn}\n\\end{bmatrix} }\n\\underset{p \\times 1}{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\n} + \\underset{n\\times 1}{\\begin{bmatrix}\n\\epsilon_1\\\\\n\\epsilon_2\\\\\n\\vdots \\\\\n\\epsilon_n\n\\end{bmatrix}}\n\\]\nPor fim, usamos uma notação mais compacta para representar o modelo\n\\[\n\\underset{n \\times 1}{\\mathbf{y}} = \\underset{n \\times p }{\\mathbf{X}} \\underset{p\\times 1}{\\boldsymbol{\\beta}} + \\underset{n \\times 1}{\\mathbf{\\epsilon}}.\n\\]\nNote como todas as multiplicações envolvidas no modelo são compatíveis respeitando as regras dos produtos de matrizes.\nNosso objetivo é encontrar o vetor \\(\\boldsymbol{\\hat{\\beta}}\\), tal que\n\\[\nSQ(\\boldsymbol{\\beta}) = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^{\\top} (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}),\n\\]\nseja a menor possível.\nEsse processo é o que chamamos de estimação dos parâmetros de regressão ou de treinamento do modelo, a segunda nomenclatura é comum na literatura de aprendizado de máquina. Note que novamente temos um processo de minimização, porém agora de uma função com muitas variáveis independentes. Usando as ferramentas de Álgebra Linear podemos facilmente proceder com esse problema de minimização.\nO primeiro passo é derivar a soma de quadrados em \\(\\boldsymbol{\\beta}\\), usando Cálculo vetorial (ver Seção 2.2.6).\nDerivando em \\(\\boldsymbol{\\beta}\\), temos\n\\[\n\\begin{eqnarray*}\n\\frac{\\partial SQ(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} &=& \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^{\\top} (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\\n&=& \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} \\left ( (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^{\\top}  \\right ) (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) + (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^{\\top} \\frac{\\partial}{\\partial \\boldsymbol{\\beta}}  (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\\n&=& -\\mathbf{X}^{\\top}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) + (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^{\\top} (-\\mathbf{X}) \\\\\n&=& -2\\mathbf{X}^{\\top}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}).\n\\end{eqnarray*}\n\\]\nO segundo passo é resolver o sistema de equações lineares resultantes\n\\[\n\\begin{eqnarray}\n\\mathbf{X}^{\\top}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\hat{\\beta}}) &=& \\boldsymbol{0} \\\\\n\\mathbf{X}^{\\top}\\mathbf{y} - \\mathbf{X}^{\\top}\\mathbf{X}\\boldsymbol{\\hat{\\beta}} &=& 0 \\\\\n\\mathbf{X}^{\\top}\\mathbf{X}\\boldsymbol{\\hat{\\beta}} &=& \\mathbf{X}^{\\top}\\mathbf{y} \\tag{2.2} \\\\\n\\boldsymbol{\\hat{\\beta}} &=& (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y}. \\tag{2.3}\n\\end{eqnarray}\n\\]\nNote que a Equação (2.2) foi multiplicada em ambos os lados por \\((\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\) para encontrar (2.3). Essa operação corresponde a resolver o sistema de equações lineares. Nós vimos na Seção 2.2.3 como obter a inversa de uma matriz usando o R. Assim, estamos aptos a implementar tais operações em R.\nPara exemplificar a implementação do modelo de regressão linear múltipla, vamos usar um conjunto de dados muito famoso sobre o preço de imóveis na cidade de Boston. O conjunto de dados está disponível no pacote MASS e contém além da variável resposta \\(13\\) covariáveis e \\(506\\) observações. As primeiras seis observações do conjunto de dados são apresentadas abaixo.\n\nrequire(MASS)\ndata(Boston)\nhead(Boston)\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\n\nAs covariáveis disponíveis são\n\ncrim: taxa de crimes per capita.\nzn: proporção de terrenos residenciais zoneados para lotes com mais de 25.000 pés quadrados.\nindus: proporção de acres de negócios não varejistas por cidade.\nchas: variável dummy de Charles River (1 se a área limita o rio; 0 caso contrário).\nnox: concentração de óxido de nitrogênio (parte por 10 milhões).\nrm: número médio de quartos por habitação.\nage: proporção de unidades ocupadas pelo proprietário construídas antes de 1940.\ndis: média ponderada das distâncias a cinco centros de empregos de Boston.\nrad: índice de acessibilidade às rodovias radiais.\ntax: taxa de imposto sobre a propriedade de valor total por $10.000.\nptratio: proporção aluno-professor por cidade.\nblack: \\(1000 (Bk - 0,63)^2\\) onde \\(Bk\\) é a proporção de negros por cidade.\nlstat: Porcentagem da população em pobreza.\n\nA variável resposta é o valor mediano das casas ocupadas pelos proprietários em \\(\\$1000\\), codificada como medv. O primeiro passo para implementar o modelo de regressão linear múltipla para este problema é montar a matriz \\(\\mathbf{X}\\), também chamada de matriz de delineamento. Ela vai conter os valores de todas as covariáveis de interesse. Em R podemos usar a função model.matrix() para construir tal matriz. Para este exemplo, vamos usar apenas as primeiras cinco covariáveis.\n\nX &lt;- model.matrix(~ crim + zn + indus + chas + nox, data = Boston)\nhead(X)\n\n  (Intercept)    crim zn indus chas   nox\n1           1 0.00632 18  2.31    0 0.538\n2           1 0.02731  0  7.07    0 0.469\n3           1 0.02729  0  7.07    0 0.469\n4           1 0.03237  0  2.18    0 0.458\n5           1 0.06905  0  2.18    0 0.458\n6           1 0.02985  0  2.18    0 0.458\n\n\nNote que a função model.matrix() automaticamente inclui uma coluna de \\(1\\)’s para representar o intercepto. O vetor \\(y\\) neste caso é a coluna medv.\n\ny &lt;- Boston$medv\n\nPor fim, implementamos a Equação (2.3) de duas formas distintas. Convido o leitor a tentar entender qual a diferença computacional entre elas. Tal diferença ficará clara quando discutirmos algoritmos para a solução de sistemas de equações lineares e obtenção da matriz inversa.\n\n# Forma ingênua\nsolve(t(X)%*%X)%*%t(X)%*%y\n\n                   [,1]\n(Intercept) 29.48994059\ncrim        -0.21851904\nzn           0.05511047\nindus       -0.38348055\nchas         7.02622266\nnox         -5.42465902\n\n\n\n# Forma eficiente\nsolve(t(X)%*%X, t(X)%*%y)\n\n                   [,1]\n(Intercept) 29.48994059\ncrim        -0.21851904\nzn           0.05511047\nindus       -0.38348055\nchas         7.02622266\nnox         -5.42465902\n\n\nPodemos usar a função lm() para conferir a nossa implementação.\n\ncoef(lm(medv ~ crim + zn + indus + chas + nox, data = Boston))\n\n(Intercept)        crim          zn       indus        chas         nox \n29.48994059 -0.21851904  0.05511047 -0.38348055  7.02622266 -5.42465902 \n\n\nOs resultados são idênticos. Podemos usar o modelo para predizer o valor de um imóvel dado os valores de suas covariáveis. Basicamente, tudo o que foi discutido no caso do modelo de regressão linear simples se adapta naturalmente para o modelo de regressão linear múltipla.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Álgebra Matricial</span>"
    ]
  },
  {
    "objectID": "content/Modulo02/Exercicios/index.html",
    "href": "content/Modulo02/Exercicios/index.html",
    "title": "6  Algebra Matricial",
    "section": "",
    "text": "Os objetivos deste tutorial são:\n\nGanhar experiência com operações vetoriais.\nPraticar a implementação computacional de operações vetoriais básicas.\nGanhar experiência com operações matriciais.\nPraticar a implementação computacional de operações matriciais, tais como, soma, subtração e multiplicação.\nUsar algoritmo para a solução de sistemas de lineares.\nUsar decomposições matriciais para resolver sistemas lineares e obter a inversa de matrizes.\nComparar a performance computacional de diferentes algoritmos para a solução de sistemas lineares.\nDesafio do módulo é implementar a distribuição Normal multivariada de forma mais eficiente que a função padrão do R.\n\n\n6.0.1 Vetores e escalares\n\nConsidere os vetores \\(\\boldsymbol{v}_1 = (1, 5, 10)\\) e \\(\\boldsymbol{v}_2 = (10, 50, 100)\\). Obtenha\n\n\nO comprimento de \\(\\boldsymbol{v}_1\\) e \\(\\boldsymbol{v}_2\\).\n\n\nv1 &lt;- c(1, 5, 10)\nv2 &lt;- c(10, 50, 100)\n\ncomprimento_v1 &lt;- sqrt(sum(v1^2))\ncomprimento_v2 &lt;- sqrt(sum(v2^2))\n\ncomprimento_v1\n\n[1] 11.22497\n\ncomprimento_v2\n\n[1] 112.2497\n\n\n\nO vetor unitário definido por \\(\\boldsymbol{v}_1\\) e \\(\\boldsymbol{v}_2\\).\n\n\nv1 &lt;- c(1, 5, 10)\nv2 &lt;- c(10, 50, 100)\n\ncomprimento_v1 &lt;- sqrt(sum(v1^2))\ncomprimento_v2 &lt;- sqrt(sum(v2^2))\n\nv1/comprimento_v1\n\n[1] 0.08908708 0.44543540 0.89087081\n\nv2/comprimento_v2 \n\n[1] 0.08908708 0.44543540 0.89087081\n\n\n\nA soma de \\(\\boldsymbol{v}_1\\) e \\(\\boldsymbol{v}_2\\).\n\n\nv1 &lt;- c(1, 5, 10)\nv2 &lt;- c(10, 50, 100)\n\nsoma &lt;- v1 + v2 \n\n\nA multiplicação de \\(\\boldsymbol{v}_1\\) e \\(\\boldsymbol{v}_2\\).\n\n\nv1 &lt;- c(1, 5, 10)\nv2 &lt;- c(10, 50, 100)\n\nv1%*%v2 \n\n     [,1]\n[1,] 1260\n\n\n\nO produto interno de \\(\\boldsymbol{v}_1\\) e \\(\\boldsymbol{v}_2\\).\n\n\nv1 &lt;- c(1, 5, 10)\nv2 &lt;- c(10, 50, 100)\n\nsum(v1*v2) \n\n[1] 1260\n\n\n\nSendo \\(\\alpha = 10\\), obtenha \\(\\alpha \\boldsymbol{v}_1\\).\n\n\nalpha = 10\n\nv1 &lt;- c(1, 5, 10)\n\nalpha*v1 \n\n[1]  10  50 100\n\n\n\nImplemente usando apenas funções básicas, funções genéricas para:\n\n\nSoma entre vetores.\n\n\nmy_soma &lt;- function(v1, v2) {\n  if(length(v1) != length(v2)) {stop(\"Tamanho dos vetores não é compatível para soma.\")}\n  n &lt;- length(v1)\n  soma &lt;- c()\n  for(i in 1:n) {\n    soma[i] &lt;- v1[i] + v2[i]\n  }\n  return(soma)\n}\n\nv1 &lt;- c(1, 5, 10)\nv2 &lt;- c(10, 50, 100)\nmy_soma(v1 = v1, v2 = v2) \n\n[1]  11  55 110\n\n\n\nSubtração entre vetores.\n\n\nmy_sub &lt;- function(v1, v2) {\n  if(length(v1) != length(v2)) {stop(\"Tamanho dos vetores não é compatível para subtração.\")}\n  n &lt;- length(v1)\n  soma &lt;- c()\n  for(i in 1:n) {\n    soma[i] &lt;- v1[i] - v2[i]\n  }\n  return(soma)\n}\n\nv1 &lt;- c(1, 5, 10)\nv2 &lt;- c(10, 50, 100)\n\nmy_sub(v1 = v1, v2 = v2) \n\n[1]  -9 -45 -90\n\n\n\nMultiplicação de um vetor por escalar.\n\n\nmy_esc_vetor &lt;- function(alpha, v1) {\n  n &lt;- length(v1)\n  out &lt;- c()\n  for(i in 1:n) {\n    out[i] &lt;- alpha*v1[i]\n  }\n  return(out)\n}\n\nmy_esc_vetor(alpha = 10, v1 = c(1, 2, 3))\n\n[1] 10 20 30\n\n\n\nProduto interno\n\n\nmy_prod &lt;- function(v1, v2) {\n  if(length(v1) != length(v2)) {stop(\"Tamanho dos vetores não é compatível para multiplicação.\")}\n  n &lt;- length(v1)\n  mul &lt;- c()\n  mul &lt;- 0\n  for(i in 1:n) {\n    mul &lt;- v1[i]*v2[i] + mul\n  }\n  return(mul)\n}\n\nmy_prod(v1 = c(1,2,3), v2 = c(10, 20, 30))\n\n[1] 140\n\n\n\n\n6.0.2 Matrizes\n\nSendo\n\n\\[\n\\mathbf{A} = \\begin{bmatrix}\n1 & 0.8 & 0.6\\\\\n0.8 & 1 & 0.4 \\\\\n0.6 & 0.4 & 1\n\\end{bmatrix} \\quad \\text{e} \\quad\n\\mathbf{B} = \\begin{bmatrix}\n1.5 & 0.1 & 0.5\\\\\n0.1 & 2 & 0.3\\\\\n0.5 & 0.3 & 3\n\\end{bmatrix}.\n\\]\nObtenha:\n\n\\(\\mathbf{C} = \\mathbf{A} + \\mathbf{B}\\).\n\n\nA &lt;- matrix(c(1,0.8,0.6,0.8,1,0.4,0.6,0.4,1), 3, 3)\nB &lt;- matrix(c(1.5,0.1,0.5,0.1,2,0.3,0.5,0.3,3), 3, 3)\n\nC = A + B\n\n\n\\(\\mathbf{C} = \\mathbf{A} - \\mathbf{B}\\).\n\n\nA &lt;- matrix(c(1,0.8,0.6,0.8,1,0.4,0.6,0.4,1), 3, 3)\nB &lt;- matrix(c(1.5,0.1,0.5,0.1,2,0.3,0.5,0.3,3), 3, 3)\n\nC = A - B\n\n\n\\(\\mathbf{A}^{\\top}\\) e \\(\\mathbf{B}^{\\top}\\).\n\n\nA &lt;- matrix(c(1,0.8,0.6,0.8,1,0.4,0.6,0.4,1), 3, 3)\nB &lt;- matrix(c(1.5,0.1,0.5,0.1,2,0.3,0.5,0.3,3), 3, 3)\n\nt(A)\n\n     [,1] [,2] [,3]\n[1,]  1.0  0.8  0.6\n[2,]  0.8  1.0  0.4\n[3,]  0.6  0.4  1.0\n\nt(B)\n\n     [,1] [,2] [,3]\n[1,]  1.5  0.1  0.5\n[2,]  0.1  2.0  0.3\n[3,]  0.5  0.3  3.0\n\n\n\nSendo \\(\\alpha = 5\\) obtenha \\(\\alpha (\\mathbf{A} + \\mathbf{B})\\).\n\n\nA &lt;- matrix(c(1,0.8,0.6,0.8,1,0.4,0.6,0.4,1), 3, 3)\nB &lt;- matrix(c(1.5,0.1,0.5,0.1,2,0.3,0.5,0.3,3), 3, 3)\nalpha = 5\n\nalpha*(A + B)\n\n     [,1] [,2] [,3]\n[1,] 12.5  4.5  5.5\n[2,]  4.5 15.0  3.5\n[3,]  5.5  3.5 20.0\n\n\n\nO determinante de \\(\\mathbf{A}\\).\n\n\nA &lt;- matrix(c(1,0.8,0.6,0.8,1,0.4,0.6,0.4,1), 3, 3)\n\ndeterminant(A, log = FALSE)\n\n$modulus\n[1] 0.224\nattr(,\"logarithm\")\n[1] FALSE\n\n$sign\n[1] 1\n\nattr(,\"class\")\n[1] \"det\"\n\n\n\nO traço de \\(\\mathbf{B}\\).\n\n\nB &lt;- matrix(c(1.5,0.1,0.5,0.1,2,0.3,0.5,0.3,3), 3, 3)\n\nsum(diag(B))\n\n[1] 6.5\n\n\n\n\\(\\mathbf{C} = \\mathbf{A}\\mathbf{B}.\\)\n\n\nA &lt;- matrix(c(1,0.8,0.6,0.8,1,0.4,0.6,0.4,1), 3, 3)\nB &lt;- matrix(c(1.5,0.1,0.5,0.1,2,0.3,0.5,0.3,3), 3, 3)\n\nA%*%B\n\n     [,1] [,2] [,3]\n[1,] 1.88 1.88 2.54\n[2,] 1.50 2.20 1.90\n[3,] 1.44 1.16 3.42\n\n\n\n\\(\\mathbf{C} = \\mathbf{B}\\mathbf{A}.\\)\n\n\nA &lt;- matrix(c(1,0.8,0.6,0.8,1,0.4,0.6,0.4,1), 3, 3)\nB &lt;- matrix(c(1.5,0.1,0.5,0.1,2,0.3,0.5,0.3,3), 3, 3)\n\nB%*%A\n\n     [,1] [,2] [,3]\n[1,] 1.88  1.5 1.44\n[2,] 1.88  2.2 1.16\n[3,] 2.54  1.9 3.42\n\n\n\n\\(\\mathbf{C} = \\mathbf{A}\\mathbf{A}^{\\top}.\\)\n\n\nA &lt;- matrix(c(1,0.8,0.6,0.8,1,0.4,0.6,0.4,1), 3, 3)\n\nA%*%t(A)\n\n     [,1] [,2] [,3]\n[1,] 2.00 1.84 1.52\n[2,] 1.84 1.80 1.28\n[3,] 1.52 1.28 1.52\n\n\n\n\\(\\mathbf{C} = \\mathbf{A}(\\mathbf{A} + \\mathbf{B}).\\)\n\n\nA &lt;- matrix(c(1,0.8,0.6,0.8,1,0.4,0.6,0.4,1), 3, 3)\nB &lt;- matrix(c(1.5,0.1,0.5,0.1,2,0.3,0.5,0.3,3), 3, 3)\n\nA%*%(A + B)\n\n     [,1] [,2] [,3]\n[1,] 3.88 3.72 4.06\n[2,] 3.34 4.00 3.18\n[3,] 2.96 2.44 4.94\n\n\n\nImplemente uma função para multiplicar duas matrizes. Não esqueça de verificar se as matrizes são compatíveis.\n\n\nmy_prod_mat &lt;- function(A, B) {\n  if(dim(A)[2] != dim(B)[1])\n    { stop(\"Tamanho dos vetores não é compatível para multiplicação.\") }\n  m &lt;- dim(A)[1]\n  n &lt;- dim(B)[2]\n  C &lt;- matrix(NA, nrow = m, ncol = n)\n  for(i in 1:m) {\n    for(j in 1:n) {\n      C[i,j] &lt;- sum(A[i,]*B[,j])\n    }\n  }\n  return(C)\n}\n\nmy_prod_mat(A = A, B = B)\n\n     [,1] [,2] [,3]\n[1,] 1.88 1.88 2.54\n[2,] 1.50 2.20 1.90\n[3,] 1.44 1.16 3.42\n\n\n\nConsidere o seguinte sistema de equações lineares:\n\n\\[\n\\begin{matrix}\n2x_1 + 2x_2 - 3x_3 = 2\\\\\n-1 x_1 + 3 x_2 + 2 x_3 = 0\\\\\n3 x_1 + x_2 - 3x_3 = 1\n\\end{matrix}\n\\] a) Resolva manualmente usando o método de eliminação de Gauss.\n\nUse a função criada em aula para resolver o sistema usando o método de eliminação de Gauss.\n\n\n# Decomposição de Gauss\ngauss &lt;- function(A, b) {\n  # Sistema aumentado\n  Ae &lt;- cbind(A, b)\n  rownames(Ae) &lt;- paste0(\"x\", 1:length(b))\n  n_row &lt;- nrow(Ae)\n  n_col &lt;- ncol(Ae)\n  # Matriz para receber os resultados\n  SOL &lt;- matrix(NA, n_row, n_col)\n  SOL[1,] &lt;- Ae[1,]\n  pivo &lt;- matrix(0, n_col, n_row)\n  for(j in 1:c(n_row-1)) {\n    for(i in c(j+1):c(n_row)) {\n      pivo[i,j] &lt;- Ae[i,j]/SOL[j,j]\n      SOL[i,] &lt;- Ae[i,] - pivo[i,j]*SOL[j,]\n      Ae[i,] &lt;- SOL[i,]\n    }\n  }\n  return(SOL)\n}\n\n# Substituição regressiva\nsub_reg &lt;- function(SOL) {\n  n_row &lt;- nrow(SOL)\n  n_col &lt;- ncol(SOL)\n  A &lt;- SOL[1:n_row,1:n_row]\n  b &lt;- SOL[,n_col]\n  n &lt;- length(b)\n  x &lt;- c()\n  x[n] &lt;- b[n]/A[n,n]\n  for(i in (n-1):1) {\n    x[i] &lt;- (b[i] - sum(A[i,c(i+1):n]*x[c(i+1):n] ))/A[i,i]\n  }\n  return(x)\n}\n\n# Sistema\nA &lt;- matrix(c(2,-1,3,2,3,1,-3,2,3), 3, 3)\nb &lt;- c(2,0,1)\n\n# Passo 1: Triangularização\nS &lt;- gauss(A, b)\n\n# Passo 2: Substituição regressiva\nsol = sub_reg(SOL = S)\nsol\n\n[1]  0.4354839  0.2741935 -0.1935484\n\n# Verificando\nA%*%sol\n\n              [,1]\n[1,]  2.000000e+00\n[2,] -1.110223e-16\n[3,]  1.000000e+00\n\n\n\nImplemente o método de Gauss-Jordan e resolva o sistema usando a sua função.\n\n\ngauss_jordan &lt;- function(A, b) {\n  # Matrix aumentada\n  Ab &lt;- cbind(A, b)\n  # Capturando a dimensão da saída\n  rownames(Ab) &lt;- paste0(\"x\", 1:length(b))\n  n_row &lt;- nrow(Ab)\n  n_col &lt;- ncol(Ab)\n  n_col_for &lt;- n_col-1\n  # Matriz para receber os resultados\n  SOL &lt;- matrix(NA, n_row, n_col)\n  for(j in 1:n_col_for) {\n    SOL[j,] &lt;- Ab[j,]/Ab[j,j]\n    for(i in 1:n_row) {\n      if(i != j) {\n        SOL[i,] &lt;- Ab[i,] - SOL[j,]*Ab[i,j] \n      }\n    }\n    Ab &lt;- SOL\n  }\n  return(list(\"Sistema\" = SOL, \"Solução\" = SOL[,n_col]))\n}\n\n## Sistema de equações\nA &lt;- matrix(c(2,-1,3,2,3,1,-3,2,3), 3, 3)\nb &lt;- c(2,0,1)\nresul &lt;- gauss_jordan(A = A, b = b)\n\nA%*%resul$Solução\n\n              [,1]\n[1,]  2.000000e+00\n[2,] -5.551115e-17\n[3,]  1.000000e+00\n\n\n\nObtenha a decomposição \\(\\mathbf{L} \\mathbf{U}\\) e resolva o sistema.\n\n\nmy_lu &lt;- function(A) {\n  n_row &lt;- nrow(A)\n  n_col &lt;- ncol(A)\n  # Matriz para receber os resultados\n  SOL &lt;- matrix(NA, n_row, n_col)\n  SOL[1,] &lt;- A[1,]\n  pivo &lt;- matrix(0, n_col, n_row)\n  for(j in 1:c(n_row-1)) {\n    for(i in c(j+1):c(n_row)) {\n      pivo[i,j] &lt;- A[i,j]/SOL[j,j]\n      SOL[i,] &lt;- A[i,] - pivo[i,j]*SOL[j,]\n      A[i,] &lt;- SOL[i,]\n    }\n  }\n  diag(pivo) &lt;- 1\n  return(list(\"L\" = pivo, \"U\" = SOL))\n}\n\n## Sistema de equações\nA &lt;- matrix(c(2,-1,3,2,3,1,-3,2,3), 3, 3)\nb &lt;- c(2,0,1)\n\n# Decomposição LU\nLU &lt;- my_lu(A)\ny = forwardsolve(LU$L, b)\nx = backsolve(LU$U, y)\n\n\nResolva o sistema usando o método de Jacobi.\n\n\n# require(Rlinsolve)\n# A &lt;- matrix(c(2,-1,3,2,3,1,-3,2,3), 3, 3)\n# b &lt;- c(2,0,1)\n# lsolve.jacobi(A, b)$x\n\n\nResolva o sistema usando o método de Gauss-Seidel.\n\n\n# require(Rlinsolve)\n# A &lt;- matrix(c(2,-1,3,2,3,1,-3,2,3), 3, 3)\n# b &lt;- c(2,0,1)\n# lsolve.gs(A, b)$x\n\n\nConsidere a matriz\n\n\\[\n\\mathbf{A} =\n\\begin{bmatrix}\n1 & 0.9 & 0.8\\\\\n0.9 & 1 & 0.95\\\\\n0.8 & 0.95 & 1\n\\end{bmatrix}.\n\\]\n\nObtenha \\(\\mathbf{A}^{-1}\\) pela decomposição \\(\\mathbf{LU}\\). E verifique a solução.\n\n\nA &lt;- matrix(c(1,0.9,0.8,0.9,1,0.95,0.8,0.95,1), 3, 3)\ninv_A &lt;- solve(A)\n\n# Verificando a solução\nA%*%inv_A # Ok\n\n              [,1] [,2] [,3]\n[1,]  1.000000e+00    0    0\n[2,] -8.881784e-16    1    0\n[3,] -4.440892e-16    0    1\n\n\n\nObtenha a decomposição em autovalores e autovetores de \\(\\mathbf{A}\\).\n\n\nA &lt;- matrix(c(1,0.9,0.8,0.9,1,0.95,0.8,0.95,1), 3, 3)\n\neigen(A)\n\neigen() decomposition\n$values\n[1] 2.76810863 0.20451154 0.02737983\n\n$vectors\n           [,1]       [,2]       [,3]\n[1,] -0.5625757  0.7706655  0.2993047\n[2,] -0.5948546 -0.1259031 -0.7939121\n[3,] -0.5741573 -0.6246784  0.5292639\n\n\n\nBaseado na letra b) obtenha \\(\\mathbf{A}^{-1}\\). Verifique sua solução.\n\n\nA &lt;- matrix(c(1, 0.9, 0.8,\n              0.9, 1, 0.95,\n              0.8, 0.95, 1),\n            3, 3)\n\ndeco &lt;- eigen(A)\nQ &lt;- deco$vectors\ninv_D &lt;- diag(1/deco$values)\ninv_A &lt;- Q%*%inv_D%*%t(Q)\n\n# Verificando\nA%*%inv_A\n\n             [,1]          [,2]         [,3]\n[1,] 1.000000e+00 -5.329071e-15 3.552714e-15\n[2,] 8.881784e-16  1.000000e+00 0.000000e+00\n[3,] 3.552714e-15 -7.105427e-15 1.000000e+00\n\n\n\n\n6.0.3 Desafio\n\nA função densidade probabilidade da distribuição Normal multivariada é dada pela seguinte equação\n\n\\[\np(\\boldsymbol{y}; \\boldsymbol{\\mu}, \\mathbf{\\Sigma}) = (2 \\pi)^{-\\frac{n}{2}} | \\mathbf{\\Sigma}|^{\\frac{1}{2}} \\exp\\left \\{ -\\frac{1}{2}(\\boldsymbol{y} - \\boldsymbol{\\mu})^{\\top} \\mathbf\n{\\Sigma}^{-1} (\\boldsymbol{y} - \\boldsymbol{\\mu}) \\right \\},\n\\]\nonde \\(\\mathbf{y}\\) e \\(\\boldsymbol{\\mu}\\) são vetores \\(n \\times 1\\) de variáveis aleatórias e valores esperados. A matriz \\(\\Sigma\\) é chamada de matriz de variância-covariância, sendo simétrica e positiva definida (admite inversa).\n\nImplemente a função densidade da distribuição Normal multivariada em R em pelo menos três formas diferentes e compare o tempo computacional para diferentes números de variáveis aleatórias.\nCompare a sua implementação com a função dmvnorm() do pacote mvtnorm em termos de tempo computacional.",
    "crumbs": [
      "Exercicios",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algebra Matricial</span>"
    ]
  }
]